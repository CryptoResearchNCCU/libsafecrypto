/*
 * Falcon key pair generation.
 *
 * ==========================(LICENSE BEGIN)============================
 *
 * Copyright (c) 2017  Falcon Project
 *
 * Permission is hereby granted, free of charge, to any person obtaining
 * a copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sublicense, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
 * CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
 * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 *
 * ===========================(LICENSE END)=============================
 *
 * @author   Thomas Pornin <thomas.pornin@nccgroup.trust>
 */

#include <stddef.h>
#include "internal.h"

/*
 * If CLEANSE is non-zero, then temporary areas obtained with malloc()
 * and used to contain secret values are explicitly cleared before
 * deallocation with free(). This is the default behaviour; use
 * -DCLEANSE=0 to disable cleansing.
 */
#ifndef CLEANSE
#define CLEANSE   1
#endif

/*
 * If MEMCHECK is non-zero, then a few extra bytes will be allocated
 * at the end of the main buffer, and filled with a specific pattern
 * which is checked upon exit. This implies a dependency to some extra
 * libc facilities (stderr, DOUBLEintf, abort). Overflows may occur only
 * if the computation in temp_size() is wrong.
 */
#ifndef MEMCHECK
#define MEMCHECK   1
#endif

#if MEMCHECK
#include <stdio.h>
#include <stdlib.h>
#endif

#define MKN(logn, full)   ((size_t)(1 + ((full) << 1)) << ((logn) - (full)))

#if CLEANSE
/*
 * Cleanse a memory region by overwriting it with zeros.
 */
static void
cleanse(void *data, size_t len)
{
	volatile unsigned char *p;

	p = (volatile unsigned char *)data;
	while (len -- > 0) {
		*p ++ = 0;
	}
}
#endif






/* see falcon-internal.h */
size_t
falcon_encode_12289(void *out, size_t max_out_len,
	const uint16_t *x, unsigned logn)
{
	unsigned char *buf;
	size_t n, u;
	uint32_t acc;
	int acc_len;

	n = (size_t)1 << logn;
	buf = out;
	u = 0;
	acc = 0;
	acc_len = 0;
	while (n > 0) {
		acc = (acc << 14) | (*x ++);
		n --;
		acc_len += 14;
		while (acc_len >= 8) {
			acc_len -= 8;
			if (out != NULL) {
				if (u >= max_out_len) {
					return 0;
				}
				buf[u] = (unsigned char)(acc >> acc_len);
			}
			u ++;
			acc &= (1U << acc_len) - 1U;
		}
	}
	if (acc_len > 0) {
		if (out != NULL) {
			if (u >= max_out_len) {
				return 0;
			}
			buf[u] = (unsigned char)(acc << (8 - acc_len));
		}
		u ++;
	}
	return u;
}

/* see falcon-internal.h */
size_t
falcon_decode_12289(uint16_t *x, unsigned logn, const void *data, size_t len)
{
	const unsigned char *buf;
	size_t n, u;
	uint32_t acc;
	int acc_len;

	n = (size_t)1 << logn;
	buf = data;
	u = 0;
	acc = 0;
	acc_len = 0;
	while (n > 0) {
		if (u >= len) {
			return 0;
		}
		acc = (acc << 8) | buf[u ++];
		acc_len += 8;
		if (acc_len >= 14) {
			uint32_t w;

			acc_len -= 14;
			w = acc >> acc_len;
			if (w >= 12289) {
				return 0;
			}
			*x ++ = (uint16_t)w;
			n --;
			acc &= (1U << acc_len) - 1U;
		}
	}
	if (acc != 0) {
		return 0;
	}
	return len;
}

/* see falcon-internal.h */
size_t
falcon_encode_18433(void *out, size_t max_out_len,
	const uint16_t *x, unsigned logn)
{
	unsigned char *buf;
	size_t n, u;
	uint32_t acc;
	int acc_len;

	n = (size_t)3 << (logn - 1);
	buf = out;
	u = 0;
	acc = 0;
	acc_len = 0;
	while (n > 0) {
		acc = (acc << 15) | (*x ++);
		n --;
		acc_len += 15;
		while (acc_len >= 8) {
			acc_len -= 8;
			if (out != NULL) {
				if (u >= max_out_len) {
					return 0;
				}
				buf[u] = (unsigned char)(acc >> acc_len);
			}
			u ++;
			acc &= (1U << acc_len) - 1U;
		}
	}
	if (acc_len > 0) {
		if (out != NULL) {
			if (u >= max_out_len) {
				return 0;
			}
			buf[u] = (unsigned char)(acc << (8 - acc_len));
		}
		u ++;
	}
	return u;
}

/* see falcon-internal.h */
size_t
falcon_decode_18433(uint16_t *x, unsigned logn, const void *data, size_t len)
{
	const unsigned char *buf;
	size_t n, u;
	uint32_t acc;
	int acc_len;

	n = (size_t)3 << (logn - 1);
	buf = data;
	u = 0;
	acc = 0;
	acc_len = 0;
	while (n > 0) {
		if (u >= len) {
			return 0;
		}
		acc = (acc << 8) | buf[u ++];
		acc_len += 8;
		if (acc_len >= 15) {
			uint32_t w;

			acc_len -= 15;
			w = acc >> acc_len;
			if (w >= 18433) {
				return 0;
			}
			*x ++ = (uint16_t)w;
			n --;
			acc &= (1U << acc_len) - 1U;
		}
	}
	if (acc != 0) {
		return 0;
	}
	return len;
}

/*
 * Encoding of a small vector, no compression, 16 bits per value.
 */
static size_t
compress_none(void *out, size_t max_out_len,
	unsigned q, const int16_t *x, unsigned logn)
{
	size_t len, u;
	unsigned char *buf;

	if (q == 12289) {
		len = (size_t)2 << logn;
	} else {
		len = (size_t)3 << logn;
	}
	if (out == NULL) {
		return len;
	}
	if (max_out_len < len) {
		return 0;
	}
	buf = out;
	for (u = 0; u < len; u += 2) {
		unsigned w;

		w = *x ++;
		buf[u + 0] = (unsigned char)(w >> 8);
		buf[u + 1] = (unsigned char)w;
	}
	return len;
}

/*
 * Encoding of a small vector, using (sort-of) Huffman codes.
 */
static size_t
compress_static(void *out, size_t max_out_len,
	unsigned q, const int16_t *x, unsigned logn)
{
	unsigned char *buf;
	size_t n, u;
	unsigned acc, mask;
	int acc_len, j;

	/*
	 * Let x be a value to encode. We first encode its sign as 1 bit
	 * (1 = negative, 0 = positive), and replace x with |x|.
	 * The low j bits are encoded as-is in the stream (number j depends
	 * on the modulus q); then we follow with x/(2^j) bits of value 0,
	 * and a final bit of value 1.
	 *
	 * We use j = 7 for q = 12289, j = 8 for q = 18433.
	 */

	if (q == 12289) {
		n = (size_t)1 << logn;
		j = 7;
	} else {
		n = (size_t)3 << (logn - 1);
		j = 8;
	}
	mask = (1U << j) - 1U;
	buf = out;
	u = 0;
	acc = 0;
	acc_len = 0;
	while (n > 0) {
		int w;
		unsigned lo;
		int ne;

		w = *x ++;
		n --;

		/*
		 * First part: 1 bit for sign, and then the 7 low bits of
		 * the absolute value of the integer.
		 */
		if (w < 0) {
			w = -w;
			lo = 1U << j;
		} else {
			lo = 0;
		}
		lo |= w & mask;
		ne = w >> j;
		acc = (acc << (j + 1)) | lo;
		acc_len += j + 1;
		while (acc_len >= 8) {
			acc_len -= 8;
			if (buf != NULL) {
				if (u >= max_out_len) {
					return 0;
				}
				buf[u] = (unsigned char)(acc >> acc_len);
			}
			u ++;
		}

		/*
		 * Second part: 'ne' bits of value 0, and one bit of value 1.
		 */
		while (ne -- >= 0) {
			acc <<= 1;
			acc += ((unsigned)ne >> 15) & 1;
			if (++ acc_len == 8) {
				if (buf != NULL) {
					if (u >= max_out_len) {
						return 0;
					}
					buf[u] = (unsigned char)acc;
				}
				u ++;
				acc_len = 0;
			}
		}
	}
	if (acc_len > 0) {
		if (buf != NULL) {
			if (u >= max_out_len) {
				return 0;
			}
			buf[u] = (unsigned char)(acc << (8 - acc_len));
		}
		u ++;
	}
	return u;
}

size_t
falcon_encode_small(void *out, size_t max_out_len,
	int comp, unsigned q, const int16_t *x, unsigned logn)
{
	switch (comp) {
	case FALCON_COMP_NONE:
		return compress_none(out, max_out_len, q, x, logn);
	case FALCON_COMP_STATIC:
		return compress_static(out, max_out_len, q, x, logn);
	default:
		return 0;
	}
}


#define Qb     12289
#define Q0Ib   12287
#define Rb      4091
#define R2b    10952

#define Qt     18433
#define Q0It   18431
#define Rt     10237
#define R2t     4564

/*
 * Inverse of n = 1.5*2^logn modulo q, for the ternary case. Values are
 * in Montogmery representation. This is defined only for logn from 2 to 9.
 */
static const uint16_t INVNQt[] = {
	0, 0, 17067, 17750, 8875, 13654, 6827, 12630, 6315, 12374
};

/*
 * Table for NTT, binary case:
 *   GMb[x] = R*(g^rev(x)) mod q
 * where g = 7 (it is a 2048-th primitive root of 1 modulo q)
 * and rev() is the bit-reversal function over 10 bits.
 */
static const uint16_t GMb[] = {
	 4091,  7888, 11060, 11208,  6960,  4342,  6275,  9759,
	 1591,  6399,  9477,  5266,   586,  5825,  7538,  9710,
	 1134,  6407,  1711,   965,  7099,  7674,  3743,  6442,
	10414,  8100,  1885,  1688,  1364, 10329, 10164,  9180,
	12210,  6240,   997,   117,  4783,  4407,  1549,  7072,
	 2829,  6458,  4431,  8877,  7144,  2564,  5664,  4042,
	12189,   432, 10751,  1237,  7610,  1534,  3983,  7863,
	 2181,  6308,  8720,  6570,  4843,  1690,    14,  3872,
	 5569,  9368, 12163,  2019,  7543,  2315,  4673,  7340,
	 1553,  1156,  8401, 11389,  1020,  2967, 10772,  7045,
	 3316, 11236,  5285, 11578, 10637, 10086,  9493,  6180,
	 9277,  6130,  3323,   883, 10469,   489,  1502,  2851,
	11061,  9729,  2742, 12241,  4970, 10481, 10078,  1195,
	  730,  1762,  3854,  2030,  5892, 10922,  9020,  5274,
	 9179,  3604,  3782, 10206,  3180,  3467,  4668,  2446,
	 7613,  9386,   834,  7703,  6836,  3403,  5351, 12276,
	 3580,  1739, 10820,  9787, 10209,  4070, 12250,  8525,
	10401,  2749,  7338, 10574,  6040,   943,  9330,  1477,
	 6865,  9668,  3585,  6633, 12145,  4063,  3684,  7680,
	 8188,  6902,  3533,  9807,  6090,   727, 10099,  7003,
	 6945,  1949,  9731, 10559,  6057,   378,  7871,  8763,
	 8901,  9229,  8846,  4551,  9589, 11664,  7630,  8821,
	 5680,  4956,  6251,  8388, 10156,  8723,  2341,  3159,
	 1467,  5460,  8553,  7783,  2649,  2320,  9036,  6188,
	  737,  3698,  4699,  5753,  9046,  3687,    16,   914,
	 5186, 10531,  4552,  1964,  3509,  8436,  7516,  5381,
	10733,  3281,  7037,  1060,  2895,  7156,  8887,  5357,
	 6409,  8197,  2962,  6375,  5064,  6634,  5625,   278,
	  932, 10229,  8927,  7642,   351,  9298,   237,  5858,
	 7692,  3146, 12126,  7586,  2053, 11285,  3802,  5204,
	 4602,  1748, 11300,   340,  3711,  4614,   300, 10993,
	 5070, 10049, 11616, 12247,  7421, 10707,  5746,  5654,
	 3835,  5553,  1224,  8476,  9237,  3845,   250, 11209,
	 4225,  6326,  9680, 12254,  4136,  2778,   692,  8808,
	 6410,  6718, 10105, 10418,  3759,  7356, 11361,  8433,
	 6437,  3652,  6342,  8978,  5391,  2272,  6476,  7416,
	 8418, 10824, 11986,  5733,   876,  7030,  2167,  2436,
	 3442,  9217,  8206,  4858,  5964,  2746,  7178,  1434,
	 7389,  8879, 10661, 11457,  4220,  1432, 10832,  4328,
	 8557,  1867,  9454,  2416,  3816,  9076,   686,  5393,
	 2523,  4339,  6115,   619,   937,  2834,  7775,  3279,
	 2363,  7488,  6112,  5056,   824, 10204, 11690,  1113,
	 2727,  9848,   896,  2028,  5075,  2654, 10464,  7884,
	12169,  5434,  3070,  6400,  9132, 11672, 12153,  4520,
	 1273,  9739, 11468,  9937, 10039,  9720,  2262,  9399,
	11192,   315,  4511,  1158,  6061,  6751, 11865,   357,
	 7367,  4550,   983,  8534,  8352, 10126,  7530,  9253,
	 4367,  5221,  3999,  8777,  3161,  6990,  4130, 11652,
	 3374, 11477,  1753,   292,  8681,  2806, 10378, 12188,
	 5800, 11811,  3181,  1988,  1024,  9340,  2477, 10928,
	 4582,  6750,  3619,  5503,  5233,  2463,  8470,  7650,
	 7964,  6395,  1071,  1272,  3474, 11045,  3291, 11344,
	 8502,  9478,  9837,  1253,  1857,  6233,  4720, 11561,
	 6034,  9817,  3339,  1797,  2879,  6242,  5200,  2114,
	 7962,  9353, 11363,  5475,  6084,  9601,  4108,  7323,
	10438,  9471,  1271,   408,  6911,  3079,   360,  8276,
	11535,  9156,  9049, 11539,   850,  8617,   784,  7919,
	 8334, 12170,  1846, 10213, 12184,  7827, 11903,  5600,
	 9779,  1012,   721,  2784,  6676,  6552,  5348,  4424,
	 6816,  8405,  9959,  5150,  2356,  5552,  5267,  1333,
	 8801,  9661,  7308,  5788,  4910,   909, 11613,  4395,
	 8238,  6686,  4302,  3044,  2285, 12249,  1963,  9216,
	 4296, 11918,   695,  4371,  9793,  4884,  2411, 10230,
	 2650,   841,  3890, 10231,  7248,  8505, 11196,  6688,
	 4059,  6060,  3686,  4722, 11853,  5816,  7058,  6868,
	11137,  7926,  4894, 12284,  4102,  3908,  3610,  6525,
	 7938,  7982, 11977,  6755,   537,  4562,  1623,  8227,
	11453,  7544,   906, 11816,  9548, 10858,  9703,  2815,
	11736,  6813,  6979,   819,  8903,  6271, 10843,   348,
	 7514,  8339,  6439,   694,   852,  5659,  2781,  3716,
	11589,  3024,  1523,  8659,  4114, 10738,  3303,  5885,
	 2978,  7289, 11884,  9123,  9323, 11830,    98,  2526,
	 2116,  4131, 11407,  1844,  3645,  3916,  8133,  2224,
	10871,  8092,  9651,  5989,  7140,  8480,  1670,   159,
	10923,  4918,   128,  7312,   725,  9157,  5006,  6393,
	 3494,  6043, 10972,  6181, 11838,  3423, 10514,  7668,
	 3693,  6658,  6905, 11953, 10212, 11922,  9101,  8365,
	 5110,    45,  2400,  1921,  4377,  2720,  1695,    51,
	 2808,   650,  1896,  9997,  9971, 11980,  8098,  4833,
	 4135,  4257,  5838,  4765, 10985, 11532,   590, 12198,
	  482, 12173,  2006,  7064, 10018,  3912, 12016, 10519,
	11362,  6954,  2210,   284,  5413,  6601,  3865, 10339,
	11188,  6231,   517,  9564, 11281,  3863,  1210,  4604,
	 8160, 11447,   153,  7204,  5763,  5089,  9248, 12154,
	11748,  1354,  6672,   179,  5532,  2646,  5941, 12185,
	  862,  3158,   477,  7279,  5678,  7914,  4254,   302,
	 2893, 10114,  6890,  9560,  9647, 11905,  4098,  9824,
	10269,  1353, 10715,  5325,  6254,  3951,  1807,  6449,
	 5159,  1308,  8315,  3404,  1877,  1231,   112,  6398,
	11724, 12272,  7286,  1459, 12274,  9896,  3456,   800,
	 1397, 10678,   103,  7420,  7976,   936,   764,   632,
	 7996,  8223,  8445,  7758, 10870,  9571,  2508,  1946,
	 6524, 10158,  1044,  4338,  2457,  3641,  1659,  4139,
	 4688,  9733, 11148,  3946,  2082,  5261,  2036, 11850,
	 7636, 12236,  5366,  2380,  1399,  7720,  2100,  3217,
	10912,  8898,  7578, 11995,  2791,  1215,  3355,  2711,
	 2267,  2004,  8568, 10176,  3214,  2337,  1750,  4729,
	 4997,  7415,  6315, 12044,  4374,  7157,  4844,   211,
	 8003, 10159,  9290, 11481,  1735,  2336,  5793,  9875,
	 8192,   986,  7527,  1401,   870,  3615,  8465,  2756,
	 9770,  2034, 10168,  3264,  6132,    54,  2880,  4763,
	11805,  3074,  8286,  9428,  4881,  6933,  1090, 10038,
	 2567,   708,   893,  6465,  4962, 10024,  2090,  5718,
	10743,   780,  4733,  4623,  2134,  2087,  4802,   884,
	 5372,  5795,  5938,  4333,  6559,  7549,  5269, 10664,
	 4252,  3260,  5917, 10814,  5768,  9983,  8096,  7791,
	 6800,  7491,  6272,  1907, 10947,  6289, 11803,  6032,
	11449,  1171,  9201,  7933,  2479,  7970, 11337,  7062,
	 8911,  6728,  6542,  8114,  8828,  6595,  3545,  4348,
	 4610,  2205,  6999,  8106,  5560, 10390,  9321,  2499,
	 2413,  7272,  6881, 10582,  9308,  9437,  3554,  3326,
	 5991, 11969,  3415, 12283,  9838, 12063,  4332,  7830,
	11329,  6605, 12271,  2044, 11611,  7353, 11201, 11582,
	 3733,  8943,  9978,  1627,  7168,  3935,  5050,  2762,
	 7496, 10383,   755,  1654, 12053,  4952, 10134,  4394,
	 6592,  7898,  7497,  8904, 12029,  3581, 10748,  5674,
	10358,  4901,  7414,  8771,   710,  6764,  8462,  7193,
	 5371,  7274, 11084,   290,  7864,  6827, 11822,  2509,
	 6578,  4026,  5807,  1458,  5721,  5762,  4178,  2105,
	11621,  4852,  8897,  2856, 11510,  9264,  2520,  8776,
	 7011,  2647,  1898,  7039,  5950, 11163,  5488,  6277,
	 9182, 11456,   633, 10046, 11554,  5633,  9587,  2333,
	 7008,  7084,  5047,  7199,  9865,  8997,   569,  6390,
	10845,  9679,  8268, 11472,  4203,  1997,     2,  9331,
	  162,  6182,  2000,  3649,  9792,  6363,  7557,  6187,
	 8510,  9935,  5536,  9019,  3706, 12009,  1452,  3067,
	 5494,  9692,  4865,  6019,  7106,  9610,  4588, 10165,
	 6261,  5887,  2652, 10172,  1580, 10379,  4638,  9949
};

/*
 * Table for inverse NTT, binary case:
 *   iGMb[x] = R*((1/g)^rev(x)) mod q
 * Since g = 7, 1/g = 8778 mod 12289.
 */
static const uint16_t iGMb[] = {
	 4091,  4401,  1081,  1229,  2530,  6014,  7947,  5329,
	 2579,  4751,  6464, 11703,  7023,  2812,  5890, 10698,
	 3109,  2125,  1960, 10925, 10601, 10404,  4189,  1875,
	 5847,  8546,  4615,  5190, 11324, 10578,  5882, 11155,
	 8417, 12275, 10599,  7446,  5719,  3569,  5981, 10108,
	 4426,  8306, 10755,  4679, 11052,  1538, 11857,   100,
	 8247,  6625,  9725,  5145,  3412,  7858,  5831,  9460,
	 5217, 10740,  7882,  7506, 12172, 11292,  6049,    79,
	   13,  6938,  8886,  5453,  4586, 11455,  2903,  4676,
	 9843,  7621,  8822,  9109,  2083,  8507,  8685,  3110,
	 7015,  3269,  1367,  6397, 10259,  8435, 10527, 11559,
	11094,  2211,  1808,  7319,    48,  9547,  2560,  1228,
	 9438, 10787, 11800,  1820, 11406,  8966,  6159,  3012,
	 6109,  2796,  2203,  1652,   711,  7004,  1053,  8973,
	 5244,  1517,  9322, 11269,   900,  3888, 11133, 10736,
	 4949,  7616,  9974,  4746, 10270,   126,  2921,  6720,
	 6635,  6543,  1582,  4868,    42,   673,  2240,  7219,
	 1296, 11989,  7675,  8578, 11949,   989, 10541,  7687,
	 7085,  8487,  1004, 10236,  4703,   163,  9143,  4597,
	 6431, 12052,  2991, 11938,  4647,  3362,  2060, 11357,
	12011,  6664,  5655,  7225,  5914,  9327,  4092,  5880,
	 6932,  3402,  5133,  9394, 11229,  5252,  9008,  1556,
	 6908,  4773,  3853,  8780, 10325,  7737,  1758,  7103,
	11375, 12273,  8602,  3243,  6536,  7590,  8591, 11552,
	 6101,  3253,  9969,  9640,  4506,  3736,  6829, 10822,
	 9130,  9948,  3566,  2133,  3901,  6038,  7333,  6609,
	 3468,  4659,   625,  2700,  7738,  3443,  3060,  3388,
	 3526,  4418, 11911,  6232,  1730,  2558, 10340,  5344,
	 5286,  2190, 11562,  6199,  2482,  8756,  5387,  4101,
	 4609,  8605,  8226,   144,  5656,  8704,  2621,  5424,
	10812,  2959, 11346,  6249,  1715,  4951,  9540,  1888,
	 3764,    39,  8219,  2080,  2502,  1469, 10550,  8709,
	 5601,  1093,  3784,  5041,  2058,  8399, 11448,  9639,
	 2059,  9878,  7405,  2496,  7918, 11594,   371,  7993,
	 3073, 10326,    40, 10004,  9245,  7987,  5603,  4051,
	 7894,   676, 11380,  7379,  6501,  4981,  2628,  3488,
	10956,  7022,  6737,  9933,  7139,  2330,  3884,  5473,
	 7865,  6941,  5737,  5613,  9505, 11568, 11277,  2510,
	 6689,   386,  4462,   105,  2076, 10443,   119,  3955,
	 4370, 11505,  3672, 11439,   750,  3240,  3133,   754,
	 4013, 11929,  9210,  5378, 11881, 11018,  2818,  1851,
	 4966,  8181,  2688,  6205,  6814,   926,  2936,  4327,
	10175,  7089,  6047,  9410, 10492,  8950,  2472,  6255,
	  728,  7569,  6056, 10432, 11036,  2452,  2811,  3787,
	  945,  8998,  1244,  8815, 11017, 11218,  5894,  4325,
	 4639,  3819,  9826,  7056,  6786,  8670,  5539,  7707,
	 1361,  9812,  2949, 11265, 10301,  9108,   478,  6489,
	  101,  1911,  9483,  3608, 11997, 10536,   812,  8915,
	  637,  8159,  5299,  9128,  3512,  8290,  7068,  7922,
	 3036,  4759,  2163,  3937,  3755, 11306,  7739,  4922,
	11932,   424,  5538,  6228, 11131,  7778, 11974,  1097,
	 2890, 10027,  2569,  2250,  2352,   821,  2550, 11016,
	 7769,   136,   617,  3157,  5889,  9219,  6855,   120,
	 4405,  1825,  9635,  7214, 10261, 11393,  2441,  9562,
	11176,   599,  2085, 11465,  7233,  6177,  4801,  9926,
	 9010,  4514,  9455, 11352, 11670,  6174,  7950,  9766,
	 6896, 11603,  3213,  8473,  9873,  2835, 10422,  3732,
	 7961,  1457, 10857,  8069,   832,  1628,  3410,  4900,
	10855,  5111,  9543,  6325,  7431,  4083,  3072,  8847,
	 9853, 10122,  5259, 11413,  6556,   303,  1465,  3871,
	 4873,  5813, 10017,  6898,  3311,  5947,  8637,  5852,
	 3856,   928,  4933,  8530,  1871,  2184,  5571,  5879,
	 3481, 11597,  9511,  8153,    35,  2609,  5963,  8064,
	 1080, 12039,  8444,  3052,  3813, 11065,  6736,  8454,
	 2340,  7651,  1910, 10709,  2117,  9637,  6402,  6028,
	 2124,  7701,  2679,  5183,  6270,  7424,  2597,  6795,
	 9222, 10837,   280,  8583,  3270,  6753,  2354,  3779,
	 6102,  4732,  5926,  2497,  8640, 10289,  6107, 12127,
	 2958, 12287, 10292,  8086,   817,  4021,  2610,  1444,
	 5899, 11720,  3292,  2424,  5090,  7242,  5205,  5281,
	 9956,  2702,  6656,   735,  2243, 11656,   833,  3107,
	 6012,  6801,  1126,  6339,  5250, 10391,  9642,  5278,
	 3513,  9769,  3025,   779,  9433,  3392,  7437,   668,
	10184,  8111,  6527,  6568, 10831,  6482,  8263,  5711,
	 9780,   467,  5462,  4425, 11999,  1205,  5015,  6918,
	 5096,  3827,  5525, 11579,  3518,  4875,  7388,  1931,
	 6615,  1541,  8708,   260,  3385,  4792,  4391,  5697,
	 7895,  2155,  7337,   236, 10635, 11534,  1906,  4793,
	 9527,  7239,  8354,  5121, 10662,  2311,  3346,  8556,
	  707,  1088,  4936,   678, 10245,    18,  5684,   960,
	 4459,  7957,   226,  2451,     6,  8874,   320,  6298,
	 8963,  8735,  2852,  2981,  1707,  5408,  5017,  9876,
	 9790,  2968,  1899,  6729,  4183,  5290, 10084,  7679,
	 7941,  8744,  5694,  3461,  4175,  5747,  5561,  3378,
	 5227,   952,  4319,  9810,  4356,  3088, 11118,   840,
	 6257,   486,  6000,  1342, 10382,  6017,  4798,  5489,
	 4498,  4193,  2306,  6521,  1475,  6372,  9029,  8037,
	 1625,  7020,  4740,  5730,  7956,  6351,  6494,  6917,
	11405,  7487, 10202, 10155,  7666,  7556, 11509,  1546,
	 6571, 10199,  2265,  7327,  5824, 11396, 11581,  9722,
	 2251, 11199,  5356,  7408,  2861,  4003,  9215,   484,
	 7526,  9409, 12235,  6157,  9025,  2121, 10255,  2519,
	 9533,  3824,  8674, 11419, 10888,  4762, 11303,  4097,
	 2414,  6496,  9953, 10554,   808,  2999,  2130,  4286,
	12078,  7445,  5132,  7915,   245,  5974,  4874,  7292,
	 7560, 10539,  9952,  9075,  2113,  3721, 10285, 10022,
	 9578,  8934, 11074,  9498,   294,  4711,  3391,  1377,
	 9072, 10189,  4569, 10890,  9909,  6923,    53,  4653,
	  439, 10253,  7028, 10207,  8343,  1141,  2556,  7601,
	 8150, 10630,  8648,  9832,  7951, 11245,  2131,  5765,
	10343,  9781,  2718,  1419,  4531,  3844,  4066,  4293,
	11657, 11525, 11353,  4313,  4869, 12186,  1611, 10892,
	11489,  8833,  2393,    15, 10830,  5003,    17,   565,
	 5891, 12177, 11058, 10412,  8885,  3974, 10981,  7130,
	 5840, 10482,  8338,  6035,  6964,  1574, 10936,  2020,
	 2465,  8191,   384,  2642,  2729,  5399,  2175,  9396,
	11987,  8035,  4375,  6611,  5010, 11812,  9131, 11427,
	  104,  6348,  9643,  6757, 12110,  5617, 10935,   541,
	  135,  3041,  7200,  6526,  5085, 12136,   842,  4129,
	 7685, 11079,  8426,  1008,  2725, 11772,  6058,  1101,
	 1950,  8424,  5688,  6876, 12005, 10079,  5335,   927,
	 1770,   273,  8377,  2271,  5225, 10283,   116, 11807,
	   91, 11699,   757,  1304,  7524,  6451,  8032,  8154,
	 7456,  4191,   309,  2318,  2292, 10393, 11639,  9481,
	12238, 10594,  9569,  7912, 10368,  9889, 12244,  7179,
	 3924,  3188,   367,  2077,   336,  5384,  5631,  8596,
	 4621,  1775,  8866,   451,  6108,  1317,  6246,  8795,
	 5896,  7283,  3132, 11564,  4977, 12161,  7371,  1366,
	12130, 10619,  3809,  5149,  6300,  2638,  4197,  1418,
	10065,  4156,  8373,  8644, 10445,   882,  8158, 10173,
	 9763, 12191,   459,  2966,  3166,   405,  5000,  9311,
	 6404,  8986,  1551,  8175,  3630, 10766,  9265,   700,
	 8573,  9508,  6630, 11437, 11595,  5850,  3950,  4775,
	11941,  1446,  6018,  3386, 11470,  5310,  5476,   553,
	 9474,  2586,  1431,  2741,   473, 11383,  4745,   836,
	 4062, 10666,  7727, 11752,  5534,   312,  4307,  4351,
	 5764,  8679,  8381,  8187,     5,  7395,  4363,  1152,
	 5421,  5231,  6473,   436,  7567,  8603,  6229,  8230
};

/*
 * Tables for NTT and inverse NTT, ternary case.
 *
 *   GMt_square: for degree halving and doubling (inverse: iGMt_square)
 *   GMt_cubic: for ternary split/merge (inverse: iGMt_cubic)
 */

static const uint16_t GMt_square[] = {
	 9358,  9358,  8086, 11703,  5774, 14509, 12722,  9851,
	16750, 12828,  7852,   806,  1458, 10770,  9265, 12609,
	 8775,  1328, 14458, 11372,  1705,  1823,  7105,  6894,
	 9026,    72, 11666,  7057,  4201,  8427, 18263, 14143,
	11872,  6834,  4390,  7775, 13188, 11852, 17658,  7550,
	 8671,  4125, 12457, 11838, 14110,  5843,  1013, 16889,
	15905,  5600, 12331, 18417,  5191,  4134,  9307, 10416,
	  141, 17654, 14588, 12484,   374,  9438, 14640,  1869,
	17998, 16130, 13431, 13647,  6690,  6180, 12094,   509,
	12223, 13523,  4231,  1594,  5883,  7501, 10569, 12987,
	17487, 15162,  2004,   694,  7557,  9626,  4139,  9031,
	10013, 13052,  3184,  2280,  6819,   761, 10145,  8793,
	15397,  5792,   430,  6514,  4105,  8173, 14998, 17409,
	 9415, 15310,  5503, 14176,  9024,  5443, 11982,  6357,
	 4076,  3104,  1147,  7259,   876,  6926,  9056, 11672,
	 8610, 11260,  3662,  8921, 16955,  6074, 12328, 17257,
	18117,   700, 13062, 18431,  2953,  5125, 12684,  1302,
	 6930,  6815, 11040, 10777,  4655,  5788,  1830,  7146,
	 5330,  8726,  5778,  3767, 14007, 15171, 17287, 17705,
	16342,  2532, 17017,  5470, 15632, 10638,   166, 15032,
	 3832, 13211,  2833, 14024, 12256,  7850, 17450, 13144,
	14661,  9989,  6120,  6976,  3983,  4010, 15841, 11575,
	 8164, 10848,   398,   285, 12373, 16224, 17397, 17228,
	 7857, 15028, 12038,  3433,  9467,  4695, 15720, 13943,
	 4443,  3691, 16893,  6678,  1588, 11882,  7158,  2810,
	12578,  9470,  3440, 15246, 14407, 10085,  9386, 10241,
	 9408,  6459,  6609, 11726, 13581, 16348, 10863, 16069,
	14175,  6399,  9176,  2773,  7008,   109, 17149,  1211,
	15887, 17073, 15175, 12117, 16909,   576,  1163,  1157,
	 4969, 10459,  7517,  6448,  9389, 11401,  9611,  5076,
	 2811, 17806, 16687,  6901, 13339,  2651, 12233,  5101,
	14069, 14567,  7491,  2539,  2282,  9878,  8104,  6081
};

static const uint16_t GMt_cubic[] = {
	    0,     0,  5863, 13355,  3451, 10413, 17691,  5912,
	 1638, 13729,   651,  6638,  5184, 14889,  7732, 13716,
	 6193, 12464,  2225,  4481,  6221, 17110, 16888,  3019,
	18432,  3784, 17251, 11902,  2776,  2426,   158, 10417,
	 2894, 16739, 10603,  6889,  3044,  2129,  3573,  9590,
	 9271, 14968,  9120, 14929, 14605, 15247,  9822, 12913,
	 5467, 13131, 10444,   256, 12400,  8818,  2565,  8231,
	 1966,  7588,  1254, 10578, 16985,  4631,  2733, 17674,
	 8301, 17281,  5426,  2378, 16107,  9043, 15618, 16119,
	12790,  7698,  2720, 11567, 15351, 12632,  6810,   294,
	 3399,  4418, 17657,  5537,  2072, 12010, 15948,  2410,
	16169, 14064, 15170, 15515, 17644, 17863,  7485,  8281,
	14259, 15768,  6376,  2013, 11100,  6407, 14337, 15544,
	11571, 12144, 18069, 13334,  7623,  2213, 15082, 16713,
	 5319,  1740,  1405, 10617, 17722, 17639,  7516,  1575,
	 3339, 10262,  2036,   770,  2735, 10106,  6995,   708,
	10542, 16517, 18369,  2547,  7012, 10112, 11767,  7800,
	16536,  7811,  6572, 16102, 12667, 12305,  4798,   873,
	 2005,  7476, 10486,  7225,   886,  2182, 15004, 16937,
	 4939,  1886, 13070, 17292,  3488, 17869, 12257, 15373,
	 7292,  1273, 10933, 11613, 15275,  5288,  9143,  1629,
	11564,  1766,  9795,  4483,  8622,   762, 16188, 15900,
	14917, 14351,  9946,  4522,  9359, 13770,  2538, 18234,
	 6214,  6732,  8614, 12601,  3224,  3030, 13570,  5458,
	11553,  6524, 15226,  6374,  2292,  9015, 17926,  1456,
	 6036, 16696,   981, 11362, 18094, 10899,  4828, 16384,
	 2832, 11718, 11051,  7493,  9259,  5077, 13369, 10289,
	 4117, 15590, 18415, 12813, 18101,  2844, 13102,  6802,
	 4802,  4170, 17033,  7329, 15140,     4, 15470,  4728,
	11498, 11881,  5515, 15829,  7508, 13414,  8183,  2968,
	   81,  6857,  3577, 12887, 14773,  6257,  5635,  4141,
	 4355, 18215,  4803,   386,  2568, 15312, 12364, 16011,
	 9971,  2087,  7035, 15245,  6870, 12883,  9820,  2048,
	 9503,  3431,  6849,   182, 15728,  5405, 10032, 10892,
	 7427,  6557,  4606,  8514,  9175,  9572,  6246, 14675,
	12678,  7547, 17800, 17415, 12902,  7849,  6073,  5719,
	15262, 17614, 12210,  8891, 10155,  6285,  3327,   371,
	11109,  9217,  6542,   591, 18258, 17045, 14346, 18354,
	12065,  4581, 12121, 13873,   321,  1914, 10762, 13522,
	 8759, 16911, 12225,  7430, 16576,  3915, 16986,   847,
	11952,  8214,  7586, 13190,   648, 17990, 10183, 10931,
	 7690,  6747,  2111, 11898, 16407, 16689,  1558,  3088,
	 4854, 10165,  4765, 15147, 18252,  2883,  7254, 16034,
	 1550, 14927,  7233,  3333, 10522,    32, 13162,   958,
	18150,  1758, 15721, 13460, 11422,  4537,  7848, 17164,
	  259, 15326, 11210, 14126, 18336, 16821, 14377, 11648,
	13534, 12651, 15777,  4319, 14503, 14122, 18289, 10339,
	 4223,  1579, 14676,  4645,   340,  3750, 14787,  8580,
	10662,  4829, 12745, 12081,  5686, 13920, 11240, 11204,
	13430,   661,  3447,  7116,  8279,  8364, 16288,  6160,
	 5385, 10058,  5685, 17704,   403,  4987, 15521, 14507,
	 3474, 15546, 14142, 16104, 15068, 14390,  4098, 13754,
	12138,  4844,  6242, 11378,   436,  9146, 17661,  8834,
	 4719,  4881, 11092, 18246,  5919, 17032, 10151,  2988,
	10093,  1264,  3775,   975, 18425, 11839,  8977,  3051,
	13104, 17667,  5208, 16238, 10038,  6621, 12497, 10430,
	12967,  1518,  9171,  6275,  3257,  7189, 15710, 18218,
	10604,  3105, 17921,  1943,   797,  7164,  1971,  7101,
	11938,  5891,  9471, 13921,  2646, 15088, 12395,  9305,
	16040,  4509, 10156,  2501,  7088, 17456,  9434,  6465,
	 2304,   473, 13677,  6096,   347, 14128,  4628, 17431,
	 3037, 10184, 13732,   739, 11602,  5438, 17845, 13032,
	 9597, 16395,  7359,  5807, 12846, 16990, 13613,  8643,
	 8738,  4210,  5836, 17743,  1140, 17995,  1871, 16841
};

static const uint16_t iGMt_square[] = {
	 3318,   879,  6730, 10347,  8582,  5711,  3924, 12659,
	 5824,  9168,  7663, 16975, 17627, 10581,  5605,  1683,
	 4290,   170, 10006, 14232, 11376,  6767, 18361,  9407,
	11539, 11328, 16610, 16728,  7061,  3975, 17105,  9658,
	16564,  3793,  8995, 18059,  5949,  3845,   779, 18292,
	 8017,  9126, 14299, 13242,    16,  6102, 12833,  2528,
	 1544, 17420, 12590,  4323,  6595,  5976, 14308,  9762,
	10883,   775,  6581,  5245, 10658, 14043, 11599,  6561,
	 1176,  6105, 12359,  1478,  9512, 14771,  7173,  9823,
	 6761,  9377, 11507, 17557, 11174, 17286, 15329, 14357,
	12076,  6451, 12990,  9409,  4257, 12930,  3123,  9018,
	 1024,  3435, 10260, 14328, 11919, 18003, 12641,  3036,
	 9640,  8288, 17672, 11614, 16153, 15249,  5381,  8420,
	 9402, 14294,  8807, 10876, 17739, 16429,  3271,   946,
	 5446,  7864, 10932, 12550, 16839, 14202,  4910,  6210,
	17924,  6339, 12253, 11743,  4786,  5002,  2303,   435,
	12352, 10329,  8555, 16151, 15894, 10942,  3866,  4364,
	13332,  6200, 15782,  5094, 11532,  1746,   627, 15622,
	13357,  8822,  7032,  9044, 11985, 10916,  7974, 13464,
	17276, 17270, 17857,  1524,  6316,  3258,  1360,  2546,
	17222,  1284, 18324, 11425, 15660,  9257, 12034,  4258,
	 2364,  7570,  2085,  4852,  6707, 11824, 11974,  9025,
	 8192,  9047,  8348,  4026,  3187, 14993,  8963,  5855,
	15623, 11275,  6551, 16845, 11755,  1540, 14742, 13990,
	 4490,  2713, 13738,  8966, 15000,  6395,  3405, 10576,
	 1205,  1036,  2209,  6060, 18148, 18035,  7585, 10269,
	 6858,  2592, 14423, 14450, 11457, 12313,  8444,  3772,
	 5289,   983, 10583,  6177,  4409, 15600,  5222, 14601,
	 3401, 18267,  7795,  2801, 12963,  1416, 15901,  2091,
	  728,  1146,  3262,  4426, 14666, 12655,  9707, 13103,
	11287, 16603, 12645, 13778,  7656,  7393, 11618, 11503,
	17131,  5749, 13308, 15480,     2,  5371, 17733,   316
};

static const uint16_t iGMt_cubic[] = {
	    0,     0, 10467, 10693, 11779, 12521, 11471,  8020,
	12449,  4717,  8728,  3544, 12446, 11795,  6342,  4704,
	 8174,  8016,   350, 16007,  5349,  6531, 14648, 14649,
	13869, 15414,  7544,  1323, 16177, 13952, 12162,  5969,
	 3492,   759, 12354, 13802,  9109,  7855, 12811, 10845,
	12767, 10202,  3582,  9615, 10188, 18177, 10769,  5302,
	15342,  5520, 17791,  3186, 12624,  3504, 12736,  3465,
	12416,  8843,   915, 16304,  3714, 11544,  4588,  1694,
	 6287, 17725, 11062,  8327,  1266, 17663, 11510,  8171,
	 5941, 16858,    83,   794,  9221,  7816,  3579, 16693,
	16802,  1720,  5410, 16220,  4735,  5099, 17860,  6289,
	17226,  2889,  4693, 12026,  4363, 16420, 16924,  2665,
	17637, 10152, 18214,   570, 18088,  2918,  2105,  4369,
	13538, 16023,  8495,  6423, 12120, 12896, 17414, 14015,
	 6516, 18139,  2719,  5801,  9586,  6866,  5092, 10735,
	17932,  2314,  7064,  9390,  3048, 16055,  9453,  1152,
	14786,  2422,  5689,  3121,  4417, 18047,  4573,   218,
	 1494, 14292,  8516, 12176,  9123,  5546, 11657, 11576,
	 5215, 15465, 12527,  5019,  8119,  2604, 18050,  6552,
	10742, 13705, 15136, 18429,  9704, 11104,   632, 14263,
	 6300, 11631, 15257, 15589,  5602,  5620,  6960,  2843,
	 3080,  8144,  4182, 13356,  3558, 10940,  9547,  6715,
	 6877,  2049,  7195,  7534,  8052,  7071,  7773,  1737,
	16470, 16977, 11710,  9418,  8852, 12059,  5029, 11909,
	 8112, 12975,   194, 15403, 14446,  5832, 17915, 11701,
	 2737,   199, 14022,  4663,  5424, 13911,   566,  4082,
	  288,  2533,  7860, 17671,  5312, 13950,  9798, 16667,
	 7514, 16804,  9987, 13145, 17753,  6820,  6019, 17160,
	15317,  3060,  4052,   564, 14211,  1141,  3053, 16547,
	16500,  1496, 17137, 16251,  3261, 11208, 12962, 10957,
	 3925, 17560,   362,  6128,  8903,  2331,  8725, 10622,
	 3967, 10633, 15333,  8321, 15822, 15886, 12458,  1916,
	 3463,  1592,  1578,   438,  6526,   690,  4528, 14223,
	 4970,  9790, 14289,  1443,  1552, 12626, 11635,  2038,
	 4813,  5401,  6164, 12995, 12993, 17694, 11286,  8249,
	 5630,  1002,  4652,  4305,  7581, 12337,  1831, 17960,
	 2969, 11968,  8065,   977,  7655, 15932, 11531, 13924,
	 3090,  9128,  5991,  3345, 13983,  4512,  6047, 12542,
	13303, 11332, 12066, 11269, 15978, 16490,  7499, 15328,
	15925,   215, 14501, 11244,  2896, 12158, 11449, 16915,
	 2067,  8003,  3417, 11812,  7403,  2195, 13870,   766,
	 5926, 15382,  6586,  6594,  2800, 17458,  8829, 17169,
	 7163, 15445,  7320,  1401, 11279,   187, 18271, 13552,
	 8827,  9599,  9723,  9287, 13297,  7055,  7294, 13589,
	 8777,  4679,   678,  4043, 16471,  2329,  6361,  2887,
	 1014,  3926, 13849, 13446,  6414,   729, 13760,  8375,
	10128, 12273, 18348, 10069, 14764, 11317, 12769, 17772,
	   36,  7229, 10199,  4513,   664,  6352,  5833, 13604,
	 6207,  9853, 15023, 14683, 10031, 13788,  2644, 16854,
	 7950,  8094,   381,  4311, 11458, 14114,   883,  5782,
	 2729,  6785,  1515,  1612, 15517,  4307,  3366,  3107,
	 9117,  1269,  6885, 13896,  2261,  4973, 16392, 16675,
	12204, 17475, 10490, 18401,  3900, 15100,  5056,  3506,
	 9653,  2399, 15369, 15550,  8051,  3286, 13122,  8268,
	16903, 15345, 18151,  1744,  8646,  6535,   943, 11686,
	17685,  7502,  1091,   443, 12829,  5243,  3738, 10219,
	16139, 17586, 12661, 14518,  4795, 11003, 10281,  1522,
	15673,  4911, 16840, 16519, 16681,  4560,  7484, 13852,
	14425,    79,  1213,  1388,  5951, 17842,  1892,  9216,
	 2956, 18062,  3870, 12148,  3319,  9542, 16081,   819,
	  354, 12714,  5053, 10584,   385,  1018,  5131, 10886,
	10004,  3758, 18036,  8861, 14525,  9919,   870, 11876,
	17573,  7541, 10323, 13028,  6667, 18251,  6072, 15002,
	 7772, 16385, 12420,  5550, 10223,  3188,  7884, 16346
};

/*
 * Reduce a small signed integer modulo q. The source integer MUST
 * be between -q/2 and +q/2.
 */
static inline uint32_t
mq_conv_small(int x, uint32_t q)
{
	/*
	 * If x < 0, the cast to uint32_t will set the high bit to 1.
	 */
	uint32_t y;

	y = (uint32_t)x;
	y += q & -(y >> 31);
	return y;
}

/*
 * Addition modulo q. Operands must be in the 0..q-1 range.
 */
static inline uint32_t
mq_add(uint32_t x, uint32_t y, uint32_t q)
{
	/*
	 * We compute x + y - q. If the result is negative, then the
	 * high bit will be set, and 'd >> 31' will be equal to 1;
	 * thus '-(d >> 31)' will be an all-one pattern. Otherwise,
	 * it will be an all-zero pattern. In other words, this
	 * implements a conditional addition of q.
	 */
	uint32_t d;

	d = x + y - q;
	d += q & -(d >> 31);
	return d;
}

/*
 * Subtraction modulo q. Operands must be in the 0..q-1 range.
 */
static inline uint32_t
mq_sub(uint32_t x, uint32_t y, uint32_t q)
{
	/*
	 * As in mq_add(), we use a conditional addition to ensure the
	 * result is in the 0..q-1 range.
	 */
	uint32_t d;

	d = x - y;
	d += q & -(d >> 31);
	return d;
}

/*
 * Division by 2 modulo q. Operand must be in the 0..q-1 range.
 */
static inline uint32_t
mq_rshift1(uint32_t x, uint32_t q)
{
	x += q & -(x & 1);
	return (x >> 1);
}

/*
 * Montgomery multiplication modulo q. If we set R = 2^16 mod q, then
 * this function computes: x * y / R mod q
 * Operands must be in the 0..q-1 range.
 */
static inline uint32_t
mq_montymul(uint32_t x, uint32_t y, uint32_t q, uint32_t q0i)
{
	uint32_t z, w;

	/*
	 * We compute x*y + k*q with a value of k chosen so that the 16
	 * low bits of the result are 0. We can then shift the value.
	 * After the shift, result may still be larger than q, but it
	 * will be lower than 2*q, so a conditional subtraction works.
	 */

	z = x * y;
	w = ((z * q0i) & 0xFFFF) * q;

	/*
	 * When adding z and w, the result will have its low 16 bits
	 * equal to 0. Since x, y and z are lower than q, the sum will
	 * be no more than (2^15 - 1) * q + (q - 1)^2, which will
	 * fit on 29 bits.
	 */
	z = (z + w) >> 16;

	/*
	 * After the shift, analysis shows that the value will be less
	 * than 2q. We do a subtraction then conditional subtraction to
	 * ensure the result is in the expected range.
	 */
	z -= q;
	z += q & -(z >> 31);
	return z;
}

/*
 * Montgomery squaring (computes (x^2)/R).
 */
static inline uint32_t
mq_montysqr(uint32_t x, uint32_t q, uint32_t q0i)
{
	return mq_montymul(x, x, q, q0i);
}

/*
 * Compute NTT on a ring element, binary case.
 */
static void
mq_NTT_binary(uint16_t *a, unsigned logn)
{
	size_t n, t, m;

	n = (size_t)1 << logn;
	t = n;
	for (m = 1; m < n; m <<= 1) {
		size_t ht, i, j1;

		ht = t >> 1;
		for (i = 0, j1 = 0; i < m; i ++, j1 += t) {
			size_t j, j2;
			uint32_t s;

			s = GMb[m + i];
			j2 = j1 + ht;
			for (j = j1; j < j2; j ++) {
				uint32_t u, v;

				u = a[j];
				v = mq_montymul(a[j + ht], s, Qb, Q0Ib);
				a[j] = (uint16_t)mq_add(u, v, Qb);
				a[j + ht] = (uint16_t)mq_sub(u, v, Qb);
			}
		}
		t = ht;
	}
}

/*
 * Compute the inverse NTT on a ring element, binary case.
 */
static void
mq_iNTT_binary(uint16_t *a, unsigned logn)
{
	size_t n, t, m;
	uint32_t ni;

	n = (size_t)1 << logn;
	t = 1;
	m = n;
	while (m > 1) {
		size_t hm, dt, i, j1;

		hm = m >> 1;
		dt = t << 1;
		for (i = 0, j1 = 0; i < hm; i ++, j1 += dt) {
			size_t j, j2;
			uint32_t s;

			j2 = j1 + t;
			s = iGMb[hm + i];
			for (j = j1; j < j2; j ++) {
				uint32_t u, v, w;

				u = a[j];
				v = a[j + t];
				a[j] = (uint16_t)mq_add(u, v, Qb);
				w = mq_sub(u, v, Qb);
				a[j + t] = (uint16_t)
					mq_montymul(w, s, Qb, Q0Ib);
			}
		}
		t = dt;
		m = hm;
	}

	/*
	 * To complete the inverse NTT, we must now divide all values by
	 * n (the vector size). We thus need the inverse of n, i.e. we
	 * need to divide 1 by 2 logn times. But we also want it in
	 * Montgomery representation, i.e. we also want to multiply it
	 * by R = 2^16. In the common case, this should be a simple right
	 * shift. The loop below is generic and works also in corner cases;
	 * its computation time is negligible.
	 */
	ni = Rb;
	for (m = n; m > 1; m >>= 1) {
		ni = mq_rshift1(ni, Qb);
	}
	for (m = 0; m < n; m ++) {
		a[m] = (uint16_t)mq_montymul(a[m], ni, Qb, Q0Ib);
	}
}

/*
 * Compute NTT on a ring element, ternary case.
 */
static void
mq_NTT_ternary(uint16_t *a, unsigned logn)
{
	size_t n, hn, u, v, t, m;
	uint32_t r, w;

	n = (size_t)3 << (logn - 1);
	hn = n >> 1;

	/*
	 * Modulo X^2-X+1.
	 */
	r = GMt_square[1];
	for (u = 0; u < hn; u ++) {
		uint32_t a0, a1, b;

		a0 = a[u];
		a1 = a[u + hn];
		b = mq_montymul(a1, r, Qt, Q0It);
		a[u] = mq_add(a0, b, Qt);
		a[u + hn] = mq_sub(mq_add(a0, a1, Qt), b, Qt);
	}

	/*
	 * Intermediate steps for degree doubling.
	 */
	t = hn;
	for (m = 2; t > 3; m <<= 1) {
		size_t ht, u1, v1;

		ht = t >> 1;
		for (u1 = 0, v1 = 0; u1 < m; u1 ++, v1 += t) {
			size_t v2;
			uint32_t s;

			s = GMt_square[m + u1];
			v2 = v1 + ht;
			for (v = v1; v < v2; v ++) {
				uint32_t a0, a1;

				a0 = a[v];
				a1 = a[v + ht];
				a1 = mq_montymul(a1, s, Qt, Q0It);
				a[v] = mq_add(a0, a1, Qt);
				a[v + ht] = mq_sub(a0, a1, Qt);
			}
		}
		t = ht;
	}

	/*
	 * Degree tripling.
	 */
	w = mq_montymul(GMt_square[1], GMt_square[1], Qt, Q0It);
	for (u = 0, v = (size_t)1 << (logn - 1); u < n; u += 3, v ++) {
		uint32_t fA, fB, fC, x, x2;
		uint32_t fB0, fB1, fB2, fC0, fC1, fC2;

		fA = a[u + 0];
		fB = a[u + 1];
		fC = a[u + 2];
		x = GMt_cubic[v];
		x2 = mq_montysqr(x, Qt, Q0It);
		fB0 = mq_montymul(fB, x, Qt, Q0It);
		fB1 = mq_montymul(fB0, w, Qt, Q0It);
		fB2 = mq_montymul(fB1, w, Qt, Q0It);
		fC0 = mq_montymul(fC, x2, Qt, Q0It);
		fC1 = mq_montymul(fC0, w, Qt, Q0It);
		fC2 = mq_montymul(fC1, w, Qt, Q0It);
		a[u + 0] = mq_add(fA, mq_add(fB0, fC0, Qt), Qt);
		a[u + 1] = mq_add(fA, mq_add(fB1, fC2, Qt), Qt);
		a[u + 2] = mq_add(fA, mq_add(fB2, fC1, Qt), Qt);
	}
}

/*
 * Compute the inverse NTT on a ring element, ternary case.
 */
static void
mq_iNTT_ternary(uint16_t *a, unsigned logn)
{
	size_t n, hn, u, v, t, m;
	uint32_t r, w, ni;

	n = (size_t)3 << (logn - 1);
	hn = n >> 1;

	/*
	 * Dividing degree by 3.
	 */
	w = mq_montymul(iGMt_square[1], iGMt_square[1], Qt, Q0It);
	for (u = 0, v = (size_t)1 << (logn - 1); u < n; u += 3, v ++) {
		uint32_t f0, f1, f2, x, x2;
		uint32_t f11, f12, f21, f22;

		f0 = a[u + 0];
		f1 = a[u + 1];
		f2 = a[u + 2];
		x = iGMt_cubic[v];
		x2 = mq_montysqr(x, Qt, Q0It);
		f11 = mq_montymul(f1, w, Qt, Q0It);
		f12 = mq_montymul(f11, w, Qt, Q0It);
		f21 = mq_montymul(f2, w, Qt, Q0It);
		f22 = mq_montymul(f21, w, Qt, Q0It);
		a[u + 0] = mq_add(f0, mq_add(f1, f2, Qt), Qt);
		a[u + 1] = mq_montymul(x,
			mq_add(f0, mq_add(f11, f22, Qt), Qt), Qt, Q0It);
		a[u + 2] = mq_montymul(x2,
			mq_add(f0, mq_add(f12, f21, Qt), Qt), Qt, Q0It);
	}

	/*
	 * Intermediate steps for degree halving.
	 */
	t = 6;
	for (m = (size_t)1 << (logn - 2); t < n; m >>= 1) {
		size_t ht, u1, v1;

		ht = t >> 1;
		for (u1 = 0, v1 = 0; u1 < m; u1 ++, v1 += t) {
			size_t v2;
			uint32_t s;

			s = iGMt_square[m + u1];
			v2 = v1 + ht;
			for (v = v1; v < v2; v ++) {
				uint32_t a0, a1;

				a0 = a[v];
				a1 = a[v + ht];
				a[v] = mq_add(a0, a1, Qt);
				a[v + ht] = mq_montymul(
					mq_sub(a0, a1, Qt), s, Qt, Q0It);
			}
		}
		t <<= 1;
	}

	/*
	 * Modulo X^2-X+1.
	 */
	r = iGMt_square[0];
	for (u = 0; u < hn; u ++) {
		uint32_t a0, a1, b;

		a0 = a[u];
		a1 = a[u + hn];
		b = mq_montymul(r, mq_sub(a0, a1, Qt), Qt, Q0It);
		a[u] = mq_sub(mq_add(a0, a1, Qt), b, Qt);
		a[u + hn] = mq_add(b, b, Qt);
	}

	/*
	 * Corrective factor: all values have been (cumulatively)
	 * multiplied by n. Inverses of n modulo q have been precomputed.
	 */
	ni = INVNQt[logn];
	for (u = 0; u < n; u ++) {
		a[u] = mq_montymul(a[u], ni, Qt, Q0It);
	}
}

static void
mq_NTT(uint16_t *a, unsigned logn, int ternary)
{
	if (ternary) {
		mq_NTT_ternary(a, logn);
	} else {
		mq_NTT_binary(a, logn);
	}
}

static void
mq_iNTT(uint16_t *a, unsigned logn, int ternary)
{
	if (ternary) {
		mq_iNTT_ternary(a, logn);
	} else {
		mq_iNTT_binary(a, logn);
	}
}

/*
 * Divide x by y modulo q = 12289.
 */
static inline uint32_t
mq_div_12289(uint32_t x, uint32_t y)
{
	/*
	 * We invert y by computing y^(q-2) mod q.
	 *
	 * We use the following addition chain for exponent e = 12287:
	 *
	 *   e0 = 1
	 *   e1 = 2 * e0 = 2
	 *   e2 = e1 + e0 = 3
	 *   e3 = e2 + e1 = 5
	 *   e4 = 2 * e3 = 10
	 *   e5 = 2 * e4 = 20
	 *   e6 = 2 * e5 = 40
	 *   e7 = 2 * e6 = 80
	 *   e8 = 2 * e7 = 160
	 *   e9 = e8 + e2 = 163
	 *   e10 = e9 + e8 = 323
	 *   e11 = 2 * e10 = 646
	 *   e12 = 2 * e11 = 1292
	 *   e13 = e12 + e9 = 1455
	 *   e14 = 2 * e13 = 2910
	 *   e15 = 2 * e14 = 5820
	 *   e16 = e15 + e10 = 6143
	 *   e17 = 2 * e16 = 12286
	 *   e18 = e17 + e0 = 12287
	 *
	 * Additions on exponents are converted to Montgomery
	 * multiplications. We define all intermediate results as so
	 * many local variables, and let the C compiler work out which
	 * must be kept around.
	 */
	uint32_t y0, y1, y2, y3, y4, y5, y6, y7, y8, y9;
	uint32_t y10, y11, y12, y13, y14, y15, y16, y17, y18;

	y0 = mq_montymul(y, R2b, Qb, Q0Ib);
	y1 = mq_montysqr(y0, Qb, Q0Ib);
	y2 = mq_montymul(y1, y0, Qb, Q0Ib);
	y3 = mq_montymul(y2, y1, Qb, Q0Ib);
	y4 = mq_montysqr(y3, Qb, Q0Ib);
	y5 = mq_montysqr(y4, Qb, Q0Ib);
	y6 = mq_montysqr(y5, Qb, Q0Ib);
	y7 = mq_montysqr(y6, Qb, Q0Ib);
	y8 = mq_montysqr(y7, Qb, Q0Ib);
	y9 = mq_montymul(y8, y2, Qb, Q0Ib);
	y10 = mq_montymul(y9, y8, Qb, Q0Ib);
	y11 = mq_montysqr(y10, Qb, Q0Ib);
	y12 = mq_montysqr(y11, Qb, Q0Ib);
	y13 = mq_montymul(y12, y9, Qb, Q0Ib);
	y14 = mq_montysqr(y13, Qb, Q0Ib);
	y15 = mq_montysqr(y14, Qb, Q0Ib);
	y16 = mq_montymul(y15, y10, Qb, Q0Ib);
	y17 = mq_montysqr(y16, Qb, Q0Ib);
	y18 = mq_montymul(y17, y0, Qb, Q0Ib);

	/*
	 * Final multiplication with x, which is not in Montgomery
	 * representation, computes the correct division result.
	 */
	return mq_montymul(y18, x, Qb, Q0Ib);
}

/*
 * Divide x by y modulo q = 18433.
 */
static inline uint32_t
mq_div_18433(uint32_t x, uint32_t y)
{
	/*
	 * We invert y by computing y^(q-2) mod q.
	 *
	 * We use the following addition chain for exponent e = 18431:
	 *
	 *   e0             = 1
	 *   e1  = 2 * e0   = 2
	 *   e2  = e1 + e0  = 3
	 *   e3  = 2 * e2   = 6
	 *   e4  = e3 + e0  = 7
	 *   e5  = 2 * e4   = 14
	 *   e6  = 2 * e5   = 28
	 *   e7  = e6 + e4  = 35
	 *   e8  = e7 + e6  = 63
	 *   e9  = 2 * e8   = 126
	 *   e10 = 2 * e9   = 252
	 *   e11 = e10 + e7 = 287
	 *   e12 = 2 * e11  = 574
	 *   e13 = 2 * e12  = 1148
	 *   e14 = 2 * e13  = 2296
	 *   e15 = 2 * e14  = 4592
	 *   e16 = 2 * e15  = 9184
	 *   e17 = 2 * e16  = 18368
	 *   e18 = e17 + e8 = 18431
	 *
	 * Additions on exponents are converted to Montgomery
	 * multiplications. We define all intermediate results as so
	 * many local variables, and let the C compiler work out which
	 * must be kept around.
	 */
	uint32_t y0, y1, y2, y3, y4, y5, y6, y7, y8, y9;
	uint32_t y10, y11, y12, y13, y14, y15, y16, y17, y18;

	y0  = mq_montymul(y, R2t, Qt, Q0It);          
	y1  = mq_montysqr(y0, Qt, Q0It);
	y2  = mq_montymul(y1, y0, Qt, Q0It);
	y3  = mq_montysqr(y2, Qt, Q0It);
	y4  = mq_montymul(y3, y0, Qt, Q0It);
	y5  = mq_montysqr(y4, Qt, Q0It);
	y6  = mq_montysqr(y5, Qt, Q0It);
	y7  = mq_montymul(y6, y4, Qt, Q0It);
	y8  = mq_montymul(y7, y6, Qt, Q0It);
	y9  = mq_montysqr(y8, Qt, Q0It);
	y10 = mq_montysqr(y9, Qt, Q0It);
	y11 = mq_montymul(y10, y7, Qt, Q0It);
	y12 = mq_montysqr(y11, Qt, Q0It);
	y13 = mq_montysqr(y12, Qt, Q0It);
	y14 = mq_montysqr(y13, Qt, Q0It);
	y15 = mq_montysqr(y14, Qt, Q0It);
	y16 = mq_montysqr(y15, Qt, Q0It);
	y17 = mq_montysqr(y16, Qt, Q0It);
	y18 = mq_montymul(y17, y8, Qt, Q0It);

	/*
	 * Final multiplication with x, which is not in Montgomery
	 * representation, computes the correct division result.
	 */
	return mq_montymul(y18, x, Qt, Q0It);
}


/* see internal.h */
int
falcon_compute_public(uint16_t *h,
	const int16_t *f, const int16_t *g, unsigned logn, int ternary)
{
	size_t u, n;
	uint16_t t[1024];
	uint32_t q;

	if (ternary) {
		n = (size_t)3 << (logn - 1);
		q = Qt;
	} else {
		n = (size_t)1 << logn;
		q = Qb;
	}
	for (u = 0; u < n; u ++) {
		t[u] = mq_conv_small(f[u], q);
		h[u] = mq_conv_small(g[u], q);
	}
	mq_NTT(h, logn, ternary);
	mq_NTT(t, logn, ternary);
	for (u = 0; u < n; u ++) {
		if (t[u] == 0) {
			return 0;
		}
		h[u] = ternary
			? mq_div_18433(h[u], t[u])
			: mq_div_12289(h[u], t[u]);
	}
	mq_iNTT(h, logn, ternary);
	return 1;
}












/* ==================================================================== */
/*
 * Compute resultant of polynomial f with phi, modulo 2. This function
 * is for phi = X^N-X(N/2)+1, where N = 1.5*2^logn.
 */
static unsigned
mod2_res_ternary(const int16_t *f, unsigned logn)
{
	/*
	 * We lower down the degree to 6, by successive degree halving:
	 * we replace f with N(f). If:
	 *   f = f0(x^2) + x*f1(x^2)
	 * with f0 and f1 taken modulo X^(N/2)-(X^N/4)+1, then:
	 *   N(f) = f0^2 - x*f1^2
	 *
	 * From f expressed as an array of bits:
	 *   - f0 and f1 are obtained by extracting bits at even and
	 *     odd indexes, respectively;
	 *   - the "holes" are squeezed out to get down to degree N/2;
	 *   - squarings (f0^2 and f1^2) compute the exact opposite of
	 *     that "squeezing out", so in practice we skip both; but
	 *     we must reduce modulo X^(N/2)-X^(N/4)+1.
	 */

	uint32_t b[24];
	size_t u, n;

	/*
	 * Extract bits into an array of 32-bit words.
	 */
	n = MKN(logn, 1);
	memset(b, 0, sizeof b);
	for (u = 0; u < n; u ++) {
		uint32_t bit;

		bit = (uint32_t)f[u] & 1;
		b[u >> 5] |= bit << (u & 31);
	}

	/*
	 * Halve the degree repeatedly.
	 *
	 * If the input is: a0 || a1 || a2 || a3
	 * Then we must compute: (a0 XOR a2 XOR a3) || (a1 XOR a2)
	 */
	switch (logn) {
	case 9:
		/*
		 * a0 = b[0..5]
		 * a1 = b[6..11]
		 * a2 = b[12..17]
		 * a3 = b[18..23]
		 */
		b[0] ^= b[12] ^ b[18];
		b[1] ^= b[13] ^ b[19];
		b[2] ^= b[14] ^ b[20];
		b[3] ^= b[15] ^ b[21];
		b[4] ^= b[16] ^ b[22];
		b[5] ^= b[17] ^ b[23];
		b[6] ^= b[12];
		b[7] ^= b[13];
		b[8] ^= b[14];
		b[9] ^= b[15];
		b[10] ^= b[16];
		b[11] ^= b[17];
		/* fall through */
	case 8:
		/*
		 * a0 = b[0..2]
		 * a1 = b[3..5]
		 * a2 = b[6..8]
		 * a3 = b[9..11]
		 */
		b[0] ^= b[6] ^ b[9];
		b[1] ^= b[7] ^ b[10];
		b[2] ^= b[8] ^ b[11];
		b[3] ^= b[6];
		b[4] ^= b[7];
		b[5] ^= b[8];
		/* fall through */
	case 7:
		/*
		 * a0 = b[0] || b[1](0..15)
		 * a1 = b[1](16..31) || b[2]
		 * a2 = b[3] || b[4](0..15)
		 * a3 = b[4](16..31) || b[5]
		 */
		b[0] ^= b[3] ^ (b[4] >> 16) ^ (b[5] << 16);
		b[1] ^= (b[4] & 0xFFFF) ^ (b[5] >> 16);
		b[1] ^= (b[3] << 16);
		b[2] ^= (b[3] >> 16) ^ (b[4] << 16);
		/* fall through */
	case 6:
		/*
		 * a0 = b[0](0..23)
		 * a1 = b[0](24..31) || b[1](0..15)
		 * a2 = b[1](16..31) || b[2](0..7)
		 * a3 = b[2](8..31)
		 */
		b[0] ^= (b[1] >> 16) ^ ((b[2] & 0xFF) << 16) ^ (b[2] >> 8);
		b[0] ^= ((b[1] << 8) & 0xFF000000);
		b[1] ^= (b[1] >> 24) ^ ((b[2] & 0xFF) << 8);
		b[1] &= 0xFFFF;
		/* fall through */
	case 5:
		/*
		 * a0 = b[0](0..11)
		 * a1 = b[0](12..23)
		 * a2 = b[0](24..31) || b[1](0..3)
		 * a3 = b[1](4..15)
		 */
		b[0] ^= (b[0] >> 24) ^ ((b[1] & 0x0F) << 8) ^ (b[1] >> 4);
		b[0] ^= ((b[0] >> 12) & 0xFF000) ^ ((b[1] & 0x0F) << 20);
		b[0] &= 0xFFFFFF;
		/* fall through */
	case 4:
		/*
		 * a0 = b[0](0..5)
		 * a1 = b[0](6..11)
		 * a2 = b[0](12..17)
		 * a3 = b[0](18..23)
		 */
		b[0] ^= ((b[0] >> 12) & 0x3F) ^ ((b[0] >> 18) & 0x3F);
		b[0] ^= ((b[0] >> 6) & 0xFC0);
		b[0] &= 0xFFF;
		/* fall through */
	case 3:
		/*
		 * a0 = b[0](0..2)
		 * a1 = b[0](3..5)
		 * a2 = b[0](6..8)
		 * a3 = b[0](9..11)
		 */
		b[0] ^= ((b[0] >> 6) & 0x7) ^ ((b[0] >> 9) & 0x7);
		b[0] ^= ((b[0] >> 3) & 0x38);
		b[0] &= 0x3F;
		/* fall through */
	case 2:
		break;
	}

	/*
	 * When we are done to phi = X^6-X^3+1, we have only 64
	 * possibilities. It turns out that all of them except 0 yield
	 * a resultant of value 1 with phi (modulo 2).
	 */
	return b[0] != 0;
}

/* ==================================================================== */
/*
 * Modular arithmetics.
 *
 * We implement a few functions for computing modulo a small integer p.
 *
 * All functions require that 2^30 < p < 2^31. Moreover, operands must
 * be in the 0..p-1 range.
 *
 * Modular addition and subtraction work for all such p.
 *
 * Montgomery multiplication requires that p is odd, and must be provided
 * with an additional value p0i = -1/p mod 2^31. See below for some basics
 * on Montgomery multiplication.
 *
 * Division computes an inverse modulo p by an exponentiation (with
 * exponent p-2): this works only if p is prime. Multiplication
 * requirements also apply, i.e. p must be odd and p0i must be provided.
 *
 * The NTT and inverse NTT need all of the above, and also that
 * p = 1 mod 2048 (binary case) or p = 1 mod 2304 (ternary case).
 *
 * -----------------------------------------------------------------------
 *
 * We use Montgomery representation with 31-bit values:
 *
 *   Let R = 2^31 mod p. When p > 2^30, R = 2^31 - p.
 *   Montgomery representation of an integer x modulo p is x*R mod p.
 *
 *   Montgomery multiplication computes (x*y)/R mod p for
 *   operands x and y. Therefore:
 *
 *    - if operands are x*R and y*R (Montgomery representations of x and y),
 *      then Montgomery multiplication computes (x*R*y*R)/R = (x*y)*R mod p,
 *      which is the Montgomery representation of the product x*y;
 *
 *    - if operands are x*R and y (or x and y*R), then Montgomery
 *      representation returns x*y mod p: mixed-representation
 *      multiplications yield results in normal representation.
 *
 * To convert to Montgomery representation, we multiply by R, which is done
 * by Montgomery-multiplying by R^2. Stand-alone conversion back from
 * Montgomery representation is Montgomery-multiplication by 1.
 */

/*
 * Precomputed small primes. Each element contains the following:
 *
 *  p   The prime itself.
 *
 *  g   A primitive root of phi = X^N+1 or phi = X^N-X^(N/2)+1.
 *
 *  s   The inverse of the product of all previous primes in the array,
 *      computed modulo p and in Montgomery representation.
 *
 * All primes are such that p = 1 mod 2048, and are lower than 2^31. They
 * are listed in decreasing order.
 */

typedef struct {
	uint32_t p;
	uint32_t g;
	uint32_t s;
} small_prime;

static const small_prime PRIMES2[] = {
	{ 2147473409,  383167813,      10239 },
	{ 2147389441,  211808905,  471403745 },
	{ 2147387393,   37672282, 1329335065 },
	{ 2147377153, 1977035326,  968223422 },
	{ 2147358721, 1067163706,  132460015 },
	{ 2147352577, 1606082042,  598693809 },
	{ 2147346433, 2033915641, 1056257184 },
	{ 2147338241, 1653770625,  421286710 },
	{ 2147309569,  631200819, 1111201074 },
	{ 2147297281, 2038364663, 1042003613 },
	{ 2147295233, 1962540515,   19440033 },
	{ 2147239937, 2100082663,  353296760 },
	{ 2147235841, 1991153006, 1703918027 },
	{ 2147217409,  516405114, 1258919613 },
	{ 2147205121,  409347988, 1089726929 },
	{ 2147196929,  927788991, 1946238668 },
	{ 2147178497, 1136922411, 1347028164 },
	{ 2147100673,  868626236,  701164723 },
	{ 2147082241, 1897279176,  617820870 },
	{ 2147074049, 1888819123,  158382189 },
	{ 2147051521,   25006327,  522758543 },
	{ 2147043329,  327546255,   37227845 },
	{ 2147039233,  766324424, 1133356428 },
	{ 2146988033, 1862817362,   73861329 },
	{ 2146963457,  404622040,  653019435 },
	{ 2146959361, 1936581214,  995143093 },
	{ 2146938881, 1559770096,  634921513 },
	{ 2146908161,  422623708, 1985060172 },
	{ 2146885633, 1751189170,  298238186 },
	{ 2146871297,  578919515,  291810829 },
	{ 2146846721, 1114060353,  915902322 },
	{ 2146834433, 2069565474,   47859524 },
	{ 2146818049, 1552824584,  646281055 },
	{ 2146775041, 1906267847, 1597832891 },
	{ 2146756609, 1847414714, 1228090888 },
	{ 2146744321, 1818792070, 1176377637 },
	{ 2146738177, 1118066398, 1054971214 },
	{ 2146736129,   52057278,  933422153 },
	{ 2146713601,  592259376, 1406621510 },
	{ 2146695169,  263161877, 1514178701 },
	{ 2146656257,  685363115,  384505091 },
	{ 2146650113,  927727032,  537575289 },
	{ 2146646017,   52575506, 1799464037 },
	{ 2146643969, 1276803876, 1348954416 },
	{ 2146603009,  814028633, 1521547704 },
	{ 2146572289, 1846678872, 1310832121 },
	{ 2146547713,  919368090, 1019041349 },
	{ 2146508801,  671847612,   38582496 },
	{ 2146492417,  283911680,  532424562 },
	{ 2146490369, 1780044827,  896447978 },
	{ 2146459649,  327980850, 1327906900 },
	{ 2146447361, 1310561493,  958645253 },
	{ 2146441217,  412148926,  287271128 },
	{ 2146437121,  293186449, 2009822534 },
	{ 2146430977,  179034356, 1359155584 },
	{ 2146418689, 1517345488, 1790248672 },
	{ 2146406401, 1615820390, 1584833571 },
	{ 2146404353,  826651445,  607120498 },
	{ 2146379777,    3816988, 1897049071 },
	{ 2146363393, 1221409784, 1986921567 },
	{ 2146355201, 1388081168,  849968120 },
	{ 2146336769, 1803473237, 1655544036 },
	{ 2146312193, 1023484977,  273671831 },
	{ 2146293761, 1074591448,  467406983 },
	{ 2146283521,  831604668, 1523950494 },
	{ 2146203649,  712865423, 1170834574 },
	{ 2146154497, 1764991362, 1064856763 },
	{ 2146142209,  627386213, 1406840151 },
	{ 2146127873, 1638674429, 2088393537 },
	{ 2146099201, 1516001018,  690673370 },
	{ 2146093057, 1294931393,  315136610 },
	{ 2146091009, 1942399533,  973539425 },
	{ 2146078721, 1843461814, 2132275436 },
	{ 2146060289, 1098740778,  360423481 },
	{ 2146048001, 1617213232, 1951981294 },
	{ 2146041857, 1805783169, 2075683489 },
	{ 2146019329,  272027909, 1753219918 },
	{ 2145986561, 1206530344, 2034028118 },
	{ 2145976321, 1243769360, 1173377644 },
	{ 2145964033,  887200839, 1281344586 },
	{ 2145906689, 1651026455,  906178216 },
	{ 2145875969, 1673238256, 1043521212 },
	{ 2145871873, 1226591210, 1399796492 },
	{ 2145841153, 1465353397, 1324527802 },
	{ 2145832961, 1150638905,  554084759 },
	{ 2145816577,  221601706,  427340863 },
	{ 2145785857,  608896761,  316590738 },
	{ 2145755137, 1712054942, 1684294304 },
	{ 2145742849, 1302302867,  724873116 },
	{ 2145728513,  516717693,  431671476 },
	{ 2145699841,  524575579, 1619722537 },
	{ 2145691649, 1925625239,  982974435 },
	{ 2145687553,  463795662, 1293154300 },
	{ 2145673217,  771716636,  881778029 },
	{ 2145630209, 1509556977,  837364988 },
	{ 2145595393,  229091856,  851648427 },
	{ 2145587201, 1796903241,  635342424 },
	{ 2145525761,  715310882, 1677228081 },
	{ 2145495041, 1040930522,  200685896 },
	{ 2145466369,  949804237, 1809146322 },
	{ 2145445889, 1673903706,   95316881 },
	{ 2145390593,  806941852, 1428671135 },
	{ 2145372161, 1402525292,  159350694 },
	{ 2145361921, 2124760298, 1589134749 },
	{ 2145359873, 1217503067, 1561543010 },
	{ 2145355777,  338341402,   83865711 },
	{ 2145343489, 1381532164,  641430002 },
	{ 2145325057, 1883895478, 1528469895 },
	{ 2145318913, 1335370424,   65809740 },
	{ 2145312769, 2000008042, 1919775760 },
	{ 2145300481,  961450962, 1229540578 },
	{ 2145282049,  910466767, 1964062701 },
	{ 2145232897,  816527501,  450152063 },
	{ 2145218561, 1435128058, 1794509700 },
	{ 2145187841,   33505311, 1272467582 },
	{ 2145181697,  269767433, 1380363849 },
	{ 2145175553,   56386299, 1316870546 },
	{ 2145079297, 2106880293, 1391797340 },
	{ 2145021953, 1347906152,  720510798 },
	{ 2145015809,  206769262, 1651459955 },
	{ 2145003521, 1885513236, 1393381284 },
	{ 2144960513, 1810381315,   31937275 },
	{ 2144944129, 1306487838, 2019419520 },
	{ 2144935937,   37304730, 1841489054 },
	{ 2144894977, 1601434616,  157985831 },
	{ 2144888833,   98749330, 2128592228 },
	{ 2144880641, 1772327002, 2076128344 },
	{ 2144864257, 1404514762, 2029969964 },
	{ 2144827393,  801236594,  406627220 },
	{ 2144806913,  349217443, 1501080290 },
	{ 2144796673, 1542656776, 2084736519 },
	{ 2144778241, 1210734884, 1746416203 },
	{ 2144759809, 1146598851,  716464489 },
	{ 2144757761,  286328400, 1823728177 },
	{ 2144729089, 1347555695, 1836644881 },
	{ 2144727041, 1795703790,  520296412 },
	{ 2144696321, 1302475157,  852964281 },
	{ 2144667649, 1075877614,  504992927 },
	{ 2144573441,  198765808, 1617144982 },
	{ 2144555009,  321528767,  155821259 },
	{ 2144550913,  814139516, 1819937644 },
	{ 2144536577,  571143206,  962942255 },
	{ 2144524289, 1746733766,    2471321 },
	{ 2144512001, 1821415077,  124190939 },
	{ 2144468993,  917871546, 1260072806 },
	{ 2144458753,  378417981, 1569240563 },
	{ 2144421889,  175229668, 1825620763 },
	{ 2144409601, 1699216963,  351648117 },
	{ 2144370689, 1071885991,  958186029 },
	{ 2144348161, 1763151227,  540353574 },
	{ 2144335873, 1060214804,  919598847 },
	{ 2144329729,  663515846, 1448552668 },
	{ 2144327681, 1057776305,  590222840 },
	{ 2144309249, 1705149168, 1459294624 },
	{ 2144296961,  325823721, 1649016934 },
	{ 2144290817,  738775789,  447427206 },
	{ 2144243713,  962347618,  893050215 },
	{ 2144237569, 1655257077,  900860862 },
	{ 2144161793,  242206694, 1567868672 },
	{ 2144155649,  769415308, 1247993134 },
	{ 2144137217,  320492023,  515841070 },
	{ 2144120833, 1639388522,  770877302 },
	{ 2144071681, 1761785233,  964296120 },
	{ 2144065537,  419817825,  204564472 },
	{ 2144028673,  666050597, 2091019760 },
	{ 2144010241, 1413657615, 1518702610 },
	{ 2143952897, 1238327946,  475672271 },
	{ 2143940609,  307063413, 1176750846 },
	{ 2143918081, 2062905559,  786785803 },
	{ 2143899649, 1338112849, 1562292083 },
	{ 2143891457,   68149545,   87166451 },
	{ 2143885313,  921750778,  394460854 },
	{ 2143854593,  719766593,  133877196 },
	{ 2143836161, 1149399850, 1861591875 },
	{ 2143762433, 1848739366, 1335934145 },
	{ 2143756289, 1326674710,  102999236 },
	{ 2143713281,  808061791, 1156900308 },
	{ 2143690753,  388399459, 1926468019 },
	{ 2143670273, 1427891374, 1756689401 },
	{ 2143666177, 1912173949,  986629565 },
	{ 2143645697, 2041160111,  371842865 },
	{ 2143641601, 1279906897, 2023974350 },
	{ 2143635457,  720473174, 1389027526 },
	{ 2143621121, 1298309455, 1732632006 },
	{ 2143598593, 1548762216, 1825417506 },
	{ 2143567873,  620475784, 1073787233 },
	{ 2143561729, 1932954575,  949167309 },
	{ 2143553537,  354315656, 1652037534 },
	{ 2143541249,  577424288, 1097027618 },
	{ 2143531009,  357862822,  478640055 },
	{ 2143522817, 2017706025, 1550531668 },
	{ 2143506433, 2078127419, 1824320165 },
	{ 2143488001,  613475285, 1604011510 },
	{ 2143469569, 1466594987,  502095196 },
	{ 2143426561, 1115430331, 1044637111 },
	{ 2143383553,    9778045, 1902463734 },
	{ 2143377409, 1557401276, 2056861771 },
	{ 2143363073,  652036455, 1965915971 },
	{ 2143260673, 1464581171, 1523257541 },
	{ 2143246337, 1876119649,  764541916 },
	{ 2143209473, 1614992673, 1920672844 },
	{ 2143203329,  981052047, 2049774209 },
	{ 2143160321, 1847355533,  728535665 },
	{ 2143129601,  965558457,  603052992 },
	{ 2143123457, 2140817191,    8348679 },
	{ 2143100929, 1547263683,  694209023 },
	{ 2143092737,  643459066, 1979934533 },
	{ 2143082497,  188603778, 2026175670 },
	{ 2143062017, 1657329695,  377451099 },
	{ 2143051777,  114967950,  979255473 },
	{ 2143025153, 1698431342, 1449196896 },
	{ 2143006721, 1862741675, 1739650365 },
	{ 2142996481,  756660457,  996160050 },
	{ 2142976001,  927864010, 1166847574 },
	{ 2142965761,  905070557,  661974566 },
	{ 2142916609,   40932754, 1787161127 },
	{ 2142892033, 1987985648,  675335382 },
	{ 2142885889,  797497211, 1323096997 },
	{ 2142871553, 2068025830, 1411877159 },
	{ 2142861313, 1217177090, 1438410687 },
	{ 2142830593,  409906375, 1767860634 },
	{ 2142803969, 1197788993,  359782919 },
	{ 2142785537,  643817365,  513932862 },
	{ 2142779393, 1717046338,  218943121 },
	{ 2142724097,   89336830,  416687049 },
	{ 2142707713,    5944581, 1356813523 },
	{ 2142658561,  887942135, 2074011722 },
	{ 2142638081,  151851972, 1647339939 },
	{ 2142564353, 1691505537, 1483107336 },
	{ 2142533633, 1989920200, 1135938817 },
	{ 2142529537,  959263126, 1531961857 },
	{ 2142527489,  453251129, 1725566162 },
	{ 2142502913, 1536028102,  182053257 },
	{ 2142498817,  570138730,  701443447 },
	{ 2142416897,  326965800,  411931819 },
	{ 2142363649, 1675665410, 1517191733 },
	{ 2142351361,  968529566, 1575712703 },
	{ 2142330881, 1384953238, 1769087884 },
	{ 2142314497, 1977173242, 1833745524 },
	{ 2142289921,   95082313, 1714775493 },
	{ 2142283777,  109377615, 1070584533 },
	{ 2142277633,   16960510,  702157145 },
	{ 2142263297,  553850819,  431364395 },
	{ 2142208001,  241466367, 2053967982 },
	{ 2142164993, 1795661326, 1031836848 },
	{ 2142097409, 1212530046,  712772031 },
	{ 2142087169, 1763869720,  822276067 },
	{ 2142078977,  644065713, 1765268066 },
	{ 2142074881,  112671944,  643204925 },
	{ 2142044161, 1387785471, 1297890174 },
	{ 2142025729,  783885537, 1000425730 },
	{ 2142011393,  905662232, 1679401033 },
	{ 2141974529,  799788433,  468119557 },
	{ 2141943809, 1932544124,  449305555 },
	{ 2141933569, 1527403256,  841867925 },
	{ 2141931521, 1247076451,  743823916 },
	{ 2141902849, 1199660531,  401687910 },
	{ 2141890561,  150132350, 1720336972 },
	{ 2141857793, 1287438162,  663880489 },
	{ 2141833217,  618017731, 1819208266 },
	{ 2141820929,  999578638, 1403090096 },
	{ 2141786113,   81834325, 1523542501 },
	{ 2141771777,  120001928,  463556492 },
	{ 2141759489,  122455485, 2124928282 },
	{ 2141749249,  141986041,  940339153 },
	{ 2141685761,  889088734,  477141499 },
	{ 2141673473,  324212681, 1122558298 },
	{ 2141669377, 1175806187, 1373818177 },
	{ 2141655041, 1113654822,  296887082 },
	{ 2141587457,  991103258, 1585913875 },
	{ 2141583361, 1401451409, 1802457360 },
	{ 2141575169, 1571977166,  712760980 },
	{ 2141546497, 1107849376, 1250270109 },
	{ 2141515777,  196544219,  356001130 },
	{ 2141495297, 1733571506, 1060744866 },
	{ 2141483009,  321552363, 1168297026 },
	{ 2141458433,  505818251,  733225819 },
	{ 2141360129, 1026840098,  948342276 },
	{ 2141325313,  945133744, 2129965998 },
	{ 2141317121, 1871100260, 1843844634 },
	{ 2141286401, 1790639498, 1750465696 },
	{ 2141267969, 1376858592,  186160720 },
	{ 2141255681, 2129698296, 1876677959 },
	{ 2141243393, 2138900688, 1340009628 },
	{ 2141214721, 1933049835, 1087819477 },
	{ 2141212673, 1898664939, 1786328049 },
	{ 2141202433,  990234828,  940682169 },
	{ 2141175809, 1406392421,  993089586 },
	{ 2141165569, 1263518371,  289019479 },
	{ 2141073409, 1485624211,  507864514 },
	{ 2141052929, 1885134788,  311252465 },
	{ 2141040641, 1285021247,  280941862 },
	{ 2141028353, 1527610374,  375035110 },
	{ 2141011969, 1400626168,  164696620 },
	{ 2140999681,  632959608,  966175067 },
	{ 2140997633, 2045628978, 1290889438 },
	{ 2140993537, 1412755491,  375366253 },
	{ 2140942337,  719477232,  785367828 },
	{ 2140925953,   45224252,  836552317 },
	{ 2140917761, 1157376588, 1001839569 },
	{ 2140887041,  278480752, 2098732796 },
	{ 2140837889, 1663139953,  924094810 },
	{ 2140788737,  802501511, 2045368990 },
	{ 2140766209, 1820083885, 1800295504 },
	{ 2140764161, 1169561905, 2106792035 },
	{ 2140696577,  127781498, 1885987531 },
	{ 2140684289,   16014477, 1098116827 },
	{ 2140653569,  665960598, 1796728247 },
	{ 2140594177, 1043085491,  377310938 },
	{ 2140579841, 1732838211, 1504505945 },
	{ 2140569601,  302071939,  358291016 },
	{ 2140567553,  192393733, 1909137143 },
	{ 2140557313,  406595731, 1175330270 },
	{ 2140549121, 1748850918,  525007007 },
	{ 2140477441,  499436566, 1031159814 },
	{ 2140469249, 1886004401, 1029951320 },
	{ 2140426241, 1483168100, 1676273461 },
	{ 2140420097, 1779917297,  846024476 },
	{ 2140413953,  522948893, 1816354149 },
	{ 2140383233, 1931364473, 1296921241 },
	{ 2140366849, 1917356555,  147196204 },
	{ 2140354561,   16466177, 1349052107 },
	{ 2140348417, 1875366972, 1860485634 },
	{ 2140323841,  456498717, 1790256483 },
	{ 2140321793, 1629493973,  150031888 },
	{ 2140315649, 1904063898,  395510935 },
	{ 2140280833, 1784104328,  831417909 },
	{ 2140250113,  256087139,  697349101 },
	{ 2140229633,  388553070,  243875754 },
	{ 2140223489,  747459608, 1396270850 },
	{ 2140200961,  507423743, 1895572209 },
	{ 2140162049,  580106016, 2045297469 },
	{ 2140149761,  712426444,  785217995 },
	{ 2140137473, 1441607584,  536866543 },
	{ 2140119041,  346538902, 1740434653 },
	{ 2140090369,  282642885,   21051094 },
	{ 2140076033, 1407456228,  319910029 },
	{ 2140047361, 1619330500, 1488632070 },
	{ 2140041217, 2089408064, 2012026134 },
	{ 2140008449, 1705524800, 1613440760 },
	{ 2139924481, 1846208233, 1280649481 },
	{ 2139906049,  989438755, 1185646076 },
	{ 2139867137, 1522314850,  372783595 },
	{ 2139842561, 1681587377,  216848235 },
	{ 2139826177, 2066284988, 1784999464 },
	{ 2139824129,  480888214, 1513323027 },
	{ 2139789313,  847937200,  858192859 },
	{ 2139783169, 1642000434, 1583261448 },
	{ 2139770881,  940699589,  179702100 },
	{ 2139768833,  315623242,  964612676 },
	{ 2139666433,  331649203,  764666914 },
	{ 2139641857, 2118730799, 1313764644 },
	{ 2139635713,  519149027,  519212449 },
	{ 2139598849, 1526413634, 1769667104 },
	{ 2139574273,  551148610,  820739925 },
	{ 2139568129, 1386800242,  472447405 },
	{ 2139549697,  813760130, 1412328531 },
	{ 2139537409, 1615286260, 1609362979 },
	{ 2139475969, 1352559299, 1696720421 },
	{ 2139455489, 1048691649, 1584935400 },
	{ 2139432961,  836025845,  950121150 },
	{ 2139424769, 1558281165, 1635486858 },
	{ 2139406337, 1728402143, 1674423301 },
	{ 2139396097, 1727715782, 1483470544 },
	{ 2139383809, 1092853491, 1741699084 },
	{ 2139369473,  690776899, 1242798709 },
	{ 2139351041, 1768782380, 2120712049 },
	{ 2139334657, 1739968247, 1427249225 },
	{ 2139332609, 1547189119,  623011170 },
	{ 2139310081, 1346827917, 1605466350 },
	{ 2139303937,  369317948,  828392831 },
	{ 2139301889, 1560417239, 1788073219 },
	{ 2139283457, 1303121623,  595079358 },
	{ 2139248641, 1354555286,  573424177 },
	{ 2139240449,   60974056,  885781403 },
	{ 2139222017,  355573421, 1221054839 },
	{ 2139215873,  566477826, 1724006500 },
	{ 2139150337,  871437673, 1609133294 },
	{ 2139144193, 1478130914, 1137491905 },
	{ 2139117569, 1854880922,  964728507 },
	{ 2139076609,  202405335,  756508944 },
	{ 2139062273, 1399715741,  884826059 },
	{ 2139045889, 1051045798, 1202295476 },
	{ 2139033601, 1707715206,  632234634 },
	{ 2139006977, 2035853139,  231626690 },
	{ 2138951681,  183867876,  838350879 },
	{ 2138945537, 1403254661,  404460202 },
	{ 2138920961,  310865011, 1282911681 },
	{ 2138910721, 1328496553,  103472415 },
	{ 2138904577,   78831681,  993513549 },
	{ 2138902529, 1319697451, 1055904361 },
	{ 2138816513,  384338872, 1706202469 },
	{ 2138810369, 1084868275,  405677177 },
	{ 2138787841,  401181788, 1964773901 },
	{ 2138775553, 1850532988, 1247087473 },
	{ 2138767361,  874261901, 1576073565 },
	{ 2138757121, 1187474742,  993541415 },
	{ 2138748929, 1782458888, 1043206483 },
	{ 2138744833, 1221500487,  800141243 },
	{ 2138738689,  413465368, 1450660558 },
	{ 2138695681,  739045140,  342611472 },
	{ 2138658817, 1355845756,  672674190 },
	{ 2138644481,  608379162, 1538874380 },
	{ 2138632193, 1444914034,  686911254 },
	{ 2138607617,  484707818, 1435142134 },
	{ 2138591233,  539460669, 1290458549 },
	{ 2138572801, 2093538990, 2011138646 },
	{ 2138552321, 1149786988, 1076414907 },
	{ 2138546177,  840688206, 2108985273 },
	{ 2138533889,  209669619,  198172413 },
	{ 2138523649, 1975879426, 1277003968 },
	{ 2138490881, 1351891144, 1976858109 },
	{ 2138460161, 1817321013, 1979278293 },
	{ 2138429441, 1950077177,  203441928 },
	{ 2138400769,  908970113,  628395069 },
	{ 2138398721,  219890864,  758486760 },
	{ 2138376193, 1306654379,  977554090 },
	{ 2138351617,  298822498, 2004708503 },
	{ 2138337281,  441457816, 1049002108 },
	{ 2138320897, 1517731724, 1442269609 },
	{ 2138290177, 1355911197, 1647139103 },
	{ 2138234881,  531313247, 1746591962 },
	{ 2138214401, 1899410930,  781416444 },
	{ 2138202113, 1813477173, 1622508515 },
	{ 2138191873, 1086458299, 1025408615 },
	{ 2138183681, 1998800427,  827063290 },
	{ 2138173441, 1921308898,  749670117 },
	{ 2138103809, 1620902804, 2126787647 },
	{ 2138099713,  828647069, 1892961817 },
	{ 2138085377,  179405355, 1525506535 },
	{ 2138060801,  615683235, 1259580138 },
	{ 2138044417, 2030277840, 1731266562 },
	{ 2138042369, 2087222316, 1627902259 },
	{ 2138032129,  126388712, 1108640984 },
	{ 2138011649,  715026550, 1017980050 },
	{ 2137993217, 1693714349, 1351778704 },
	{ 2137888769, 1289762259, 1053090405 },
	{ 2137853953,  199991890, 1254192789 },
	{ 2137833473,  941421685,  896995556 },
	{ 2137817089,  750416446, 1251031181 },
	{ 2137792513,  798075119,  368077456 },
	{ 2137786369,  878543495, 1035375025 },
	{ 2137767937,    9351178, 1156563902 },
	{ 2137755649, 1382297614, 1686559583 },
	{ 2137724929, 1345472850, 1681096331 },
	{ 2137704449,  834666929,  630551727 },
	{ 2137673729, 1646165729, 1892091571 },
	{ 2137620481,  778943821,   48456461 },
	{ 2137618433, 1730837875, 1713336725 },
	{ 2137581569,  805610339, 1378891359 },
	{ 2137538561,  204342388, 1950165220 },
	{ 2137526273, 1947629754, 1500789441 },
	{ 2137516033,  719902645, 1499525372 },
	{ 2137491457,  230451261,  556382829 },
	{ 2137440257,  979573541,  412760291 },
	{ 2137374721,  927841248, 1954137185 },
	{ 2137362433, 1243778559,  861024672 },
	{ 2137313281, 1341338501,  980638386 },
	{ 2137311233,  937415182, 1793212117 },
	{ 2137255937,  795331324, 1410253405 },
	{ 2137243649,  150756339, 1966999887 },
	{ 2137182209,  163346914, 1939301431 },
	{ 2137171969, 1952552395,  758913141 },
	{ 2137159681,  570788721,  218668666 },
	{ 2137147393, 1896656810, 2045670345 },
	{ 2137141249,  358493842,  518199643 },
	{ 2137139201, 1505023029,  674695848 },
	{ 2137133057,   27911103,  830956306 },
	{ 2137122817,  439771337, 1555268614 },
	{ 2137116673,  790988579, 1871449599 },
	{ 2137110529,  432109234,  811805080 },
	{ 2137102337, 1357900653, 1184997641 },
	{ 2137098241,  515119035, 1715693095 },
	{ 2137090049,  408575203, 2085660657 },
	{ 2137085953, 2097793407, 1349626963 },
	{ 2137055233, 1556739954, 1449960883 },
	{ 2137030657, 1545758650, 1369303716 },
	{ 2136987649,  332602570,  103875114 },
	{ 2136969217, 1499989506, 1662964115 },
	{ 2136924161,  857040753,    4738842 },
	{ 2136895489, 1948872712,  570436091 },
	{ 2136893441,   58969960, 1568349634 },
	{ 2136887297, 2127193379,  273612548 },
	{ 2136850433,  111208983, 1181257116 },
	{ 2136809473, 1627275942, 1680317971 },
	{ 2136764417, 1574888217,   14011331 },
	{ 2136741889,   14011055, 1129154251 },
	{ 2136727553,   35862563, 1838555253 },
	{ 2136721409,  310235666, 1363928244 },
	{ 2136698881, 1612429202, 1560383828 },
	{ 2136649729, 1138540131,  800014364 },
	{ 2136606721,  602323503, 1433096652 },
	{ 2136563713,  182209265, 1919611038 },
	{ 2136555521,  324156477,  165591039 },
	{ 2136549377,  195513113,  217165345 },
	{ 2136526849, 1050768046,  939647887 },
	{ 2136508417, 1886286237, 1619926572 },
	{ 2136477697,  609647664,   35065157 },
	{ 2136471553,  679352216, 1452259468 },
	{ 2136457217,  128630031,  824816521 },
	{ 2136422401,   19787464, 1526049830 },
	{ 2136420353,  698316836, 1530623527 },
	{ 2136371201, 1651862373, 1804812805 },
	{ 2136334337,  326596005,  336977082 },
	{ 2136322049,   63253370, 1904972151 },
	{ 2136297473,  312176076,  172182411 },
	{ 2136248321,  381261841,  369032670 },
	{ 2136242177,  358688773, 1640007994 },
	{ 2136229889,  512677188,   75585225 },
	{ 2136219649, 2095003250, 1970086149 },
	{ 2136207361, 1909650722,  537760675 },
	{ 2136176641, 1334616195, 1533487619 },
	{ 2136158209, 2096285632, 1793285210 },
	{ 2136143873, 1897347517,  293843959 },
	{ 2136133633,  923586222, 1022655978 },
	{ 2136096769, 1464868191, 1515074410 },
	{ 2136094721, 2020679520, 2061636104 },
	{ 2136076289,  290798503, 1814726809 },
	{ 2136041473,  156415894, 1250757633 },
	{ 2135996417,  297459940, 1132158924 },
	{ 2135955457,  538755304, 1688831340 },
	{ 0, 0, 0 }
};

/*
 * Prime moduli for the ternary case. Each prime p is such that
 * p = 1 mod 2304. Generator g is a primitive 2304-th root of 1.
 */
static const small_prime PRIMES3[] = {
	{ 2147450113, 1822830492,      33535 },
	{ 2147431681,  424626201, 1193134109 },
	{ 2147415553, 1454863251, 1663647397 },
	{ 2147390209, 1762035773, 1387046861 },
	{ 2147385601, 1517680363, 1106952843 },
	{ 2147362561, 1025814050,  440476355 },
	{ 2147355649,  865455738,  854658425 },
	{ 2147346433, 1321425846,  224103891 },
	{ 2147339521, 1474981691,  599730472 },
	{ 2147332609, 1864656042, 1545592206 },
	{ 2147316481, 1890505928,  421789636 },
	{ 2147309569,  906570069, 1610828544 },
	{ 2147304961, 1403818598, 1990856782 },
	{ 2147281921,   71783863,  956869830 },
	{ 2147258881, 1036649303,  396683436 },
	{ 2147242753,  467401799, 1773880773 },
	{ 2147235841, 1453821700,  461674371 },
	{ 2147233537,  598421725, 1689622480 },
	{ 2147217409, 1761254347,  688859791 },
	{ 2147212801, 1327730595, 1887769026 },
	{ 2147164417, 1258121641,  366578724 },
	{ 2147141377, 1777466165,  171390629 },
	{ 2147139073, 1984146916,  328716798 },
	{ 2147136769, 1765129553,  767922350 },
	{ 2147129857, 1514145184, 1081034369 },
	{ 2147104513, 1951719537,  733036907 },
	{ 2147095297,  682785034,  373776370 },
	{ 2147079169, 1820310317, 1807535939 },
	{ 2147051521,  458986762,  590428790 },
	{ 2147049217, 1038363684,  877203562 },
	{ 2147026177, 1326504697,  643505453 },
	{ 2147003137, 1170185764, 1319639833 },
	{ 2146966273,  114827812, 1294985554 },
	{ 2146959361, 1164199326, 1256988252 },
	{ 2146954753,  486248957,  710359258 },
	{ 2146947841, 2000149550,  918021771 },
	{ 2146936321,  942091103,  108081081 },
	{ 2146906369,  271696604,  608809917 },
	{ 2146887937, 1511165281,  369139633 },
	{ 2146885633,  441164610,  926260308 },
	{ 2146883329, 1085986991,  240773649 },
	{ 2146864897,  345552901, 1817459006 },
	{ 2146814209,  793155214,  640578693 },
	{ 2146775041, 1675390468,  820220886 },
	{ 2146772737,  730144429,  765352711 },
	{ 2146756609, 1835554388, 1004443916 },
	{ 2146738177,  433272441, 2105099367 },
	{ 2146733569, 1762957593, 1602986233 },
	{ 2146694401,  399612535,  169309537 },
	{ 2146687489,  114105700,  780597858 },
	{ 2146646017, 1434027294,  564442758 },
	{ 2146622977, 1341692395, 2091021085 },
	{ 2146613761,  360157916, 1064050988 },
	{ 2146606849, 1313179470, 1969566727 },
	{ 2146599937, 1706429999,  652421166 },
	{ 2146572289, 1732243288, 1454972738 },
	{ 2146544641,  272853975,  590131110 },
	{ 2146542337,   36418634, 1056975891 },
	{ 2146530817, 2007241330, 1580599978 },
	{ 2146507777, 1995701118, 1014402730 },
	{ 2146493953, 1114934790, 1032062368 },
	{ 2146487041, 1862337352, 1231735150 },
	{ 2146450177,  846834198,  681753242 },
	{ 2146447873, 1227566685,   12770655 },
	{ 2146417921, 1671891715,  794746270 },
	{ 2146406401,  609289185,  630588397 },
	{ 2146381057, 2109266947,  655092508 },
	{ 2146378753,  343938960,  966167795 },
	{ 2146367233,   41811369, 1440184031 },
	{ 2146353409, 1450579491,  183813399 },
	{ 2146348801,    9565898,  526104353 },
	{ 2146330369, 1407087756,  647129879 },
	{ 2146325761,  957276356,  283440898 },
	{ 2146291201,  925507446,  985278760 },
	{ 2146288897,   48605924,  828823151 },
	{ 2146256641,  974604801, 1426305449 },
	{ 2146203649,  977374447, 1007788238 },
	{ 2146192129, 2083411670, 1165914744 },
	{ 2146187521, 1993961053,  795729927 },
	{ 2146180609, 1629167227,  730660993 },
	{ 2146169089,   44701833, 1427754293 },
	{ 2146106881,   16997996,  530746042 },
	{ 2146095361,  264082098,  306963294 },
	{ 2146093057,  662783894, 1341690726 },
	{ 2146090753, 1656443739,   45600745 },
	{ 2146072321, 1430706864, 1210417794 },
	{ 2146067713, 1657990272, 1024407936 },
	{ 2146030849, 1649603809, 2098081629 },
	{ 2146019329,  978947895,  491565736 },
	{ 2146014721,   48551225,   46133079 },
	{ 2145996289, 1832516941,  325405827 },
	{ 2145984769, 1046055041, 1409723796 },
	{ 2145964033,   66156561,  464497063 },
	{ 2145954817,  859915264, 2092994912 },
	{ 2145952513, 1758184581,  956837854 },
	{ 2145943297, 1901395808, 1848403013 },
	{ 2145915649,   30807819, 1059439378 },
	{ 2145904129,  647739402, 1973108753 },
	{ 2145874177, 1869553544,  577659032 },
	{ 2145871873,  337408396, 1872862727 },
	{ 2145864961, 1685455768,  667710631 },
	{ 2145862657, 1532795538, 2070068256 },
	{ 2145851137,  212501100, 1224511404 },
	{ 2145837313, 1358121493, 1848966089 },
	{ 2145825793,  386307300,  449999704 },
	{ 2145823489, 1129365680, 1001085691 },
	{ 2145816577,  551493242, 2119183454 },
	{ 2145807361,  271270756, 1989968022 },
	{ 2145793537,  852239048, 1309749017 },
	{ 2145782017, 1284378810,  311082915 },
	{ 2145777409, 2004177093, 1290706457 },
	{ 2145742849, 2121468587, 1133755266 },
	{ 2145733633, 1260159354, 1951998626 },
	{ 2145722113,  163237044,  594573040 },
	{ 2145689857,  474757169,  834321078 },
	{ 2145687553,   67947935,  828266594 },
	{ 2145664513, 1598442324,  630205829 },
	{ 2145646081,  250505282,  776273401 },
	{ 2145623041, 1703821214,  888409131 },
	{ 2145611521, 1039247338,  228177613 },
	{ 2145609217, 1668731457, 1185982491 },
	{ 2145600001,  857636216,  139252527 },
	{ 2145595393,  400214229,  729082632 },
	{ 2145593089, 1796005933,  550289398 },
	{ 2145588481, 2094475478, 1217287696 },
	{ 2145565441,  426324144, 1312430145 },
	{ 2145563137,   78773460,  169188458 },
	{ 2145549313,  936100306,  757760717 },
	{ 2145542401, 1097930762,  824118991 },
	{ 2145535489, 1983878618, 1042705853 },
	{ 2145528577, 1036190039, 1022323836 },
	{ 2145523969, 1868801802,  416370830 },
	{ 2145491713,  356121488,  543381348 },
	{ 2145480193,  199326412, 1731701467 },
	{ 2145466369, 1830188719,  240239794 },
	{ 2145445633,  351737879, 1506144677 },
	{ 2145443329,  379875076,  475878516 },
	{ 2145434113, 1003996799,  683903694 },
	{ 2145415681, 1035366258, 1531251342 },
	{ 2145401857,  126895727, 1548302219 },
	{ 2145390337,  203720005,  425208191 },
	{ 2145388033, 1347512002,  117858071 },
	{ 2145362689, 1169852366, 1431567820 },
	{ 2145355777, 2110316730, 2086117269 },
	{ 2145353473, 1774773548,  876852201 },
	{ 2145339649,  501723795, 1021106097 },
	{ 2145318913,  418847235, 1160609910 },
	{ 2145300481, 1023331752,  191383930 },
	{ 2145286657, 1280971615,  216845844 },
	{ 2145282049, 1196793073, 1187575821 },
	{ 2145235969,  923496757, 1307358539 },
	{ 2145219841,  519785435, 1626462263 },
	{ 2145185281, 1860630272,  474564844 },
	{ 2145180673, 1834049770,  586172945 },
	{ 2145178369, 1501247472, 1096722774 },
	{ 2145136897,  550810282,   40160384 },
	{ 2145113857, 1296058651,  977708791 },
	{ 2145079297,  955545860,  265600380 },
	{ 2145076993,   79051519, 1039925789 },
	{ 2145067777,  253166375, 1127232024 },
	{ 2145065473, 1026024296,  756613594 },
	{ 2145063169, 1426910002, 1608845610 },
	{ 2145033217,  970758503, 1555852593 },
	{ 2145017089,  347430931,  775368992 },
	{ 2145007873,  914675316, 1297416956 },
	{ 2144975617, 2015869942, 1431118733 },
	{ 2144938753, 1762298335, 1193660775 },
	{ 2144929537, 1449381583, 1771237555 },
	{ 2144920321,  875265402, 2099494532 },
	{ 2144915713,  582439339,  817587747 },
	{ 2144894977,  506160393, 1688289421 },
	{ 2144809729,  734926996, 1704354178 },
	{ 2144793601,  155059687,  171692410 },
	{ 2144777473,  317485600,  874802365 },
	{ 2144775169,  651843170,  473816143 },
	{ 2144759041,  681485475,  464197116 },
	{ 2144733697, 2125180198,   48767965 },
	{ 2144729089, 1478112475, 1355118431 },
	{ 2144712961, 1279790481,  591304708 },
	{ 2144648449, 1335778078, 1098669758 },
	{ 2144630017, 1603567267,  160302246 },
	{ 2144604673, 1175259039,   78203500 },
	{ 2144597761,  620616998, 1515263848 },
	{ 2144579329,  193500483, 1559132057 },
	{ 2144567809, 1946028673, 1581197529 },
	{ 2144558593,  231387691, 1485256545 },
	{ 2144551681,  844374396,   30673778 },
	{ 2144535553,  166176063,  168263365 },
	{ 2144528641,  781790035,  556577063 },
	{ 2144500993,  461561124, 1399755614 },
	{ 2144459521,    2822303,  752681683 },
	{ 2144454913,  274692318,  257668067 },
	{ 2144448001,  716371349,  584223158 },
	{ 2144418049, 1936863174,  540598834 },
	{ 2144388097, 1855586009,  690032843 },
	{ 2144383489,  408100025, 1859550157 },
	{ 2144348929,  122163029, 2060148799 },
	{ 2144337409, 1525008836,  819305252 },
	{ 2144330497, 2024998620, 1611547511 },
	{ 2144275201, 1947760064, 1759305590 },
	{ 2144261377,  468455779, 2046852340 },
	{ 2144256769,  243366493,  207179424 },
	{ 2144236033,  562111014,  536612673 },
	{ 2144229121,  562082296, 1933892350 },
	{ 2144210689, 1057111161,  162239457 },
	{ 2144192257, 1440567493,  907872966 },
	{ 2144160001,  464029916,  319626240 },
	{ 2144136961,  853524564,  297716302 },
	{ 2144120833,  587037095, 1136871325 },
	{ 2144065537,  231183627,  323060764 },
	{ 2144028673,  340762973, 1758401946 },
	{ 2144010241,  593721336,  481717690 },
	{ 2143996417,  743415799,   71802978 },
	{ 2143975681,  403083216,  363908257 },
	{ 2143950337,  854680705, 1615520152 },
	{ 2143948033,  294824006, 1680513832 },
	{ 2143922689,  648528897,  390399209 },
	{ 2143918081, 1755729599,  293848938 },
	{ 2143899649, 1560525715,  670501530 },
	{ 2143867393,  733595942, 1533336387 },
	{ 2143821313, 1550195321,  726145119 },
	{ 2143786753,  856875165,   36866658 },
	{ 2143784449, 1222822055, 1205640485 },
	{ 2143754497,  991548026,  190649322 },
	{ 2143742977, 1756977003,  292977861 },
	{ 2143740673, 1342868950,  176825607 },
	{ 2143708417, 1236271287,  157693291 },
	{ 2143692289, 1746765009, 1168989539 },
	{ 2143685377, 1342856351, 1371059722 },
	{ 2143680769,  273481162, 1775434577 },
	{ 2143641601, 1998453617,  606651047 },
	{ 2143567873,  702418292,  536490409 },
	{ 2143556353, 1662552442, 1276091018 },
	{ 2143535617,  842561199, 1808542507 },
	{ 2143533313,  826061287, 1605713154 },
	{ 2143531009, 1930038526, 2102909123 },
	{ 2143510273,  172073132, 1023337452 },
	{ 2143491841, 1212168134, 1114919776 },
	{ 2143487233, 1779380185, 1831962347 },
	{ 2143480321, 1156632912, 1555759032 },
	{ 2143478017,  622095943,  417269653 },
	{ 2143461889, 1280303071,  153354823 },
	{ 2143431937,  153658480, 1588613191 },
	{ 2143383553,  277427922,   38234351 },
	{ 2143339777,  589784914, 1573224776 },
	{ 2143335169,  922783059,  200661355 },
	{ 2143323649,  302291280, 1138833370 },
	{ 2143277569,  820797102,  854962129 },
	{ 2143213057, 1893415535,  181451477 },
	{ 2143203841, 1088582389,  170356944 },
	{ 2143196929,  291107059,  728824031 },
	{ 2143192321, 1068927089,  373852844 },
	{ 2143187713,  985974306,  668372891 },
	{ 2143173889,  167922091,   50439572 },
	{ 2143130113,  211225918, 1845430847 },
	{ 2143127809,   27582853, 1679634064 },
	{ 2143097857, 1766916709, 1819896188 },
	{ 2143063297,  780824783, 1952357891 },
	{ 2143058689, 1378949832,  756913072 },
	{ 2143051777,  408317329,  443287483 },
	{ 2143047169, 1273910740, 1515393890 },
	{ 2143028737,  996305079,  776734402 },
	{ 2143003393,  993006570, 1390097560 },
	{ 2142996481, 2136513072, 1012671159 },
	{ 2142961921,  891029287,  107949307 },
	{ 2142948097,  844702524,  757623023 },
	{ 2142943489,  783825741,  900340177 },
	{ 2142936577,  674435958,  527289896 },
	{ 2142934273,  823653457,  327447549 },
	{ 2142920449, 1856390383,  273195225 },
	{ 2142911233, 1065735230, 1111511492 },
	{ 2142899713,  852649554, 1319180783 },
	{ 2142897409, 1582470696, 1728311821 },
	{ 2142885889,  875959709, 1969188734 },
	{ 2142851329, 1668580464, 1442501897 },
	{ 2142830593, 1991029339,  713631715 },
	{ 2142807553,   46451453,  209687937 },
	{ 2142786817, 1066849029, 1022563324 },
	{ 2142754561, 1182968060, 1098740072 },
	{ 2142749953,  170870492, 1883579850 },
	{ 2142736129,  885298220,  134381218 },
	{ 2142690049,  257234559,  713466052 },
	{ 2142671617,   16153127,  932308898 },
	{ 2142639361, 1904439789,  232384311 },
	{ 2142623233,  710460071, 1914284724 },
	{ 2142616321, 1384373375, 1948960778 },
	{ 2142614017,  967648016,  687398138 },
	{ 2142579457, 1095246428, 2090495107 },
	{ 2142574849, 1641210381,  638943403 },
	{ 2142556417,  958201775, 1972069612 },
	{ 2142547201,  951709836,  676516709 },
	{ 2142540289, 1374042909,  215502433 },
	{ 2142533377, 1882816694, 2074030459 },
	{ 2142498817, 1504404304, 1972349416 },
	{ 2142471169, 1750000645,  813201047 },
	{ 2142450433,  295533779, 1565446756 },
	{ 2142438913,   10280011,   91646711 },
	{ 2142436609, 1274524844,  162069470 },
	{ 2142429697, 1092732318, 1096144802 },
	{ 2142420481, 1535070609, 1079403268 },
	{ 2142402049, 2005480704,  629779334 },
	{ 2142381313, 2114923039,  648509010 },
	{ 2142379009,  718105805,  536973776 },
	{ 2142374401, 2095587425, 1044147117 },
	{ 2142351361,  439135167, 1502821682 },
	{ 2142349057,  446437191,  530473080 },
	{ 2142323713,  100125463,  992682060 },
	{ 2142316801,  696384453, 1947571491 },
	{ 2142314497, 1453856322, 2001001690 },
	{ 2142277633, 1952977383,  221148682 },
	{ 2142245377, 1644990598, 1408241725 },
	{ 2142229249, 1528562358, 1061142574 },
	{ 2142217729,  510200942, 1943431139 },
	{ 2142208513,  572850506,  958721727 },
	{ 2142178561, 1699015145,  655247881 },
	{ 2142144001,  295258268, 1190693208 },
	{ 2142109441,   13501310, 1444074262 },
	{ 2142097921, 1555745306,  965245540 },
	{ 2142095617,  639823805,  124040022 },
	{ 2142091009,   78431256, 2072711469 },
	{ 2142074881, 1583322983, 1971506113 },
	{ 2142067969, 1985460292,  493290576 },
	{ 2142044929,  964118073, 1818270494 },
	{ 2142040321, 2074619527,   89552074 },
	{ 2142024193,  114755492,  442193256 },
	{ 2142010369, 1379074915, 1941110794 },
	{ 2141932033, 2026935677,  190080015 },
	{ 2141920513,   74333441,  805281961 },
	{ 2141918209, 1775077654,  236453650 },
	{ 2141913601, 1802464945, 1566679036 },
	{ 2141911297,  387494635,  563810545 },
	{ 2141895169, 1172229060, 1528048235 },
	{ 2141890561, 1361767304, 2041867386 },
	{ 2141867521,  533045780,  914774350 },
	{ 2141842177,  437131558,  183042158 },
	{ 2141821441,   39421972, 1331298027 },
	{ 2141814529, 1537989736, 1530178830 },
	{ 2141803009, 1676671105,  515971140 },
	{ 2141791489, 2010187792, 1541172871 },
	{ 2141784577, 1386646410, 1982618979 },
	{ 2141738497,  712677114,   31915251 },
	{ 2141736193, 1274969467,  916301278 },
	{ 2141733889,  116533872, 1715534326 },
	{ 2141694721, 1454976825, 1509954498 },
	{ 2141692417, 1516965569,  642117163 },
	{ 2141671681,  750263061,  316436557 },
	{ 2141669377, 2072414840,  808860641 },
	{ 2141660161,  161141902,  282052692 },
	{ 2141653249, 1463156395,  255786615 },
	{ 2141620993, 1362041953,  229951180 },
	{ 2141591041, 1936223409,  710815623 },
	{ 2141563393, 1302310432, 2126420394 },
	{ 2141542657, 1197316148,    2471210 },
	{ 2141533441, 2086849163, 1253750414 },
	{ 2141526529,  392684861,  291575124 },
	{ 2141475841, 1392668921, 1135731293 },
	{ 2141464321, 1574939096,  682732876 },
	{ 2141450497,  714585706, 2017942072 },
	{ 2141418241, 1697181785, 1091684538 },
	{ 2141406721,  712755841,  661693530 },
	{ 2141404417, 2001939869,   46726158 },
	{ 2141342209,  400626204, 1436047974 },
	{ 2141335297, 1502178162,  413989624 },
	{ 2141332993, 1475685643,  178253589 },
	{ 2141291521,  304189746, 1048860171 },
	{ 2141275393, 2084823014, 1555287725 },
	{ 2141273089, 2119184022,  411567434 },
	{ 2141261569,  178224725,  298057668 },
	{ 2141254657,  677034170, 1139735334 },
	{ 2141238529,  616800485, 1401647061 },
	{ 2141220097,  779544570,  504667947 },
	{ 2141197057,  978744056,  193160486 },
	{ 2141148673, 1163962695, 1287367370 },
	{ 2141137153,  224770889,  980061580 },
	{ 2141123329,  298410621, 1056581872 },
	{ 2141111809,  219751128, 1647153596 },
	{ 2141100289, 1311425207,  724567430 },
	{ 2141088769,  541960942, 1683309546 },
	{ 2141077249, 1907117344, 1956090946 },
	{ 2141044993, 1762133402, 1997717427 },
	{ 2141026561,  929429695, 1693498396 },
	{ 2140980481,  202324091, 1791782539 },
	{ 2140962049,  847752429,  771999167 },
	{ 2140955137,  171581753,  897638410 },
	{ 2140934401, 1561197544, 1785721193 },
	{ 2140927489, 1304799727,  610189109 },
	{ 2140911361,  584407800,  573572391 },
	{ 2140872193,  579572504, 1460985498 },
	{ 2140865281, 2037311399, 1085114600 },
	{ 2140842241, 1464914593,  585074325 },
	{ 2140823809, 1476350636,    6041181 },
	{ 2140814593, 1547025818,  862668427 },
	{ 2140791553,  600414192, 1406967556 },
	{ 2140766209, 1778609535, 1403120148 },
	{ 2140733953, 1320658482, 1879929384 },
	{ 2140713217, 1129185878, 1667839994 },
	{ 2140701697,  296171658, 1309665658 },
	{ 2140664833,  399603307, 1473037276 },
	{ 2140627969, 2072761417,  860933793 },
	{ 2140561153,  859021277, 1227879163 },
	{ 2140547329, 1716541026, 1290146230 },
	{ 2140542721, 1194859500, 1797753332 },
	{ 2140535809,  167714346, 1162981484 },
	{ 2140503553,  370984759,   46309386 },
	{ 2140494337, 1328986356, 1606498728 },
	{ 2140480513,   38230879, 2034344207 },
	{ 2140466689, 1806259424,  362621291 },
	{ 2140427521,  814658758,  825681996 },
	{ 2140404481, 1123614881,  456597404 },
	{ 2140399873, 1573999347, 2109157497 },
	{ 2140365313,  972962485, 1511091337 },
	{ 2140351489,  862138970, 1385361132 },
	{ 2140323841,  925446313,  315386822 },
	{ 2140316929,  327600537, 1432209372 },
	{ 2140300801,  206223333, 1824969389 },
	{ 2140284673,  154825255,  625926281 },
	{ 2140275457, 1268521276, 1039783122 },
	{ 2140270849, 1930935020, 2093846199 },
	{ 2140250113,  293408394,  446043725 },
	{ 2140236289, 1210426371,  927336002 },
	{ 2140224769,  132901891,  584957812 },
	{ 2140220161,  940671602, 1748241255 },
	{ 2140208641,  337534060, 1014808439 },
	{ 2140206337,  707821818,  736128861 },
	{ 2140197121, 1276000052, 1233695606 },
	{ 2140192513, 1586736300, 1734440244 },
	{ 2140185601,  823807555,  861050097 },
	{ 2140171777,  706329492, 1082375865 },
	{ 2140116481, 1812454795, 1369401687 },
	{ 2140104961,  264127389, 1819984006 },
	{ 2140098049, 1965766156,  383515743 },
	{ 2140047361, 1960123302, 1042763142 },
	{ 2140042753, 1687337635,  420287792 },
	{ 2140031233, 1366749250, 1532940500 },
	{ 2139987457, 1912737167, 1404131659 },
	{ 2139964417,  693333303,  177486658 },
	{ 2139952897,  495455314, 1274422832 },
	{ 2139948289,   40363916,  943432746 },
	{ 2139927553,  444424273, 1207981519 },
	{ 2139902209, 1465807360,   92415256 },
	{ 2139872257, 1837154584,  909402842 },
	{ 2139867649,   75059817,  804803785 },
	{ 2139826177, 2015221154,  881164323 },
	{ 2139814657, 1148432315, 1578970409 },
	{ 2139800833, 2088034106,  933005359 },
	{ 2139789313, 1861311437,  177956065 },
	{ 2139770881,  363514308,   25637872 },
	{ 2139766273, 2070991768, 1557275280 },
	{ 2139713281, 1604789895, 1788183740 },
	{ 2139708673, 1845339933,  609946729 },
	{ 2139701761, 1430546144, 1989106525 },
	{ 2139676417,  605392937,  970641834 },
	{ 2139641857, 1165076318,  835985127 },
	{ 2139616513,  283116094,  667711089 },
	{ 2139614209,  646890502, 1209456877 },
	{ 2139598081,  449743376,  718517127 },
	{ 2139593473,  497145855,  394220435 },
	{ 2139572737,  955015696,  294304456 },
	{ 2139568129,  401133955, 1091472607 },
	{ 2139563521, 1735308269, 1691190275 },
	{ 2139556609, 1826473043, 1043649467 },
	{ 2139549697, 1908832672,  377280535 },
	{ 2139535873, 1241741506,  651921754 },
	{ 2139524353, 1923937400, 1353981614 },
	{ 2139492097,  285331406,  802398974 },
	{ 2139475969,  576196150,  429222684 },
	{ 2139466753, 1780761618,  296308885 },
	{ 2139459841,  611500689, 1213639654 },
	{ 2139434497,  148656389, 1051625014 },
	{ 2139413761,  391073297, 2081064242 },
	{ 2139399937, 1065174985,  787712624 },
	{ 2139383809,  788093248, 1111802639 },
	{ 2139356161,  336361251,  319889191 },
	{ 2139333121,  884166060,  509405995 },
	{ 2139321601, 1513473632, 1940111538 },
	{ 2139310081,  900672962, 2071072080 },
	{ 2139303169, 1991620918,  543628217 },
	{ 2139287041,  370425359, 1047050467 },
	{ 2139275521,  713658400, 1797885684 },
	{ 2139268609, 1783527316,  874491612 },
	{ 2139261697,  631837513, 1395044429 },
	{ 2139259393, 1742874935,  508544171 },
	{ 2139252481,  463463038,  737489950 },
	{ 2139204097,  538698195,  604942560 },
	{ 2139201793, 1435754599,   54362978 },
	{ 2139169537, 2012388705,  392083310 },
	{ 2139144193, 1155362435, 1319368247 },
	{ 2139137281,  921952177,   92928882 },
	{ 2139123457, 1506351550,  602798069 },
	{ 2139109633, 1527038848,   48844022 },
	{ 2139095809, 2071318942, 1524340004 },
	{ 2139075073, 1165123429, 1717466457 },
	{ 2139056641, 1776112510,  286710183 },
	{ 2139033601,  980780564, 2116611843 },
	{ 2139028993, 1474450200, 1742934604 },
	{ 2138976001,  428486407, 1580417049 },
	{ 2138969089, 1396721654, 1511256767 },
	{ 2138950657, 1516054630, 2071630098 },
	{ 2138939137, 1078360116,  691835055 },
	{ 2138927617,  425837073,  756872582 },
	{ 2138918401, 1641039620, 1734207081 },
	{ 2138916097, 1017601848, 1142652819 },
	{ 2138913793,  306828523,  191212034 },
	{ 2138904577, 1745075919, 1122876435 },
	{ 2138888449, 1503947447,  951342509 },
	{ 2138837761, 1210620672,  957215442 },
	{ 2138833153,  787109305,  412518979 },
	{ 2138823937,   44637017,  408073095 },
	{ 2138775553,  199446608,  907722635 },
	{ 2138757121, 2081488043, 1042423315 },
	{ 2138738689, 1497686426, 2084550241 },
	{ 2138729473,  608998372, 1206782464 },
	{ 2138717953,  539269185, 2044657934 },
	{ 2138681089,  268630505, 1615466641 },
	{ 2138660353,  582047226,  449049076 },
	{ 2138648833,  926857321, 1056946200 },
	{ 2138639617,  195695324, 2012033442 },
	{ 2138616577, 2068544160, 1896897903 },
	{ 2138605057, 1751671600,  614364881 },
	{ 2138600449,  478123986,  288140368 },
	{ 2138591233,  783785615,  851589578 },
	{ 0, 0, 0 }
};

/*
 * Reduce a small signed integer modulo a small prime. The source
 * value x MUST be such that -p < x < p.
 */
static inline uint32_t
modp_set(int32_t x, uint32_t p)
{
	uint32_t w;

	w = (uint32_t)x;
	w += p & -(w >> 31);
	return w;
}

/*
 * Normalize a modular integer around 0.
 */
static inline int32_t
modp_norm(uint32_t x, uint32_t p)
{
	return x - (p & (((x - ((p + 1) >> 1)) >> 31) - 1));
}

/*
 * Compute -1/p mod 2^31. This works for all odd integers p that fit
 * on 32 bits.
 */
static uint32_t
modp_ninv31(uint32_t p)
{
	uint32_t y;

	y = 2 - p;
	y *= 2 - p * y;
	y *= 2 - p * y;
	y *= 2 - p * y;
	y *= 2 - p * y;
	return (uint32_t)0x7FFFFFFF & -y;
}

/*
 * Compute R = 2^31 mod p.
 */
static inline uint32_t
modp_R(uint32_t p)
{
	/*
	 * Since 2^30 < p < 2^31, we know that 2^31 mod p is simply
	 * 2^31 - p.
	 */
	return ((uint32_t)1 << 31) - p;
}

/*
 * Addition modulo p.
 */
static inline uint32_t
modp_add(uint32_t a, uint32_t b, uint32_t p)
{
	uint32_t d;

	d = a + b - p;
	d += p & -(d >> 31);
	return d;
}

/*
 * Subtraction modulo p.
 */
static inline uint32_t
modp_sub(uint32_t a, uint32_t b, uint32_t p)
{
	uint32_t d;

	d = a - b;
	d += p & -(d >> 31);
	return d;
}

/*
 * Halving modulo p.
 */
static inline uint32_t
modp_half(uint32_t a, uint32_t p)
{
	a += p & -(a & 1);
	return a >> 1;
}

/*
 * Montgomery multiplication modulo p. The 'p0i' value is -1/p mod 2^31.
 * It is required that p is an odd integer.
 */
static inline uint32_t
modp_montymul(uint32_t a, uint32_t b, uint32_t p, uint32_t p0i)
{
	uint64_t z, w;
	uint32_t d;

	z = (uint64_t)a * (uint64_t)b;
	w = ((z * p0i) & (uint64_t)0x7FFFFFFF) * p;
	d = (uint32_t)((z + w) >> 31) - p;
	d += p & -(d >> 31);
	return d;
}

/*
 * Compute R2 = 2^62 mod p.
 */
static uint32_t
modp_R2(uint32_t p, uint32_t p0i)
{
	uint32_t z;

	/*
	 * Compute z = 2^31 mod p (this is the value 1 in Montgomery
	 * representation), then double it with an addition.
	 */
	z = modp_R(p);
	z = modp_add(z, z, p);

	/*
	 * Square it five times to obtain 2^32 in Montgomery representation
	 * (i.e. 2^63 mod p).
	 */
	z = modp_montymul(z, z, p, p0i);
	z = modp_montymul(z, z, p, p0i);
	z = modp_montymul(z, z, p, p0i);
	z = modp_montymul(z, z, p, p0i);
	z = modp_montymul(z, z, p, p0i);

	/*
	 * Halve the value mod p to get 2^62.
	 */
	z = (z + (p & -(z & 1))) >> 1;
	return z;
}

/*
 * Compute 2^(31*x) modulo p. This works for integers x up to 2^11.
 * p must be prime such that 2^30 < p < 2^31; p0i must be equal to
 * -1/p mod 2^31.
 */
static inline uint32_t
modp_Rx(unsigned x, uint32_t p, uint32_t p0i, uint32_t R2)
{
	int i;
	uint32_t r, z;

	/*
	 * 2^(31*x) = (2^31)*(2^(31*(x-1))); i.e. we want the Montgomery
	 * representation of (2^31)^e mod p, where e = x-1.
	 * R2 is 2^31 in Montgomery representation.
	 */
	x --;
	r = R2;
	z = modp_R(p);
	for (i = 0; (1U << i) <= x; i ++) {
		if ((x & (1U << i)) != 0) {
			z = modp_montymul(z, r, p, p0i);
		}
		r = modp_montymul(r, r, p, p0i);
	}
	return z;
}

/*
 * Division modulo p. If the divisor (b) is 0, then 0 is returned.
 * This function computes proper results only when p is prime.
 * Parameters:
 *   a     dividend
 *   b     divisor
 *   p     odd prime modulus
 *   p0i   -1/p mod 2^31
 *   R     2^31 mod R
 */
static uint32_t
modp_div(uint32_t a, uint32_t b, uint32_t p, uint32_t p0i, uint32_t R)
{
	uint32_t z, e;
	int i;

	e = p - 2;
	z = R;
	for (i = 30; i >= 0; i --) {
		uint32_t z2;

		z = modp_montymul(z, z, p, p0i);
		z2 = modp_montymul(z, b, p, p0i);
		z ^= (z ^ z2) & -(uint32_t)((e >> i) & 1);
	}

	/*
	 * The loop above just assumed that b was in Montgomery
	 * representation, i.e. really contained b*R; under that
	 * assumption, it returns 1/b in Montgomery representation,
	 * which is R/b. But we gave it b in normal representation,
	 * so the loop really returned R/(b/R) = R^2/b.
	 *
	 * We want a/b, so we need one Montgomery multiplication with a,
	 * which also remove one of the R factors, and another such
	 * multiplication to remove the second R factor.
	 */
	z = modp_montymul(z, 1, p, p0i);
	return modp_montymul(a, z, p, p0i);
}

/*
 * Bit-reversal index table.
 */
static const uint16_t REV10[] = {
	   0,  512,  256,  768,  128,  640,  384,  896,   64,  576,  320,  832,
	 192,  704,  448,  960,   32,  544,  288,  800,  160,  672,  416,  928,
	  96,  608,  352,  864,  224,  736,  480,  992,   16,  528,  272,  784,
	 144,  656,  400,  912,   80,  592,  336,  848,  208,  720,  464,  976,
	  48,  560,  304,  816,  176,  688,  432,  944,  112,  624,  368,  880,
	 240,  752,  496, 1008,    8,  520,  264,  776,  136,  648,  392,  904,
	  72,  584,  328,  840,  200,  712,  456,  968,   40,  552,  296,  808,
	 168,  680,  424,  936,  104,  616,  360,  872,  232,  744,  488, 1000,
	  24,  536,  280,  792,  152,  664,  408,  920,   88,  600,  344,  856,
	 216,  728,  472,  984,   56,  568,  312,  824,  184,  696,  440,  952,
	 120,  632,  376,  888,  248,  760,  504, 1016,    4,  516,  260,  772,
	 132,  644,  388,  900,   68,  580,  324,  836,  196,  708,  452,  964,
	  36,  548,  292,  804,  164,  676,  420,  932,  100,  612,  356,  868,
	 228,  740,  484,  996,   20,  532,  276,  788,  148,  660,  404,  916,
	  84,  596,  340,  852,  212,  724,  468,  980,   52,  564,  308,  820,
	 180,  692,  436,  948,  116,  628,  372,  884,  244,  756,  500, 1012,
	  12,  524,  268,  780,  140,  652,  396,  908,   76,  588,  332,  844,
	 204,  716,  460,  972,   44,  556,  300,  812,  172,  684,  428,  940,
	 108,  620,  364,  876,  236,  748,  492, 1004,   28,  540,  284,  796,
	 156,  668,  412,  924,   92,  604,  348,  860,  220,  732,  476,  988,
	  60,  572,  316,  828,  188,  700,  444,  956,  124,  636,  380,  892,
	 252,  764,  508, 1020,    2,  514,  258,  770,  130,  642,  386,  898,
	  66,  578,  322,  834,  194,  706,  450,  962,   34,  546,  290,  802,
	 162,  674,  418,  930,   98,  610,  354,  866,  226,  738,  482,  994,
	  18,  530,  274,  786,  146,  658,  402,  914,   82,  594,  338,  850,
	 210,  722,  466,  978,   50,  562,  306,  818,  178,  690,  434,  946,
	 114,  626,  370,  882,  242,  754,  498, 1010,   10,  522,  266,  778,
	 138,  650,  394,  906,   74,  586,  330,  842,  202,  714,  458,  970,
	  42,  554,  298,  810,  170,  682,  426,  938,  106,  618,  362,  874,
	 234,  746,  490, 1002,   26,  538,  282,  794,  154,  666,  410,  922,
	  90,  602,  346,  858,  218,  730,  474,  986,   58,  570,  314,  826,
	 186,  698,  442,  954,  122,  634,  378,  890,  250,  762,  506, 1018,
	   6,  518,  262,  774,  134,  646,  390,  902,   70,  582,  326,  838,
	 198,  710,  454,  966,   38,  550,  294,  806,  166,  678,  422,  934,
	 102,  614,  358,  870,  230,  742,  486,  998,   22,  534,  278,  790,
	 150,  662,  406,  918,   86,  598,  342,  854,  214,  726,  470,  982,
	  54,  566,  310,  822,  182,  694,  438,  950,  118,  630,  374,  886,
	 246,  758,  502, 1014,   14,  526,  270,  782,  142,  654,  398,  910,
	  78,  590,  334,  846,  206,  718,  462,  974,   46,  558,  302,  814,
	 174,  686,  430,  942,  110,  622,  366,  878,  238,  750,  494, 1006,
	  30,  542,  286,  798,  158,  670,  414,  926,   94,  606,  350,  862,
	 222,  734,  478,  990,   62,  574,  318,  830,  190,  702,  446,  958,
	 126,  638,  382,  894,  254,  766,  510, 1022,    1,  513,  257,  769,
	 129,  641,  385,  897,   65,  577,  321,  833,  193,  705,  449,  961,
	  33,  545,  289,  801,  161,  673,  417,  929,   97,  609,  353,  865,
	 225,  737,  481,  993,   17,  529,  273,  785,  145,  657,  401,  913,
	  81,  593,  337,  849,  209,  721,  465,  977,   49,  561,  305,  817,
	 177,  689,  433,  945,  113,  625,  369,  881,  241,  753,  497, 1009,
	   9,  521,  265,  777,  137,  649,  393,  905,   73,  585,  329,  841,
	 201,  713,  457,  969,   41,  553,  297,  809,  169,  681,  425,  937,
	 105,  617,  361,  873,  233,  745,  489, 1001,   25,  537,  281,  793,
	 153,  665,  409,  921,   89,  601,  345,  857,  217,  729,  473,  985,
	  57,  569,  313,  825,  185,  697,  441,  953,  121,  633,  377,  889,
	 249,  761,  505, 1017,    5,  517,  261,  773,  133,  645,  389,  901,
	  69,  581,  325,  837,  197,  709,  453,  965,   37,  549,  293,  805,
	 165,  677,  421,  933,  101,  613,  357,  869,  229,  741,  485,  997,
	  21,  533,  277,  789,  149,  661,  405,  917,   85,  597,  341,  853,
	 213,  725,  469,  981,   53,  565,  309,  821,  181,  693,  437,  949,
	 117,  629,  373,  885,  245,  757,  501, 1013,   13,  525,  269,  781,
	 141,  653,  397,  909,   77,  589,  333,  845,  205,  717,  461,  973,
	  45,  557,  301,  813,  173,  685,  429,  941,  109,  621,  365,  877,
	 237,  749,  493, 1005,   29,  541,  285,  797,  157,  669,  413,  925,
	  93,  605,  349,  861,  221,  733,  477,  989,   61,  573,  317,  829,
	 189,  701,  445,  957,  125,  637,  381,  893,  253,  765,  509, 1021,
	   3,  515,  259,  771,  131,  643,  387,  899,   67,  579,  323,  835,
	 195,  707,  451,  963,   35,  547,  291,  803,  163,  675,  419,  931,
	  99,  611,  355,  867,  227,  739,  483,  995,   19,  531,  275,  787,
	 147,  659,  403,  915,   83,  595,  339,  851,  211,  723,  467,  979,
	  51,  563,  307,  819,  179,  691,  435,  947,  115,  627,  371,  883,
	 243,  755,  499, 1011,   11,  523,  267,  779,  139,  651,  395,  907,
	  75,  587,  331,  843,  203,  715,  459,  971,   43,  555,  299,  811,
	 171,  683,  427,  939,  107,  619,  363,  875,  235,  747,  491, 1003,
	  27,  539,  283,  795,  155,  667,  411,  923,   91,  603,  347,  859,
	 219,  731,  475,  987,   59,  571,  315,  827,  187,  699,  443,  955,
	 123,  635,  379,  891,  251,  763,  507, 1019,    7,  519,  263,  775,
	 135,  647,  391,  903,   71,  583,  327,  839,  199,  711,  455,  967,
	  39,  551,  295,  807,  167,  679,  423,  935,  103,  615,  359,  871,
	 231,  743,  487,  999,   23,  535,  279,  791,  151,  663,  407,  919,
	  87,  599,  343,  855,  215,  727,  471,  983,   55,  567,  311,  823,
	 183,  695,  439,  951,  119,  631,  375,  887,  247,  759,  503, 1015,
	  15,  527,  271,  783,  143,  655,  399,  911,   79,  591,  335,  847,
	 207,  719,  463,  975,   47,  559,  303,  815,  175,  687,  431,  943,
	 111,  623,  367,  879,  239,  751,  495, 1007,   31,  543,  287,  799,
	 159,  671,  415,  927,   95,  607,  351,  863,  223,  735,  479,  991,
	  63,  575,  319,  831,  191,  703,  447,  959,  127,  639,  383,  895,
	 255,  767,  511, 1023
};

/*
 * Compute the roots for NTT and inverse NTT (binary case). Input
 * parameter g is a primitive 2048-th root of 1 modulo p (i.e. g^1024 =
 * -1 mod p). This fills gm[] and igm[] with powers of g and 1/g:
 *   gm[rev(i)] = g^i mod p
 *   igm[rev(i)] = (1/g)^i mod p
 * where rev() is the "bit reversal" function over 10 bits. It fills
 * the arrays only up to N = 2^logn values.
 *
 * The values stored in gm[] and igm[] are in Montgomery representation.
 *
 * p must be a prime such that p = 1 mod 2048.
 */
static void
modp_mkgm2(uint32_t *restrict gm, uint32_t *restrict igm, unsigned logn,
	uint32_t g, uint32_t p, uint32_t p0i)
{
	size_t u, n;
	unsigned k;
	uint32_t ig, x1, x2, R2;

	n = (size_t)1 << logn;

	/*
	 * We want g such that g^(2N) = 1 mod p, but the provided
	 * generator has order 2048. We must square it a few times.
	 */
	R2 = modp_R2(p, p0i);
	g = modp_montymul(g, R2, p, p0i);
	for (k = logn; k < 10; k ++) {
		g = modp_montymul(g, g, p, p0i);
	}

	ig = modp_div(R2, g, p, p0i, modp_R(p));
	k = 10 - logn;
	x1 = x2 = modp_R(p);
	for (u = 0; u < n; u ++) {
		size_t v;

		v = REV10[u << k];
		gm[v] = x1;
		igm[v] = x2;
		x1 = modp_montymul(x1, g, p, p0i);
		x2 = modp_montymul(x2, ig, p, p0i);
	}
}

/*
 * Compute the NTT over a polynomial (binary case). Polynomial elements
 * are a[0], a[stride], a[2 * stride]...
 */
static void
modp_NTT2_ext(uint32_t *a, size_t stride, const uint32_t *gm, unsigned logn,
	uint32_t p, uint32_t p0i)
{
	size_t t, m, n;

	if (logn == 0) {
		return;
	}
	n = (size_t)1 << logn;
	t = n;
	for (m = 1; m < n; m <<= 1) {
		size_t ht, u, v1;

		ht = t >> 1;
		for (u = 0, v1 = 0; u < m; u ++, v1 += t) {
			uint32_t s;
			size_t v;
			uint32_t *r1, *r2;

			s = gm[m + u];
			r1 = a + v1 * stride;
			r2 = r1 + ht * stride;
			for (v = 0; v < ht; v ++, r1 += stride, r2 += stride) {
				uint32_t x, y;

				x = *r1;
				y = modp_montymul(*r2, s, p, p0i);
				*r1 = modp_add(x, y, p);
				*r2 = modp_sub(x, y, p);
			}
		}
		t = ht;
	}
}

/*
 * Compute the inverse NTT over a polynomial (binary case).
 */
static void
modp_iNTT2_ext(uint32_t *a, size_t stride, const uint32_t *igm, unsigned logn,
	uint32_t p, uint32_t p0i)
{
	size_t t, m, n, k;
	uint32_t ni;
	uint32_t *r;

	if (logn == 0) {
		return;
	}
	n = (size_t)1 << logn;
	t = 1;
	for (m = n; m > 1; m >>= 1) {
		size_t hm, dt, u, v1;

		hm = m >> 1;
		dt = t << 1;
		for (u = 0, v1 = 0; u < hm; u ++, v1 += dt) {
			uint32_t s;
			size_t v;
			uint32_t *r1, *r2;

			s = igm[hm + u];
			r1 = a + v1 * stride;
			r2 = r1 + t * stride;
			for (v = 0; v < t; v ++, r1 += stride, r2 += stride) {
				uint32_t x, y;

				x = *r1;
				y = *r2;
				*r1 = modp_add(x, y, p);
				*r2 = modp_montymul(
					modp_sub(x, y, p), s, p, p0i);;
			}
		}
		t = dt;
	}

	/*
	 * We need 1/n in Montgomery representation, i.e. R/n. Since
	 * 1 <= logn <= 10, R/n is an integer; morever, R/n <= 2^30 < p,
	 * thus a simple shift will do.
	 * a modular reduction.
	 */
	ni = (uint32_t)1 << (31 - logn);
	for (k = 0, r = a; k < n; k ++, r += stride) {
		*r = modp_montymul(*r, ni, p, p0i);
	}
}

/*
 * Simplified macros for NTT and iNTT (binary case) when the elements
 * are consecutive in RAM.
 */
#define modp_NTT2(a, gm, logn, p, p0i)   modp_NTT2_ext(a, 1, gm, logn, p, p0i)
#define modp_iNTT2(a, igm, logn, p, p0i) modp_iNTT2_ext(a, 1, igm, logn, p, p0i)

/*
 * Compute the roots for NTT and inverse NTT (ternary case).
 *
 * Degree is 1.5*2^logn if 'full' is 1; otherwise, 'full' is 0 and the
 * degree is 2^logn.
 *
 * Input parameter g is a primitive 2304-th root of 1 modulo p (i.e.
 * g^1152 = -1 mod p).
 *
 * In the full case, for n = 768:
 *
 *  - Tables gm[] and igm[] have size 512 entries each.
 *
 *  - gm[256..511] contains the values g^k for k = 1 or 5 mod 6 and
 *    k < 768.
 *
 *  - For 1 <= j < 256, gm[j] contains the square of gm[2*j].
 *
 *  - gm[0] is a copy of gm[1].
 *
 *  - For j >= 1, igm[j] is the inverse of gm[j].
 *
 *  - igm[0] is the inverse of 2*gm[1]-1.
 *
 * For smaller degrees, everything is scaled down accordingly, and g
 * is repeatedly squared.
 *
 * In the partial case, tables gm[] and igm[] have size 2^logn, and
 * are the prefixes of the table for the full case for logn+1.
 */
static void
modp_mkgm3(uint32_t *restrict gm, uint32_t *restrict igm,
	unsigned logn, unsigned full,
	uint32_t g, uint32_t p, uint32_t p0i)
{
	size_t u;
	unsigned k;
	uint32_t R, R2, w, ig;

	R = modp_R(p);
	R2 = modp_R2(p, p0i);

	/*
	 * Square g as needed for the requested degree, and convert it
	 * to Montgomery representation. Also set ig = 1/g, also in
	 * Montgomery representation.
	 */
	g = modp_montymul(g, R2, p, p0i);
	k = logn;
	if (!full) {
		g = modp_montymul(g, modp_montymul(g, g, p, p0i), p, p0i);
		k ++;
	}
	while (k ++ < 9) {
		g = modp_montymul(g, g, p, p0i);
	}
	ig = modp_div(R2, g, p, p0i, modp_R(p));

	/*
	 * Fill the last row, using bit-reversal order.
	 */
	if (logn == 1) {
		gm[1] = g;
		igm[1] = ig;
	} else {
		uint32_t x, ix, g2, g4, ig2, ig4;
		size_t b;

		x = g;
		ix = ig;
		g2 = modp_montymul(g, g, p, p0i);
		g4 = modp_montymul(g2, g2, p, p0i);
		ig2 = modp_montymul(ig, ig, p, p0i);
		ig4 = modp_montymul(ig2, ig2, p, p0i);
		k = 11 - logn;
		b = (size_t)1 << (logn - 1);
		for (u = 0; u < b; u += 2) {
			gm[b + REV10[u << k]] = x;
			igm[b + REV10[u << k]] = ix;
			x = modp_montymul(x, g4, p, p0i);
			ix = modp_montymul(ix, ig4, p, p0i);
			gm[b + REV10[(u + 1) << k]] = x;
			igm[b + REV10[(u + 1) << k]] = ix;
			x = modp_montymul(x, g2, p, p0i);
			ix = modp_montymul(ix, ig2, p, p0i);
		}
	}

	/*
	 * If the table is full, then the next-to-last row contains the
	 * cubes of the last row.
	 */
	k = logn - 1;
	if (full) {
		k --;
		for (u = (size_t)1 << k; u < ((size_t)1 << (k + 1)); u ++) {
			uint32_t y, z;

			y = gm[u << 1];
			z = igm[u << 1];
			y = modp_montymul(y,
				modp_montymul(y, y, p, p0i), p, p0i);
			z = modp_montymul(z,
				modp_montymul(z, z, p, p0i), p, p0i);
			gm[u] = y;
			igm[u] = z;
		}
	}

	/*
	 * Fill other rows, with squares of the next one.
	 */
	for (u = ((size_t)1 << k) - 1; u > 0; u --) {
		size_t v;

		v = u << 1;
		gm[u] = modp_montymul(gm[v], gm[v], p, p0i);
		igm[u] = modp_montymul(igm[v], igm[v], p, p0i);
	}

	/*
	 * Comute top elements.
	 */
	gm[0] = gm[1];
	w = gm[1];
	igm[0] = modp_div(R2, modp_sub(modp_add(w, w, p), R, p), p, p0i, R);
}

/*
 * Compute the NTT over a polynomial (ternary case). If full is 1, then
 * the degree 1.5*2^logn; otherwise, the degree is 2^logn.
 */
static void
modp_NTT3_ext(uint32_t *a, size_t stride, const uint32_t *gm,
	unsigned logn, unsigned full, uint32_t p, uint32_t p0i)
{
	size_t n, hn, u, r, m, t;
	uint32_t w;
	uint32_t *r1, *r2;

	if (logn == 0) {
		return;
	}
	n = MKN(logn, full);
	hn = n >> 1;

	/*
	 * First pass: NTT over individual degree-1 polynomials modulo
	 * X^2-X+1. Roots are w (such that w != -1, and w^3 = -1) and w^5.
	 * Note that w^2 - w + 1 = 0, thus:
	 *
	 *  a(w) = a0 + a1*w
	 *  a(w^5) = a(-w^2)
	 *         = a0 + a1*(-w + 1)
	 *         = a0 + a1 - a1*w
	 */
	w = gm[1];
	for (u = 0, r1 = a, r2 = a + hn * stride;
		u < hn; u ++, r1 += stride, r2 += stride)
	{
		uint32_t a0, a1, b;

		a0 = *r1;
		a1 = *r2;
		b = modp_montymul(a1, w, p, p0i);
		*r1 = modp_add(a0, b, p);
		*r2 = modp_sub(modp_add(a0, a1, p), b, p);
	}

	/*
	 * Intermediate passes, for doubling the degree repeatedly.
	 */
	t = hn;
	for (m = 2; t > (1 + (full << 1)); m <<= 1) {
		size_t ht, u1, v1;

		ht = t >> 1;
		for (u1 = 0, v1 = 0; u1 < m; u1 ++, v1 += t) {
			size_t v;
			uint32_t s;

			s = gm[m + u1];
			r1 = a + v1 * stride;
			r2 = r1 + ht * stride;
			for (v = 0; v < ht; v ++, r1 += stride, r2 += stride) {
				uint32_t x, y;

				x = *r1;
				y = *r2;
				y = modp_montymul(y, s, p, p0i);
				*r1 = modp_add(x, y, p);
				*r2 = modp_sub(x, y, p);
			}
		}
		t = ht;
	}

	/*
	 * Final pass, to triple the degree.
	 */
	if (full) {
		w = modp_montymul(gm[1], gm[1], p, p0i);
		for (u = 0, r = (size_t)1 << (logn - 1), r1 = a;
			u < n; u += 3, r ++, r1 += 3 * stride)
		{
			uint32_t fA, fB, fC, fB0, fB1, fB2, fC0, fC1, fC2;
			uint32_t x, x2;

			x = gm[r];
			x2 = modp_montymul(x, x, p, p0i);
			fA = *r1;
			fB = *(r1 + stride);
			fC = *(r1 + 2 * stride);
			fB0 = modp_montymul(fB, x, p, p0i);
			fB1 = modp_montymul(fB0, w, p, p0i);
			fB2 = modp_montymul(fB1, w, p, p0i);
			fC0 = modp_montymul(fC, x2, p, p0i);
			fC1 = modp_montymul(fC0, w, p, p0i);
			fC2 = modp_montymul(fC1, w, p, p0i);
			*r1 = modp_add(fA,
				modp_add(fB0, fC0, p), p);
			*(r1 + stride) = modp_add(fA,
				modp_add(fB1, fC2, p), p);
			*(r1 + 2 * stride) = modp_add(fA,
				modp_add(fB2, fC1, p), p);
		}
	}
}

/*
 * Compute the inverse NTT over a polynomial (ternary case). If full is
 * 1, then the degree 1.5*2^logn; otherwise, the degree is 2^logn.
 */
static void
modp_iNTT3_ext(uint32_t *a, size_t stride, const uint32_t *igm,
	unsigned logn, unsigned full, uint32_t p, uint32_t p0i)
{
	size_t n, hn, u, r, m, t;
	uint32_t w, ni, R, *r1, *r2;

	if (logn == 0) {
		return;
	}
	n = MKN(logn, full);
	hn = n >> 1;

	/*
	 * Steps here correspond to the steps in modp_NTT3_ext(), in
	 * reverse order. However, computations leave a cumulative
	 * multiplicative factor, that must be cancelled out at the end.
	 */

	/*
	 * Divide degree by 3.
	 */
	if (full) {
		w = modp_montymul(igm[1], igm[1], p, p0i);
		for (u = 0, r = (size_t)1 << (logn - 1), r1 = a;
			u < n; u += 3, r ++, r1 += 3 * stride)
		{
			uint32_t f0, f1, f2, f11, f12, f21, f22;
			uint32_t x, x2;

			x = igm[r];
			x2 = modp_montymul(x, x, p, p0i);
			f0 = *r1;
			f1 = *(r1 + stride);
			f2 = *(r1 + 2 * stride);
			f11 = modp_montymul(f1, w, p, p0i);
			f12 = modp_montymul(f11, w, p, p0i);
			f21 = modp_montymul(f2, w, p, p0i);
			f22 = modp_montymul(f21, w, p, p0i);
			*r1 = modp_add(f0, modp_add(f1, f2, p), p);
			*(r1 + stride) = modp_montymul(x,
				modp_add(f0, modp_add(f11, f22, p), p), p, p0i);
			*(r1 + 2 * stride) = modp_montymul(x2,
				modp_add(f0, modp_add(f12, f21, p), p), p, p0i);
		}
	}

	/*
	 * Intermediate steps. The 't' and 'm' values have the same
	 * semantics as in NTT3, except that they are processed in
	 * reverse order. Note the invariant: t*m = n.
	 */
	t = 2 + (full << 2);
	for (m = (size_t)1 << (logn - 1 - full); t < n; m >>= 1) {
		size_t ht, u1, v1;

		ht = t >> 1;
		for (u1 = 0, v1 = 0; u1 < m; u1 ++, v1 += t) {
			size_t v;
			uint32_t s;

			s = igm[m + u1];
			r1 = a + v1 * stride;
			r2 = r1 + ht * stride;
			for (v = 0; v < ht; v ++, r1 += stride, r2 += stride) {
				uint32_t x, y;

				x = *r1;
				y = *r2;
				*r1 = modp_add(x, y, p);
				*r2 = modp_montymul(
					modp_sub(x, y, p), s, p, p0i);
			}
		}
		t <<= 1;
	}

	/*
	 * Final step: inverse NTT for polynomials modulo X^2-X+1.
	 */
	w = igm[0];
	for (u = 0, r1 = a, r2 = a + hn * stride;
		u < hn; u ++, r1 += stride, r2 += stride)
	{
		uint32_t a0, a1, b, c;

		a0 = *r1;
		a1 = *r2;
		b = modp_add(a0, a1, p);
		c = modp_montymul(w, modp_sub(a0, a1, p), p, p0i);
		*r1 = modp_sub(b, c, p);
		*r2 = modp_add(c, c, p);
	}

	/*
	 * Corrective factor: all values must be divided by n.
	 */
	R = modp_R(p);
	ni = modp_div(R, (uint32_t)n, p, p0i, R);
	for (u = 0, r1 = a; u < n; u ++, r1 += stride) {
		*r1 = modp_montymul(*r1, ni, p, p0i);
	}
}

/*
 * Simplified macros for NTT and iNTT (ternary case) when the elements
 * are consecutive in RAM.
 */
#define modp_NTT3(a, gm, logn, full, p, p0i) \
	modp_NTT3_ext(a, 1, gm, logn, full, p, p0i)
#define modp_iNTT3(a, igm, logn, full, p, p0i) \
	modp_iNTT3_ext(a, 1, igm, logn, full, p, p0i)

/*
 * Given polynomial f in NTT representation modulo p, compute f' of degree
 * less than N/2 such that f' = f0^2 - X*f1^2, where f0 and f1 are
 * polynomials of degree less than N/2 such that f = f0(X^2) + X*f1(X^2).
 *
 * The new polynomial is written "in place" over the first N/2 elements
 * of f.
 *
 * If applied logn times successively on a given polynomial, the resulting
 * degree-0 polynomial is the resultant of f and X^N+1 modulo p.
 *
 * This function applies only to the binary case; it is invoked from
 * solve_NTRU_binary_depth1().
 */
static void
modp_poly_rec_res(uint32_t *f, unsigned logn,
	uint32_t p, uint32_t p0i, uint32_t R2)
{
	size_t hn, u;

	hn = (size_t)1 << (logn - 1);
	for (u = 0; u < hn; u ++) {
		uint32_t w0, w1;

		w0 = f[(u << 1) + 0];
		w1 = f[(u << 1) + 1];
		f[u] = modp_montymul(modp_montymul(w0, w1, p, p0i), R2, p, p0i);
	}
}

/* ==================================================================== */
/*
 * Custom bignum implementation.
 *
 * This is a very reduced set of functionalities. We need to do the
 * following operations:
 *
 *  - Rebuild the resultant and the polynomial coefficients from their
 *    values modulo small primes (of length 31 bits each).
 *
 *  - Compute an extended GCD between the two computed resultants.
 *
 *  - Extract top bits and add scaled values during the successive steps
 *    of Babai rounding.
 *
 * When rebuilding values using CRT, we must also recompute the product
 * of the small prime factors. We always do it one small factor at a
 * time, so the "complicated" operations can be done modulo the small
 * prime with the modp_* functions. CRT coefficients (inverses) can be
 * precomputed.
 *
 * All values are positive until the last step: when the polynomial
 * coefficients have been rebuilt, we normalize them around 0. But then,
 * only additions and subtractions on the upper few bits are needed
 * afterwards.
 *
 * We keep big integers as arrays of 31-bit words (in uint32_t values);
 * the top bit of each uint32_t is kept equal to 0. Using 31-bit words
 * makes it easier to track carries. When negative values are used,
 * two's complement is used.
 */

/*
 * Add integer b to integer a. Both integers are supposed to have the
 * same size, and the result should fit in that size as well. The carry
 * is returned. Source arrays a and b MUST be distinct.
 */
static uint32_t
zint_add(uint32_t *restrict a, const uint32_t *restrict b, size_t len)
{
	size_t u;
	uint32_t cc;

	cc = 0;
	for (u = 0; u < len; u ++) {
		uint32_t w;

		w = a[u] + b[u] + cc;
		a[u] = w & 0x7FFFFFFF;
		cc = w >> 31;
	}
	return cc;
}

/*
 * Subtract integer b from integer a. Both integers are supposed to have
 * the same size. The carry (0 or 1) is returned. Source arrays a and b
 * MUST be distinct.
 */
static uint32_t
zint_sub(uint32_t *restrict a, const uint32_t *restrict b, size_t len)
{
	size_t u;
	uint32_t cc;

	cc = 0;
	for (u = 0; u < len; u ++) {
		uint32_t w;

		w = a[u] - b[u] - cc;
		a[u] = w & 0x7FFFFFFF;
		cc = w >> 31;
	}
	return cc;
}

/*
 * Mutiply the provided big integer m with a small value x.
 * This function assumes that x < 2^31. The carry word is returned.
 */
static uint32_t
zint_mul_small(uint32_t *m, size_t mlen, uint32_t x)
{
	size_t u;
	uint32_t cc;

	cc = 0;
	for (u = 0; u < mlen; u ++) {
		uint64_t z;

		z = (uint64_t)m[u] * (uint64_t)x + cc;
		m[u] = (uint32_t)z & 0x7FFFFFFF;
		cc = (uint32_t)(z >> 31);
	}
	return cc;
}

/*
 * Reduce a big integer d modulo a small integer p.
 * Rules:
 *  d is unsigned
 *  p is prime
 *  2^30 < p < 2^31
 *  p0i = -(1/p) mod 2^31
 *  R2 = 2^62 mod p
 */
static uint32_t
zint_mod_small_unsigned(const uint32_t *d, size_t dlen,
	uint32_t p, uint32_t p0i, uint32_t R2)
{
	uint32_t x;
	size_t u;

	/*
	 * Algorithm: we inject words one by one, starting with the high
	 * word. Each step is:
	 *  - multiply x by 2^31
	 *  - add new word
	 */
	x = 0;
	u = dlen;
	while (u -- > 0) {
		uint32_t w;

		x = modp_montymul(x, R2, p, p0i);
		w = d[u] - p;
		w += p & -(w >> 31);
		x = modp_add(x, w, p);
	}
	return x;
}

/*
 * Similar to zint_mod_small_unsigned(), except that d may be signed.
 * Extra parameter is Rx = 2^(31*dlen) mod p.
 */
static uint32_t
zint_mod_small_signed(const uint32_t *d, size_t dlen,
	uint32_t p, uint32_t p0i, uint32_t R2, uint32_t Rx)
{
	uint32_t z;

	if (dlen == 0) {
		return 0;
	}
	z = zint_mod_small_unsigned(d, dlen, p, p0i, R2);
	z = modp_sub(z, Rx & -(d[dlen - 1] >> 30), p);
	return z;
}

/*
 * Add y*s to x. x and y initially have length 'len' words; the new x
 * has length 'len+1' words. 's' must fit on 31 bits.
 */
static void
zint_add_mul_small(uint32_t *restrict x,
	const uint32_t *restrict y, size_t len, uint32_t s)
{
	size_t u;
	uint32_t cc;

	cc = 0;
	for (u = 0; u < len; u ++) {
		uint32_t xw, yw;
		uint64_t z;

		xw = x[u];
		yw = y[u];
		z = (uint64_t)yw * (uint64_t)s + (uint64_t)xw + (uint64_t)cc;
		x[u] = (uint32_t)z & 0x7FFFFFFF;
		cc = (uint32_t)(z >> 31);
	}
	x[len] = cc;
}

/*
 * Right-shift an _unsigned_ integer by one bit. The least significant
 * bit is returned. The new integer length is returned.
 */
static uint32_t
zint_rshift1(uint32_t *d, size_t len)
{
	uint32_t cc;
	size_t k;

	cc = 0;
	k = len;
	while (k -- > 0) {
		uint32_t w;

		w = d[k];
		d[k] = (w >> 1) | (cc << 30);
		cc = w & 1;
	}
	return cc;
}

/*
 * Halve integer x modulo integer p. The modulus p MUST be odd.
 */
static void
zint_rshift1_mod(uint32_t *restrict x, const uint32_t *restrict p, size_t len)
{
	uint32_t hi;

	if ((x[0] & 1) != 0) {
		hi = zint_add(x, p, len);
	} else {
		hi = 0;
	}
	zint_rshift1(x, len);
	x[len - 1] |= hi << 30;
}

/*
 * Subtract y from x, modulo p.
 */
static void
zint_sub_mod(uint32_t *restrict x, const uint32_t *restrict y,
	const uint32_t *restrict p, size_t len)
{
	if (zint_sub(x, y, len)) {
		zint_add(x, p, len);
	}
}

/*
 * Compare a with b. Both integers are unsigned and have the same encoded
 * length.
 */
static int
zint_ucmp(const uint32_t *a, const uint32_t *b, size_t len)
{
	while (len -- > 0) {
		uint32_t wa, wb;

		wa = a[len];
		wb = b[len];
		if (wa < wb) {
			return -1;
		}
		if (wa > wb) {
			return 1;
		}
	}
	return 0;
}

/*
 * Normalize a modular integer around 0: if x > p/2, then x is replaced
 * with x - p (signed encoding with two's complement); otherwise, x is
 * untouched. The two integers x and p are encoded over the same length.
 */
static void
zint_norm_zero(uint32_t *restrict x, const uint32_t *restrict p, size_t len)
{
	uint32_t cc;
	size_t u;

	cc = 0;
	u = len;
	while (u -- > 0) {
		uint32_t w;

		w = (p[u] >> 1) | (cc << 30);
		cc = p[u] & 1;
		if (x[u] < w) {
			return;
		}
		if (x[u] > w) {
			zint_sub(x, p, len);
			return;
		}
	}
}

/*
 * Rebuild integers from their RNS representation. There are 'num'
 * integers, and each consists in 'xlen' words. 'xx' points at that
 * first word of the first integer; subsequent integers are accessed
 * by adding 'xstride' repeatedly.
 *
 * The words of an integer are the RNS representation of that integer,
 * using the provided 'primes' are moduli. This function replaces
 * each integer with its multi-word value (little-endian order).
 *
 * If "normalize_signed" is non-zero, then the returned value is
 * normalized to the -m/2..m/2 interval (where m is the product of all
 * small prime moduli); two's complement is used for negative values.
 */
static void
zint_rebuild_CRT(uint32_t *restrict xx, size_t xlen, size_t xstride,
	size_t num, const small_prime *primes, int normalize_signed,
	uint32_t *restrict tmp)
{
	size_t u;
	uint32_t *x;

	tmp[0] = primes[0].p;
	for (u = 1; u < xlen; u ++) {
		/*
		 * At the entry of each loop iteration:
		 *  - the first u words of each array have been
		 *    reassembled;
		 *  - the first u words of tmp[] contains the
		 * product of the prime moduli processed so far.
		 *
		 * We call 'q' the product of all previous primes.
		 */
		uint32_t p, p0i, s, R2;
		size_t v;

		p = primes[u].p;
		s = primes[u].s;
		p0i = modp_ninv31(p);
		R2 = modp_R2(p, p0i);

		for (v = 0, x = xx; v < num; v ++, x += xstride) {
			uint32_t xp, xq, xr;
			/*
			 * xp = the integer x modulo the prime p for this
			 *      iteration
			 * xq = (x mod q) mod p
			 */
			xp = x[u];
			xq = zint_mod_small_unsigned(x, u, p, p0i, R2);

			/*
			 * New value is (x mod q) + q * (s * (xp - xq) mod p)
			 */
			xr = modp_montymul(s, modp_sub(xp, xq, p), p, p0i);
			zint_add_mul_small(x, tmp, u, xr);
		}

		/*
		 * Update product of primes in tmp[].
		 */
		tmp[u] = zint_mul_small(tmp, u, p);
	}

	/*
	 * Normalize the reconstructed values around 0.
	 */
	if (normalize_signed) {
		for (u = 0, x = xx; u < num; u ++, x += xstride) {
			zint_norm_zero(x, tmp, xlen);
		}
	}
}

/*
 * Compute exact length of an integer (i.e. reduce it to remove high
 * words of value 0).
 */
static size_t
zint_exact_length(const uint32_t *x, size_t xlen)
{
	while (xlen > 0) {
		if (x[xlen - 1] != 0) {
			return xlen;
		}
		xlen --;
	}
	return xlen;
}

/*
 * Replace a with (a*xa+b*xb)/(2^31) and b with (a*ya+b*yb)/(2^31).
 * The low bits are dropped (the caller should compute the coefficients
 * such that these dropped bits are all zeros). If either or both
 * yields a negative value, then the value is negated.
 *
 * Returned value is:
 *  0  both values were positive
 *  1  new a had to be negated
 *  2  new b had to be negated
 *  3  both new a and new b had to be negated
 *
 * Coefficients xa, xb, ya and yb may use the full signed 32-bit range.
 */
static int
zint_co_reduce(uint32_t *a, uint32_t *b, size_t len,
	int32_t xa, int32_t xb, int32_t ya, int32_t yb)
{
	size_t u;
	int32_t cca, ccb;
	int r;

	cca = 0;
	ccb = 0;
	for (u = 0; u < len; u ++) {
		int32_t wa, wb;
		int64_t za, zb;
		uint32_t tta, ttb;

		wa = (int32_t)a[u];
		wb = (int32_t)b[u];
		za = (int64_t)wa * xa + (int64_t)wb * xb + cca;
		zb = (int64_t)wa * ya + (int64_t)wb * yb + ccb;
		if (u > 0) {
			a[u - 1] = (uint32_t)za & 0x7FFFFFFF;
			b[u - 1] = (uint32_t)zb & 0x7FFFFFFF;
		}
		tta = (uint32_t)((uint64_t)za >> 31);
		ttb = (uint32_t)((uint64_t)zb >> 31);
		cca = *(int32_t *)&tta;
		ccb = *(int32_t *)&ttb;
	}
	a[len - 1] = (uint32_t)cca;
	b[len - 1] = (uint32_t)ccb;
	r = 0;
	if (cca < 0) {
		uint32_t c;

		c = 1;
		for (u = 0; u < len; u ++) {
			uint32_t w;

			w = c + ~a[u];
			a[u] = w & 0x7FFFFFFF;
			c = (~w) >> 31;
		}
		r |= 1;
	}
	if (ccb < 0) {
		uint32_t c;

		c = 1;
		for (u = 0; u < len; u ++) {
			uint32_t w;

			w = c + ~b[u];
			b[u] = w & 0x7FFFFFFF;
			c = (~w) >> 31;
		}
		r |= 2;
	}

	return r;
}

/*
 * Replace a with (a*xa+b*xb)/(2^31) mod m, and b with
 * (a*ya+b*yb)/(2^31) mod m. Modulus m must be odd; m0i = -1/m[0] mod 2^31.
 */
static void
zint_co_reduce_mod(uint32_t *a, uint32_t *b, const uint32_t *m, size_t len,
	uint32_t m0i, int32_t xa, int32_t xb, int32_t ya, int32_t yb)
{
	size_t u;
	uint32_t fx, fy;
	int64_t cca, ccb;

	/*
	 * These are actually four combined Montgomery multiplications.
	 */
	fx = ((a[0] * (uint32_t)xa + b[0] * (uint32_t)xb) * m0i) & 0x7FFFFFFF;
	fy = ((a[0] * (uint32_t)ya + b[0] * (uint32_t)yb) * m0i) & 0x7FFFFFFF;
	cca = 0;
	ccb = 0;
	for (u = 0; u < len; u ++) {
		uint32_t wa, wb;
		int64_t za, zb;
		uint64_t tta, ttb;

		wa = a[u];
		wb = b[u];
		za = (int64_t)wa * (int64_t)xa + (int64_t)wb * (int64_t)xb;
		zb = (int64_t)wa * (int64_t)ya + (int64_t)wb * (int64_t)yb;
		za += cca;
		zb += ccb;
		za += (uint64_t)m[u] * (uint64_t)fx;
		zb += (uint64_t)m[u] * (uint64_t)fy;
		if (u > 0) {
			a[u - 1] = (uint32_t)za & 0x7FFFFFFF;
			b[u - 1] = (uint32_t)zb & 0x7FFFFFFF;
		}

		/*
		 * Weird code below is a sign-extension. We want to
		 * perform an arithmetic shift, but the C standard does
		 * not guarantee that right-shifting signed negative
		 * values performs an arithmetic shift (it's
		 * "implementation-defined").
		 */
#define M   ((uint64_t)1 << 32)
		tta = (uint64_t)za >> 31;
		ttb = (uint64_t)zb >> 31;
		tta = (tta ^ M) - M;
		ttb = (ttb ^ M) - M;
		cca = *(int64_t *)&tta;
		ccb = *(int64_t *)&ttb;
#undef M
	}
	a[len - 1] = (uint32_t)cca & 0x7FFFFFFF;
	b[len - 1] = (uint32_t)ccb & 0x7FFFFFFF;

	/*
	 * For each value a and b:
	 *  - if negative, add modulus
	 *  - if positive and not lower than modulus, subtract modulus
	 */
	if (cca < 0) {
		zint_add(a, m, len);
	} else {
		if (zint_ucmp(a, m, len) >= 0) {
			zint_sub(a, m, len);
		}
	}
	if (ccb < 0) {
		zint_add(b, m, len);
	} else {
		if (zint_ucmp(b, m, len) >= 0) {
			zint_sub(b, m, len);
		}
	}
}

/*
 * Replace a with (a+k*b)/(2^31). If the result it negative, then it is
 * negated and 1 is returned; otherwise, 0 is returned.
 */
static int
zint_reduce(uint32_t *a, const uint32_t *b, size_t len, int32_t k)
{
	size_t u;
	int32_t cc;

	cc = 0;
	for (u = 0; u < len; u ++) {
		int32_t wa, wb;
		int64_t z;
		uint32_t tt;

		wa = (int32_t)a[u];
		wb = (int32_t)b[u];
		z = (int64_t)wb * k + (int64_t)wa + cc;
		if (u > 0) {
			a[u - 1] = (uint32_t)z & 0x7FFFFFFF;
		}
		tt = (uint32_t)((uint64_t)z >> 31);
		cc = *(int32_t *)&tt;
	}
	a[len - 1] = (uint32_t)cc;
	if (cc < 0) {
		uint32_t c;

		c = 1;
		for (u = 0; u < len; u ++) {
			uint32_t w;

			w = c + ~a[u];
			a[u] = w & 0x7FFFFFFF;
			c = (~w) >> 31;
		}
		return 1;
	} else {
		return 0;
	}
}

/*
 * Replace a with (a+k*b)/(2^31) mod m.
 * Modulus m must be odd; m0i = -1/m[0] mod 2^31.
 */
static void
zint_reduce_mod(uint32_t *a, const uint32_t *b, const uint32_t *m,
	size_t len, uint32_t m0i, int32_t k)
{
	size_t u;
	uint32_t f;
	int32_t cc;

	f = ((a[0] + b[0] * (uint32_t)k) * m0i) & 0x7FFFFFFF;
	cc = 0;
	for (u = 0; u < len; u ++) {
		uint32_t wa, wb;
		int64_t z;
		uint32_t tt;

		wa = a[u];
		wb = b[u];
		z = (int64_t)wa + (int64_t)wb * (int64_t)k + cc;
		z += (uint64_t)m[u] * (uint64_t)f;
		if (u > 0) {
			a[u - 1] = (uint32_t)z & 0x7FFFFFFF;
		}
		tt = (uint32_t)((uint64_t)z >> 31);
		cc = *(int32_t *)&tt;
	}
	a[len - 1] = (uint32_t)cc & 0x7FFFFFFF;

	/*
	 * - if negative, add modulus
	 * - if positive and not lower than modulus, subtract modulus
	 */
	if (cc < 0) {
		zint_add(a, m, len);
	} else {
		if (zint_ucmp(a, m, len) >= 0) {
			zint_sub(a, m, len);
		}
	}
}

/*
 * Compute a GCD between two positive big integers x and y. The two
 * integers must be odd. Returned value is 1 if the GCD is 1, 0
 * otherwise. When 1 is returned, arrays u and v are filled with values
 * such that:
 *   0 <= u <= y
 *   0 <= v <= x
 *   x*u - y*v = 1
 * x[] and y[] are unmodified. Both input values must have the same
 * encoded length. Temporary array must be large enough to accommodate 4
 * extra values of that length. Arrays u, v and tmp may not overlap with
 * each other, or with either x or y.
 */
static int
zint_bezout(uint32_t *restrict u, uint32_t *restrict v,
	const uint32_t *restrict x, const uint32_t *restrict y,
	size_t len, uint32_t *restrict tmp)
{
	uint32_t *u0, *u1, *v0, *v1, *a, *b;
	size_t xlen, ylen, alen, blen, mlen;
	uint32_t x0i, y0i;

	/*
	 * Algorithm is an extended binary GCD. We maintain 6 values
	 * a, b, u0, u1, v0 and v1 with the following invariants:
	 *
	 *  a = x*u0 - y*v0
	 *  b = x*u1 - y*v1
	 *  0 <= u0 < y
	 *  0 <= v0 < x
	 *  0 <= u1 <= y
	 *  0 <= v1 <= x
	 *
	 * Initial values are:
	 *
	 *  a = x   u0 = 1   v0 = 0
	 *  b = y   u1 = y   v1 = x-1
	 *
	 * Each iteration reduces either a or b, and maintain the
	 * invariants. Algorithm stops when a = b, at which point their
	 * common value is GCD(a,b) and (u0,v0) (or (u1,v1)) contains
	 * the values (u,v) we want to return.
	 *
	 * We must handle specially the cases of x = 1 or y = 1, which
	 * make the solution trivial. If x > 1 and y > 1, and GCD(x,y) = 1,
	 * then there will be a solution (u,v) such that 0 < u < y and
	 * 0 < v < x (it can be shown that u = 1/x mod y and v = -1/y mod x).
	 */

	u0 = u;
	v0 = v;
	u1 = tmp;
	v1 = u1 + len;
	a = v1 + len;
	b = a + len;

	/*
	 * Compute actual lengths of x and y.
	 */
	xlen = zint_exact_length(x, len);
	ylen = zint_exact_length(y, len);

	/*
	 * Filter out bad values:
	 *   x and y must not be zero.
	 *   x and y must be odd.
	 */
	if (xlen == 0 || ylen == 0 || (x[0] & y[0] & 1) == 0) {
		return 0;
	}

	/*
	 * Initialize a, b, u0, u1, v0 and v1.
	 *  a = x   u0 = 1   v0 = 0
	 *  b = y   u1 = y   v1 = x-1
	 * Note that x is odd, so computing x-1 is easy.
	 */
	memcpy(a, x, xlen * sizeof *x);
	memcpy(b, y, ylen * sizeof *y);
	alen = xlen;
	blen = ylen;
	u0[0] = 1;
	memset(u0 + 1, 0, (ylen - 1) * sizeof *u0);
	memset(v0, 0, xlen * sizeof *v0);
	memcpy(u1, y, ylen * sizeof *u1);
	memcpy(v1, x, xlen * sizeof *v1);
	v1[0] &= ~(uint32_t)1;

	/*
	 * We also zero out the upper unused words of the returned array
	 * u and v (caller expects it).
	 */
	memset(u + ylen, 0, (len - ylen) * sizeof *u);
	memset(v + xlen, 0, (len - xlen) * sizeof *v);

	/*
	 * We zero out the upper unused words of a and b as well, so that
	 * we may subtract one from the other with a common length.
	 */
	mlen = alen < blen ? blen : alen;
	memset(a + alen, 0, (mlen - alen) * sizeof *a);
	memset(b + blen, 0, (mlen - blen) * sizeof *b);

	/*
	 * If x = 1 then the current values in u and v are just fine
	 * and we can return them (because u0 and u are the same array,
	 * and similarly v0 and v).
	 * If y = 1, then the values in u1 and v1 must be returned.
	 */
	if (xlen == 1 && x[0] == 1) {
		return 1;
	}
	if (ylen == 1 && y[0] == 1) {
		memcpy(u, u1, ylen * sizeof *u);
		memcpy(v, v1, xlen * sizeof *v);
		return 1;
	}

	x0i = modp_ninv31(x[0]);
	y0i = modp_ninv31(y[0]);

	/*
	 * We are now all set for the main algorithm.
	 */
	for (;;) {
		int r;

		/*
		 * If either word is large enough, we use the
		 * accelerated approximation.
		 */
		if (alen >= 3 || blen >= 3) {
			size_t len;
			uint64_t a_hi, b_hi;
			uint32_t a_lo, b_lo;
			uint32_t uxa, uya, uxb, uyb;
			int i, r;

			len = alen < blen ? blen : alen;

			/*
			 * Get the top and low bits of each value.
			 */
			a_hi = ((uint64_t)a[len - 1] << 31) | a[len - 2];
			b_hi = ((uint64_t)b[len - 1] << 31) | b[len - 2];
			a_lo = a[0];
			b_lo = b[0];
			uxa = 1;
			uxb = 0;
			uya = 0;
			uyb = 1;
			for (i = 0; i < 31; i ++) {
				uint32_t m;

				m = (uint32_t)1 << i;
				if ((a_lo & m) == 0) {
					a_hi >>= 1;
					b_lo <<= 1;
					uya <<= 1;
					uyb <<= 1;
				} else if ((b_lo & m) == 0) {
					b_hi >>= 1;
					a_lo <<= 1;
					uxa <<= 1;
					uxb <<= 1;
				} else if (a_hi > b_hi) {
					a_hi -= b_hi;
					a_lo -= b_lo;
					uxa -= uya;
					uxb -= uyb;
					a_hi >>= 1;
					b_lo <<= 1;
					uya <<= 1;
					uyb <<= 1;
				} else {
					b_hi -= a_hi;
					b_lo -= a_lo;
					uya -= uxa;
					uyb -= uxb;
					b_hi >>= 1;
					a_lo <<= 1;
					uxa <<= 1;
					uxb <<= 1;
				}
			}

			/*
			 * It may happen that one of the factors is
			 * equal to 2^31. In that case, we must use a
			 * specialized function, because that value will
			 * not fit in an int32_t.
			 */
			if (uxa == 0x80000000) {
				int32_t ya;

				if (uxb != 0 || uyb != 1) {
					return 0;
				}
				ya = *(int32_t *)&uya;
				if (zint_reduce(b, a, len, ya)) {
					ya = -ya;
				}
				zint_reduce_mod(u1, u0, y, ylen, y0i, ya);
				zint_reduce_mod(v1, v0, x, xlen, x0i, ya);
			} else if (uyb == 0x80000000) {
				int32_t xb;

				if (uya != 0 || uxa != 1) {
					return 0;
				}
				xb = *(int32_t *)&uxb;
				if (zint_reduce(a, b, len, xb)) {
					xb = -xb;
				}
				zint_reduce_mod(u0, u1, y, ylen, y0i, xb);
				zint_reduce_mod(v0, v1, x, xlen, x0i, xb);
			} else {
				int32_t xa, xb, ya, yb;

				xa = *(int32_t *)&uxa;
				xb = *(int32_t *)&uxb;
				ya = *(int32_t *)&uya;
				yb = *(int32_t *)&uyb;

				r = zint_co_reduce(a, b, len, xa, xb, ya, yb);
				if ((r & 1) != 0) {
					xa = -xa;
					xb = -xb;
				}
				if ((r & 2) != 0) {
					ya = -ya;
					yb = -yb;
				}
				zint_co_reduce_mod(u0, u1, y, ylen, y0i,
					xa, xb, ya, yb);
				zint_co_reduce_mod(v0, v1, x, xlen, x0i,
					xa, xb, ya, yb);
			}
			alen = zint_exact_length(a, alen);
			blen = zint_exact_length(b, blen);

			continue;
		}

		/*
		 * If a is even, divide it by 2 and adjust u0 and v0.
		 */
		if ((a[0] & 1) == 0) {
			zint_rshift1(a, alen);
			alen = zint_exact_length(a, alen);
			zint_rshift1_mod(u0, y, ylen);
			zint_rshift1_mod(v0, x, xlen);
			continue;
		}

		/*
		 * If b is even, divide it by 2 and adjust u1 and v1.
		 */
		if ((b[0] & 1) == 0) {
			zint_rshift1(b, blen);
			blen = zint_exact_length(b, blen);
			zint_rshift1_mod(u1, y, ylen);
			zint_rshift1_mod(v1, x, xlen);
			continue;
		}

		/*
		 * Compare a to b. If equal, then the algorithm
		 * terminates.
		 */
		if (alen < blen) {
			r = -1;
		} else if (alen > blen) {
			r = 1;
		} else {
			r = zint_ucmp(a, b, alen);
			if (r == 0) {
				/*
				 * If a == b, then the algorithm terminate;
				 * they both contain the GCD of x and y.
				 * This is a success only if that GCD is 1.
				 * Arrays u and v are already filled with
				 * the proper results.
				 */
				return alen == 1 && a[0] == 1;
			}
		}

		/*
		 * If a > b, then set a <- a-b, and adjust u0 and v0
		 * accordingly. Analysis shows that we will be able to
		 * maintain 0 < u0 < y and 0 < v0 < x.
		 *
		 * If a < b, then set b <- b-a, and adjust u1 and v1
		 * accordingly. Analysis shows that we will be able to
		 * maintain 0 < u1 < y and 0 < v1 < x.
		 */
		if (r > 0) {
			zint_sub(a, b, alen);
			alen = zint_exact_length(a, alen);
			zint_sub_mod(u0, u1, y, ylen);
			zint_sub_mod(v0, v1, x, xlen);
		} else {
			zint_sub(b, a, blen);
			blen = zint_exact_length(b, blen);
			zint_sub_mod(u1, u0, y, ylen);
			zint_sub_mod(v1, v0, x, xlen);
		}
	}
}

/*
 * Compute bit length of a word. Input word x must have length at most 31
 * bits (i.e. top bit is cleared).
 */
unsigned
bitlength(uint32_t x)
{
	/*
	 * This algorithm is inspired from an algorithm devised by
	 * Robert Harley and explained in Hacker's Delight, 2nd edition
	 * (section 5.3).
	 *
	 * We first propagate the highest non-zero bit to the right, so
	 * that the value becomes equal to 2^bl-1; at that point, we thus
	 * have 32 possible values for x (0, and powers of 2 from 2^0 to
	 * 2^30). Then, we multiply the value with a specific constant
	 * that makes it so that the top 5 bits of the 32-bit result will
	 * contain 32 different values for the 32 possible values of x
	 * at this point. These top 5 bits thus contain a permutation of
	 * the 0..31 result we need; a table look-up implements the
	 * reverse permutation.
	 */
	static const unsigned vv[] = {
		 0, 31,  4,  5,  6, 10,  7, 15,
		11, 20,  8, 18, 16, 25, 12, 27,
		21, 30,  3,  9, 14, 19, 17, 24,
		26, 29,  2, 13, 23, 28,  1, 22
	};

	x |= x >> 1;
	x |= x >> 2;
	x |= x >> 4;
	x |= x >> 8;
	x |= x >> 16;
	return vv[(x * 0xF04653AE) >> 27];
}

/*
 * Get the bit length of a signed big integer: this is the minimum number
 * of bits required to hold the value, _without_ the signed bit (thus, -1
 * has bit length 0).
 */
static uint32_t
zint_signed_bit_length(const uint32_t *x, size_t xlen)
{
	uint32_t sign;

	if (xlen == 0) {
		return 0;
	}
	sign = (-(x[xlen - 1] >> 30)) >> 1;
	while (xlen > 0) {
		if (x[xlen - 1] != sign) {
			break;
		}
		xlen --;
	}
	if (xlen == 0) {
		return 0;
	}
	return (uint32_t)(xlen - 1) * 31 + bitlength(x[xlen - 1] ^ sign);
}

/*
 * Get the top 63 bits of a signed big integer, starting at the provided
 * index (in bits). The integer absolute value MUST fit in sc+63 bits.
 */
static int64_t
zint_get_top(const uint32_t *x, size_t xlen, uint32_t sc)
{
	uint64_t z;
	uint32_t sign, w0, w1, w2;
	uint32_t k, off;

	if (xlen == 0) {
		return 0;
	}

	/*
	 * The "sign word" is -1 for negative values, 0 for positive values.
	 */
	sign = -(x[xlen - 1] >> 30);

	k = sc / 31;
	off = sc - (31 * k);

	/*
	 * To obtain 63 bits, we always need exactly three words.
	 */
	if ((k + 2) < xlen) {
		w0 = x[k + 0];
		w1 = x[k + 1];
		w2 = x[k + 2] | (sign << 31);
	} else if ((k + 1) < xlen) {
		w0 = x[k + 0];
		w1 = x[k + 1];
		w2 = sign;
	} else if (k < xlen) {
		w0 = x[k + 0];
		w1 = sign;
		w2 = sign;
	} else {
		w0 = sign;
		w1 = sign;
		w2 = sign;
	}
	z = ((uint64_t)w0 >> off)
		| ((uint64_t)w1 << (31 - off))
		| ((uint64_t)w2 << (62 - off));

	/*
	 * Properties of the exact-width types (no padding, no trap
	 * representation, two's complement representation) means that
	 * we can use a cast on the in-memory representation to
	 * convert from unsigned to signed values, without incurring
	 * any undefined behaviour.
	 */
	return *(int64_t *)&z;
}

/*
 * Add k*y*2^sc to x. The result is assumed to fit in the array of
 * size xlen (truncation is applied if necessary).
 * Scale factor 'sc' is provided as sch and scl, such that:
 *   sch = sc / 31
 *   scl = sc % 31
 * xlen MUST NOT be lower than ylen.
 *
 * x[] and y[] are both signed integers, using two's complement for
 * negative values.
 */
static void
zint_add_scaled_mul_small(uint32_t *restrict x, size_t xlen,
	const uint32_t *restrict y, size_t ylen, int32_t k,
	uint32_t sch, uint32_t scl)
{
	size_t u;
	uint32_t ysign, tw;
	int32_t cc;

	if (ylen == 0) {
		return;
	}

	ysign = -(y[ylen - 1] >> 30) >> 1;
	tw = 0;
	cc = 0;
	for (u = sch; u < xlen; u ++) {
		size_t v;
		uint32_t wy, wys, ccu;
		uint64_t z;

		/*
		 * Get the next word of y (scaled).
		 */
		v = u - sch;
		wy = v < ylen ? y[v] : ysign;
		wys = ((wy << scl) & 0x7FFFFFFF) | tw;
		tw = wy >> (31 - scl);

		/*
		 * The expression below does not overflow.
		 */
		z = (int64_t)wys * (int64_t)k + (int64_t)x[u] + cc;
		x[u] = (uint32_t)z & 0x7FFFFFFF;

		/*
		 * Right-shifting the signed value z would yield
		 * implementation-defined results (arithmetic shift is
		 * not guaranteed). However, we can cast to unsigned,
		 * and get the next carry as an unsigned word. We can
		 * then convert it back to signed by using the guaranteed
		 * fact that 'int32_t' uses two's complement with no
		 * trap representation or padding bit, and with a layout
		 * compatible with that of 'uint32_t'.
		 */
		ccu = (uint32_t)((uint64_t)z >> 31);
		cc = *(int32_t *)&ccu;
	}
}

/*
 * Subtract y*2^sc from x. The result is assumed to fit in the array of
 * size xlen (truncation is applied if necessary).
 * Scale factor 'sc' is provided as sch and scl, such that:
 *   sch = sc / 31
 *   scl = sc % 31
 * xlen MUST NOT be lower than ylen.
 *
 * x[] and y[] are both signed integers, using two's complement for
 * negative values.
 */
static void
zint_sub_scaled(uint32_t *restrict x, size_t xlen,
	const uint32_t *restrict y, size_t ylen, uint32_t sch, uint32_t scl)
{
	size_t u;
	uint32_t ysign, tw;
	uint32_t cc;

	if (ylen == 0) {
		return;
	}

	ysign = -(y[ylen - 1] >> 30) >> 1;
	tw = 0;
	cc = 0;
	for (u = sch; u < xlen; u ++) {
		size_t v;
		uint32_t w, wy, wys;

		/*
		 * Get the next word of y (scaled).
		 */
		v = u - sch;
		wy = v < ylen ? y[v] : ysign;
		wys = ((wy << scl) & 0x7FFFFFFF) | tw;
		tw = wy >> (31 - scl);

		w = x[u] - wys - cc;
		x[u] = w & 0x7FFFFFFF;
		cc = w >> 31;
	}
}

/*
 * Convert a one-word signed big integer into a signed value.
 */
static inline int32_t
zint_one_to_plain(const uint32_t *x)
{
	uint32_t w;

	w = x[0];
	w |= (w & 0x40000000) << 1;
	return *(int32_t *)&w;
}

/* ==================================================================== */

/*
 * Get the maximum bitlength of coordinates for a polynomial.
 */
static uint32_t
poly_max_bitlength(const uint32_t *f, size_t flen, size_t fstride,
	unsigned logn, unsigned ter)
{
	size_t n, u;
	uint32_t maxbl;

	n = MKN(logn, ter);
	maxbl = 0;
	for (u = 0; u < n; u ++, f += fstride) {
		uint32_t bl;

		bl = zint_signed_bit_length(f, flen);
		if (bl > maxbl) {
			maxbl = bl;
		}
	}
	return maxbl;
}

/*
 * Convert a polynomial to floating-point values; the maximum bit length
 * of all coefficients is provided as 'maxbl' parameter. Returned values are
 * scaled down by 'scale' bits: if the integer value is z, this function
 * computes an approximation of z*2^(-scale).
 */
static void
poly_big_to_fp(DOUBLE *d, const uint32_t *f, size_t flen, size_t fstride,
	unsigned logn, unsigned ter, uint32_t maxbl, uint32_t scale)
{
	size_t n, u;
	uint32_t off;

	n = MKN(logn, ter);
	off = maxbl < 63 ? 0 : maxbl - 63;
	for (u = 0; u < n; u ++, f += fstride) {
		d[u] = ldexp(zint_get_top(f, flen, off), (int)(off - scale));
	}
}

/*
 * Convert a polynomial to small integers. Source values are supposed
 * to be one-word integers, signed over 31 bits. Returned value is 0
 * if any of the coefficients exceeds 2047 (in absolute value), or 1
 * on success.
 */
static int
poly_big_to_small(int16_t *d, const uint32_t *s, unsigned logn, unsigned ter)
{
	size_t n, u;

	n = MKN(logn, ter);
	for (u = 0; u < n; u ++) {
		int32_t z;

		z = zint_one_to_plain(s + u);
		if (z < -2047 || z > 2047) {
			return 0;
		}
		d[u] = (int16_t)z;
	}
	return 1;
}

/*
 * Subtract k*f from F, where F, f and k are polynomials modulo X^N+1.
 * Coefficients of polynomial k are small integers (signed values in the
 * -2^31..2^31 range) scaled by 2^sc.
 *
 * This function implements the basic quadratic multiplication algorithm,
 * which is efficient in space (no extra buffer needed) but slow at
 * high degree.
 */
static void
poly_sub_scaled(uint32_t *restrict F, size_t Flen, size_t Fstride,
	const uint32_t *restrict f, size_t flen, size_t fstride,
	const int32_t *restrict k, uint32_t sc,
	unsigned logn, unsigned full, unsigned ternary)
{
	size_t n, hn, u;
	uint32_t sch, scl;

	n = MKN(logn, full);
	hn = n >> 1;
	sch = sc / 31;
	scl = sc % 31;
	if (ternary) {
		size_t off1, off2, off3;

		off1 = hn * Fstride;
		off2 = n * Fstride;
		off3 = off1 + off2;
		for (u = 0; u < n; u ++) {
			int32_t kf;
			size_t v, j;
			const uint32_t *y;

			kf = -k[u];
			j = u * Fstride;
			y = f;
			for (v = 0; v < n; v ++, j += Fstride, y += fstride) {
				if (u + v < n) {
					zint_add_scaled_mul_small(
						F + j, Flen,
						y, flen, kf, sch, scl);
				} else if (u + v < (n + hn)) {
					zint_add_scaled_mul_small(
						F + j - off1, Flen,
						y, flen, kf, sch, scl);
					zint_add_scaled_mul_small(
						F + j - off2, Flen,
						y, flen, -kf, sch, scl);
				} else {
					zint_add_scaled_mul_small(
						F + j - off3, Flen,
						y, flen, -kf, sch, scl);
				}
			}
		}
	} else {
		for (u = 0; u < n; u ++) {
			int32_t kf;
			size_t v;
			uint32_t *x;
			const uint32_t *y;

			kf = -k[u];
			x = F + u * Fstride;
			y = f;
			for (v = 0; v < n; v ++) {
				zint_add_scaled_mul_small(
					x, Flen, y, flen, kf, sch, scl);
				if (u + v == n - 1) {
					x = F;
					kf = -kf;
				} else {
					x += Fstride;
				}
				y += fstride;
			}
		}
	}
}

/*
 * Subtract k*f from F. Coefficients of polynomial k are small integers
 * (signed values in the -2^31..2^31 range) scaled by 2^sc. This function
 * assumes that the degree is large, and integers relatively small.
 */
static void
poly_sub_scaled_ntt(uint32_t *restrict F, size_t Flen, size_t Fstride,
	const uint32_t *restrict f, size_t flen, size_t fstride,
	const int32_t *restrict k, uint32_t sc,
	unsigned logn, unsigned full, int ternary, uint32_t *restrict tmp)
{
	uint32_t *gm, *igm, *fk, *t1, *x;
	const uint32_t *y;
	size_t n, u, tlen;
	uint32_t sch, scl;
	const small_prime *primes;

	n = MKN(logn, full);
	tlen = flen + 1;
	gm = tmp;
	igm = gm + MKN(logn, 0);
	fk = igm + MKN(logn, 0);
	t1 = fk + n * tlen;

	primes = ternary ? PRIMES3 : PRIMES2;

	/*
	 * Compute k*f in fk[], in RNS notation.
	 */
	for (u = 0; u < tlen; u ++) {
		uint32_t p, p0i, R2, Rx;
		size_t v;

		p = primes[u].p;
		p0i = modp_ninv31(p);
		R2 = modp_R2(p, p0i);
		Rx = modp_Rx(flen, p, p0i, R2);
		if (ternary) {
			modp_mkgm3(gm, igm, logn, full, primes[u].g, p, p0i);
		} else {
			modp_mkgm2(gm, igm, logn, primes[u].g, p, p0i);
		}

		for (v = 0; v < n; v ++) {
			t1[v] = modp_set(k[v], p);
		}
		if (ternary) {
			modp_NTT3(t1, gm, logn, full, p, p0i);
		} else {
			modp_NTT2(t1, gm, logn, p, p0i);
		}
		for (v = 0, y = f, x = fk + u;
			v < n; v ++, y += fstride, x += tlen)
		{
			*x = zint_mod_small_signed(y, flen, p, p0i, R2, Rx);
		}
		if (ternary) {
			modp_NTT3_ext(fk + u, tlen, gm, logn, full, p, p0i);
		} else {
			modp_NTT2_ext(fk + u, tlen, gm, logn, p, p0i);
		}
		for (v = 0, x = fk + u; v < n; v ++, x += tlen) {
			*x = modp_montymul(
				modp_montymul(t1[v], *x, p, p0i), R2, p, p0i);
		}
		if (ternary) {
			modp_iNTT3_ext(fk + u, tlen, igm, logn, full, p, p0i);
		} else {
			modp_iNTT2_ext(fk + u, tlen, igm, logn, p, p0i);
		}
	}

	/*
	 * Rebuild k*f.
	 */
	zint_rebuild_CRT(fk, tlen, tlen, n, primes, 1, t1);

	/*
	 * Subtract k*f, scaled, from F.
	 */
	sch = sc / 31;
	scl = sc % 31;
	for (u = 0, x = F, y = fk; u < n; u ++, x += Fstride, y += tlen) {
		zint_sub_scaled(x, Flen, y, tlen, sch, scl);
	}
}

/* ==================================================================== */

struct falcon_keygen_ {

	// Base-2 logarithm of the degree
	unsigned logn;

	// 1 for a ternary modulus, 0 for binary [UNUSED]
	unsigned ternary;

	// The selected modulus
	unsigned q;

	// RNG:
	//   seeded    non-zero when a 'replace' seed or system RNG was pushed
	//   flipped   non-zero when flipped
	shake_context rng;
	int seeded;
	int flipped;

	// Temporary storage for key generation. 'tmp_len' is expressed
	//   in 32-bit words
	uint32_t *tmp;
	size_t tmp_len;
};

/*
 * Get a random 8-byte integer from a SHAKE-based RNG. This function
 * ensures consistent interpretation of the SHAKE output so that
 * the same values will be obtained over different platforms, in case
 * a known seed is used.
 */
static inline uint64_t
get_rng_u64(shake_context *rng)
{
	/*
	 * On little-endian systems we just interpret the bytes "as is"
	 * (this is correct because the exact-width types such as
	 * 'uint64_t' are guaranteed to have no padding and no trap
	 * representation).
	 *
	 * On other systems we enforce little-endian representation.
	 */
#if FALCON_LE_U
	uint64_t r;

	shake_extract(rng, &r, sizeof r);
	return r;
#else
	unsigned char tmp[8];

	shake_extract(rng, tmp, sizeof tmp);
	return (uint64_t)tmp[0]
		| ((uint64_t)tmp[1] << 8)
		| ((uint64_t)tmp[2] << 16)
		| ((uint64_t)tmp[3] << 24)
		| ((uint64_t)tmp[4] << 32)
		| ((uint64_t)tmp[5] << 40)
		| ((uint64_t)tmp[6] << 48)
		| ((uint64_t)tmp[7] << 56);
#endif
}

/*
 * Table below incarnates a discrete Gaussian distribution:
 *    D(x) = exp(-(x^2)/(2*sigma^2))
 * where sigma = 1.17*sqrt(q/(2*N)), q = 12289, and N = 1024.
 * Element 0 of the table is P(x = 0).
 * For k > 0, element k is P(x >= k+1 | x > 0).
 * Probabilities are scaled up by 2^63.
 */
static const uint64_t gauss_1024_12289[] = {
	 1283868770400643928u,  6416574995475331444u,  4078260278032692663u,
	 2353523259288686585u,  1227179971273316331u,   575931623374121527u,
	  242543240509105209u,    91437049221049666u,    30799446349977173u,
	    9255276791179340u,     2478152334826140u,      590642893610164u,
	     125206034929641u,       23590435911403u,        3948334035941u,
	        586753615614u,          77391054539u,           9056793210u,
	           940121950u,             86539696u,              7062824u,
	              510971u,                32764u,                 1862u,
	                  94u,                    4u,                    0u
};

/*
 * Generate a random value with a Gaussian distribution centered on 0.
 * The RNG must be ready for extraction (already flipped).
 *
 * Distribution has standard deviation 1.17*sqrt(q/(2*N)). The
 * precomputed table is for N = 1024. Since the sum of two independent
 * values of standard deviation sigma has standard deviation
 * sigma*sqrt(2), then we can just generate more values and add them
 * together for lower dimensions.
 *
 * This function is only for the binary case.
 */
static int
mkgauss(falcon_keygen *fk, unsigned logn)
{
	unsigned u, g;
	int val;

	g = 1U << (10 - logn);
	val = 0;
	for (u = 0; u < g; u ++) {
		uint64_t r;
		int k, neg;

		r = get_rng_u64(&fk->rng);
		neg = (int)(r >> 63);
		r &= ~((uint64_t)1 << 63);
		if (r < gauss_1024_12289[0]) {
			continue;
		}
		r = get_rng_u64(&fk->rng);
		r &= ~((uint64_t)1 << 63);
		k = 1;
		while (gauss_1024_12289[k] > r) {
			k ++;
		}
		k *= (int)(1 - (neg << 1));
		val += k;
	}
	return val;
}

/*
 * The MAX_BL_SMALL*[] and MAX_BL_LARGE*[] contain the lengths, in 31-bit
 * words, of intermediate values in the computation:
 *
 *   MAX_BL_SMALL*[depth]: length for the input f and g at that depth
 *   MAX_BL_LARGE*[depth]: length for the unreduced F and G at that depth
 *
 * MAX_BL_SMALL2[] and MAX_BL_LARGE2[] are for the binary case, for depth
 * up to 10. MAX_BL_SMALL3[] and MAX_BL_LARGE3[] are for the ternary case.
 *
 * Rules:
 *
 *  - Within an array, values grow.
 *
 *  - The 'SMALL' array must have an entry for maximum depth, corresponding
 *    to the size of values used in the binary GCD. There is no such value
 *    for the 'LARGE' array (the binary GCD yields already reduced
 *    coefficients).
 *
 *  - MAX_BL_LARGE[depth] >= MAX_BL_SMALL[depth + 1].
 *
 *  - Values must be large enough to handle the common cases, with some
 *    margins.
 *
 * The following average lengths, in bits, have been measured on thousands
 * of random keys (fg = max length of the absolute value of coefficients
 * of f and g at that depth; FG = idem for the unreduced F and G; for the
 * maximum depth, F and G are the output of binary GCD, multiplied by q;
 * for each value, the average and standard deviation are provided).
 *
 * Binary case:
 *    depth: 10    fg: 6307.52 (24.48)    FG: 6319.66 (24.51)
 *    depth:  9    fg: 3138.35 (12.25)    FG: 9403.29 (27.55)
 *    depth:  8    fg: 1576.87 ( 7.49)    FG: 4703.30 (14.77)
 *    depth:  7    fg:  794.17 ( 4.98)    FG: 2361.84 ( 9.31)
 *    depth:  6    fg:  400.67 ( 3.10)    FG: 1188.68 ( 6.04)
 *    depth:  5    fg:  202.22 ( 1.87)    FG:  599.81 ( 3.87)
 *    depth:  4    fg:  101.62 ( 1.02)    FG:  303.49 ( 2.38)
 *    depth:  3    fg:   50.37 ( 0.53)    FG:  153.65 ( 1.39)
 *    depth:  2    fg:   24.07 ( 0.25)    FG:   78.20 ( 0.73)
 *    depth:  1    fg:   10.99 ( 0.08)    FG:   39.82 ( 0.41)
 *    depth:  0    fg:    4.00 ( 0.00)    FG:   19.61 ( 0.49)
 *
 * Ternary case:
 *    depth:  9    fg: 4975.81 (22.38)    FG: 4988.54 (22.43)
 *    depth:  8    fg: 2472.64 (11.20)    FG: 7409.66 (25.93)
 *    depth:  7    fg: 1243.34 ( 6.78)    FG: 3705.30 (13.66)
 *    depth:  6    fg:  626.61 ( 4.40)    FG: 1861.86 ( 8.50)
 *    depth:  5    fg:  316.34 ( 2.75)    FG:  937.68 ( 5.51)
 *    depth:  4    fg:  159.68 ( 1.61)    FG:  473.48 ( 3.45)
 *    depth:  3    fg:   80.16 ( 0.86)    FG:  239.82 ( 2.06)
 *    depth:  2    fg:   39.58 ( 0.51)    FG:  121.80 ( 1.14)
 *    depth:  1    fg:   18.98 ( 0.13)    FG:   61.93 ( 0.61)
 *    depth:  0    fg:    4.76 ( 0.42)    FG:   34.97 ( 0.28)
 *
 * Integers are actually represented either in binary notation over
 * 31-bit words (signed, using two's complement), or in RNS, modulo
 * many small primes. These small primes are close to, but slightly
 * lower than, 2^31. Use of RNS loses less than two bits, even for
 * the largest values.
 */

static const size_t MAX_BL_SMALL2[] = {
	1, 1, 2, 2, 4, 7, 14, 27, 53, 106, 212
};

static const size_t MAX_BL_LARGE2[] = {
	2, 2, 5, 7, 12, 22, 42, 80, 157, 310
};

static const size_t MAX_BL_SMALL3[] = {
	1, 1, 2, 3, 6, 12, 22, 42, 82, 166
};

static const size_t MAX_BL_LARGE3[] = {
	2, 3, 5, 9, 16, 32, 62, 123, 245
};

/*
 * Minimal recursion depth at which we rebuild intermediate values
 * when reconstructing f and g.
 */
#define DEPTH_INT_FG   4

/*
 * Compute size of temporary array for key generation.
 * Returned size is expressed in bytes.
 */
static size_t
temp_size(unsigned logn)
{
#define ALIGN_FP(tt)   ((((tt) + sizeof(DOUBLE) - 1) / sizeof(DOUBLE)) * sizeof(DOUBLE))
#define ALIGN_UW(tt)   ((((tt) + sizeof(uint32_t) - 1) \
                       / sizeof(uint32_t)) * sizeof(uint32_t))

	size_t gmax;
	unsigned depth;

	gmax = 0;

	/*
	 * Compute memory requirements for make_fg() at each depth.
	 */
	for (depth = 0; depth < logn; depth ++) {
		size_t cur;

		size_t n, slen, tlen;

		n = (size_t)1 << (logn - depth);
		slen = MAX_BL_SMALL2[depth];
		tlen = MAX_BL_SMALL2[depth + 1];
		cur = (n * tlen + 2 * n * slen + 3 * n)
			* sizeof(uint32_t);
		gmax = cur > gmax ? cur : gmax;
		cur = (n * tlen + 2 * n * slen + slen)
			* sizeof(uint32_t);
		gmax = cur > gmax ? cur : gmax;
	}

	/*
	 * Compute memory requirements for each depth.
	 */
	for (depth = 0; depth <= logn; depth ++) {
		size_t cur, max;

		max = 0;
		if (depth == logn) {
			size_t slen;

			slen = MAX_BL_SMALL2[depth];
			cur = 8 * slen * sizeof(uint32_t);
			max = cur > max ? cur : max;
		} else if (depth == 0 && logn > 2) {
			size_t n, hn;

			n = (size_t)1 << logn;
			hn = n >> 1;
			cur = 7 * n * sizeof(uint32_t);
			max = cur > max ? cur : max;
			cur = ALIGN_FP(4 * n * sizeof(uint32_t))
				+ n * sizeof(DOUBLE);
			max = cur > max ? cur : max;
			cur = ALIGN_FP(3 * n * sizeof(uint32_t))
				+ (n + hn) * sizeof(DOUBLE);
			max = cur > max ? cur : max;
		} else if (depth == 1 && logn > 2) {
			size_t n, hn, slen, dlen, llen;

			n = (size_t)1 << (logn - 1);
			hn = n >> 1;
			slen = MAX_BL_SMALL2[depth];
			dlen = MAX_BL_SMALL2[depth + 1];
			llen = MAX_BL_LARGE2[depth];
			cur = (2 * hn * dlen + 2 * n * llen) * sizeof(uint32_t);
			max = cur > max ? cur : max;
			cur = (2 * n * llen + 2 * n * slen + 7 * n)
				* sizeof(uint32_t);
			max = cur > max ? cur : max;
			cur = (2 * n * llen + 2 * n * slen + llen)
				* sizeof(uint32_t);
			max = cur > max ? cur : max;
			cur = ALIGN_FP((2 * n * llen + 2 * n * slen)
				* sizeof(uint32_t))
				+ 2 * n * sizeof(DOUBLE);
			max = cur > max ? cur : max;
			cur = ALIGN_FP(2 * n * slen * sizeof(uint32_t))
				+ 4 * n * sizeof(DOUBLE);
			max = cur > max ? cur : max;
			cur = (5 * n + hn) * sizeof(DOUBLE);
			max = cur > max ? cur : max;
			cur = ALIGN_FP(2 * n * sizeof(uint32_t))
				+ 2 * n * sizeof(DOUBLE);
			max = cur > max ? cur : max;
		} else {
			size_t n, hn, slen, llen, tmp1, tmp2;

			n = (size_t)1 << (logn - depth);
			hn = n >> 1;
			slen = MAX_BL_SMALL2[depth];
			llen = MAX_BL_LARGE2[depth];
			cur = (2 * n * llen + 2 * n * slen + 4 * n)
				* sizeof(uint32_t);
			max = cur > max ? cur : max;
			cur = (2 * n * llen + 2 * n * slen + llen)
				* sizeof(uint32_t);
			max = cur > max ? cur : max;
			tmp1 = ALIGN_UW(
				ALIGN_FP((2 * n * llen + 2 * n * slen)
					* sizeof(uint32_t))
				+ (2 * n + hn) * sizeof(DOUBLE))
				+ n * sizeof(uint32_t);
			tmp2 = ALIGN_FP((2 * n * llen + 2 * n * slen)
				* sizeof(uint32_t))
				+ (3 * n + hn) * sizeof(DOUBLE);
			cur = tmp1 > tmp2 ? tmp1 : tmp2;
			cur = ALIGN_FP(cur) + n * sizeof(DOUBLE);
			max = cur > max ? cur : max;
			cur = ALIGN_UW(
				ALIGN_FP((2 * n * llen + 2 * n * slen)
					* sizeof(uint32_t))
				+ (2 * n + hn) * sizeof(DOUBLE))
				+ (5 * n + n * slen) * sizeof(uint32_t);
			max = cur > max ? cur : max;
		}

		gmax = max > gmax ? max : gmax;
	}

	return gmax;

#undef ALIGN_FP
#undef ALIGN_UW
}

#if MEMCHECK
static const char MEMCHECK_MARK[] = "memcheck";
#endif

/* see falcon.h */
falcon_keygen *
falcon_keygen_new(unsigned logn, unsigned q)
{
	falcon_keygen *fk;

	if (logn < 1 || logn > 10) {
		return NULL;
	}
	fk = malloc(sizeof *fk);
	if (fk == NULL) {
		return NULL;
	}
	fk->logn = logn;
	fk->ternary = 0;
	fk->q = q;
	shake_init(&fk->rng, 512);
	fk->seeded = 0;
	fk->flipped = 0;

	fk->tmp_len = temp_size(logn);
#if MEMCHECK
	fk->tmp = malloc(fk->tmp_len + sizeof MEMCHECK_MARK);
#else
	fk->tmp = malloc(fk->tmp_len);
#endif
	if (fk->tmp == NULL) {
		free(fk);
		return NULL;
	}
#if MEMCHECK
	memcpy((unsigned char *)fk->tmp + fk->tmp_len,
		MEMCHECK_MARK, sizeof MEMCHECK_MARK);
#endif

	return fk;
}

/* see falcon.h */
void
falcon_keygen_free(falcon_keygen *fk)
{
	if (fk != NULL) {
#if CLEANSE
		cleanse(fk->tmp, fk->tmp_len);
#endif
#if MEMCHECK
		if (memcmp((unsigned char *)fk->tmp + fk->tmp_len,
			MEMCHECK_MARK, sizeof MEMCHECK_MARK) != 0)
		{
			fprintf(stderr, "buffer overflow! temp_size() is wrong\n");
			abort();
		}
#endif
		free(fk->tmp);
		free(fk);
	}
}

/* see falcon.h */
size_t
falcon_keygen_max_privkey_size(falcon_keygen *fk)
{
	/*
	 * Uncompressed private key is a one-byte header, followed by
	 * f, g, F and G, each represented as an array of 16-bit values.
	 */
	unsigned logn;
	size_t n;

	logn = fk->logn;
	n = fk->ternary ? ((size_t)3 << (logn - 1)) : ((size_t)1 << logn);
	return 1 + (n << 3);
}

/* see falcon.h */
size_t
falcon_keygen_max_pubkey_size(falcon_keygen *fk)
{
	/*
	 * Public key is a one-byte header, followed by the public
	 * vector h. Each element of h uses 14 bits in the binary case,
	 * 15 bits in the ternary case.
	 */
	unsigned logn;
	unsigned z;

	logn = fk->logn;
	z = fk->ternary ? (45U << (logn - 1)) : (14U << logn);
	return 1 + ((z + 7) >> 3);
}

/* see falcon.h */
void
falcon_keygen_set_seed(falcon_keygen *fk,
	const void *seed, size_t len, int replace)
{
	if (replace) {
		shake_init(&fk->rng, 512);
		shake_inject(&fk->rng, seed, len);
		fk->seeded = 1;
		fk->flipped = 0;
		return;
	}
	if (fk->flipped) {
		unsigned char tmp[32];

		shake_extract(&fk->rng, tmp, sizeof tmp);
		shake_init(&fk->rng, 512);
		shake_inject(&fk->rng, tmp, sizeof tmp);
		fk->flipped = 0;
	}
	shake_inject(&fk->rng, seed, len);
}

static int
rng_ready(falcon_keygen *fk)
{
	if (!fk->seeded) {
		unsigned char tmp[32];

		if (!falcon_get_seed(tmp, sizeof tmp)) {
			return 0;
		}
		falcon_keygen_set_seed(fk, tmp, sizeof tmp, 0);
		fk->seeded = 1;
	}
	if (!fk->flipped) {
		shake_flip(&fk->rng);
		fk->flipped = 1;
	}
	return 1;
}

/*
 * Compute squared norm of a short vector. Returned value is saturated to
 * 2^32-1 if it is not lower than 2^31.
 */
static uint32_t
poly_small_sqnorm(const int16_t *f, unsigned logn, unsigned ter)
{
	size_t n, u;
	uint32_t s, ng;

	n = MKN(logn, ter);
	s = 0;
	ng = 0;
	for (u = 0; u < n; u ++) {
		int32_t z;

		z = f[u];
		s += (uint32_t)(z * z);
		ng |= s;
	}
	return s | -(ng >> 31);
}

/*
 * Align (upwards) the provided 'data' pointer with regards to 'base'
 * so that the offset is a multiple of the size of 'DOUBLE'.
 */
static DOUBLE *
align_DOUBLE(void *base, void *data)
{
	unsigned char *cb, *cd;
	size_t k, km;

	cb = base;
	cd = data;
	k = (size_t)(cd - cb);
	km = k % sizeof(DOUBLE);
	if (km) {
		k += (sizeof(DOUBLE)) - km;
	}
	return (DOUBLE *)(cb + k);
}

/*
 * Align (upwards) the provided 'data' pointer with regards to 'base'
 * so that the offset is a multiple of the size of 'uint32_t'.
 */
static uint32_t *
align_u32(void *base, void *data)
{
	unsigned char *cb, *cd;
	size_t k, km;

	cb = base;
	cd = data;
	k = (size_t)(cd - cb);
	km = k % sizeof(uint32_t);
	if (km) {
		k += (sizeof(uint32_t)) - km;
	}
	return (uint32_t *)(cb + k);
}

/*
 * Convert a small vector to floating point.
 */
static void
poly_small_to_fp(DOUBLE *x, const int16_t *f, unsigned logn, unsigned ter)
{
	size_t n, u;

	n = MKN(logn, ter);
	for (u = 0; u < n; u ++) {
		x[u] = 1 / (DOUBLE) f[u];
	}
}

/*
 * Input: f,g of degree N = 2^logn; 'depth' is used only to get their
 * individual length. If 'ter' is 1, then this is for the ternary case.
 * This function is never invoked for the top-level of the ternary case,
 * though.
 *
 * Output: f',g' of degree N/2, with the length for 'depth+1'.
 *
 * Values are in RNS; input and/or output may also be in NTT.
 */
static void
make_fg_step(uint32_t *data, unsigned logn, unsigned depth, unsigned ter,
	int in_ntt, int out_ntt)
{
	size_t n, hn, u;
	size_t slen, tlen;
	uint32_t *fd, *gd, *fs, *gs, *gm, *igm, *t1;
	const small_prime *primes;

	n = (size_t)1 << logn;
	hn = n >> 1;
	if (ter) {
		slen = MAX_BL_SMALL3[depth];
		tlen = MAX_BL_SMALL3[depth + 1];
		primes = PRIMES3;
	} else {
		slen = MAX_BL_SMALL2[depth];
		tlen = MAX_BL_SMALL2[depth + 1];
		primes = PRIMES2;
	}

	/*
	 * Prepare room for the result.
	 */
	fd = data;
	gd = fd + hn * tlen;
	fs = gd + hn * tlen;
	gs = fs + n * slen;
	gm = gs + n * slen;
	igm = gm + n;
	t1 = igm + n;
	memmove(fs, data, 2 * n * slen * sizeof *data);

	/*
	 * First slen words: we use the input values directly, and apply
	 * inverse NTT as we go.
	 */
	for (u = 0; u < slen; u ++) {
		uint32_t p, p0i, R2;
		size_t v;
		uint32_t *x;

		p = primes[u].p;
		p0i = modp_ninv31(p);
		R2 = modp_R2(p, p0i);
		if (ter) {
			modp_mkgm3(gm, igm, logn, 0, primes[u].g, p, p0i);
		} else {
			modp_mkgm2(gm, igm, logn, primes[u].g, p, p0i);
		}

		for (v = 0, x = fs + u; v < n; v ++, x += slen) {
			t1[v] = *x;
		}
		if (!in_ntt) {
			if (ter) {
				modp_NTT3(t1, gm, logn, 0, p, p0i);
			} else {
				modp_NTT2(t1, gm, logn, p, p0i);
			}
		}
		for (v = 0, x = fd + u; v < hn; v ++, x += tlen) {
			uint32_t w0, w1;

			w0 = t1[(v << 1) + 0];
			w1 = t1[(v << 1) + 1];
			*x = modp_montymul(
				modp_montymul(w0, w1, p, p0i), R2, p, p0i);
		}
		if (in_ntt) {
			if (ter) {
				modp_iNTT3_ext(fs + u, slen, igm,
					logn, 0, p, p0i);
			} else {
				modp_iNTT2_ext(fs + u, slen, igm,
					logn, p, p0i);
			}
		}

		for (v = 0, x = gs + u; v < n; v ++, x += slen) {
			t1[v] = *x;
		}
		if (!in_ntt) {
			if (ter) {
				modp_NTT3(t1, gm, logn, 0, p, p0i);
			} else {
				modp_NTT2(t1, gm, logn, p, p0i);
			}
		}
		for (v = 0, x = gd + u; v < hn; v ++, x += tlen) {
			uint32_t w0, w1;

			w0 = t1[(v << 1) + 0];
			w1 = t1[(v << 1) + 1];
			*x = modp_montymul(
				modp_montymul(w0, w1, p, p0i), R2, p, p0i);
		}
		if (in_ntt) {
			if (ter) {
				modp_iNTT3_ext(gs + u, slen, igm,
					logn, 0, p, p0i);
			} else {
				modp_iNTT2_ext(gs + u, slen, igm,
					logn, p, p0i);
			}
		}

		if (!out_ntt) {
			if (ter) {
				modp_iNTT3_ext(fd + u, tlen, igm,
					logn - 1, 0, p, p0i);
				modp_iNTT3_ext(gd + u, tlen, igm,
					logn - 1, 0, p, p0i);
			} else {
				modp_iNTT2_ext(fd + u, tlen, igm,
					logn - 1, p, p0i);
				modp_iNTT2_ext(gd + u, tlen, igm,
					logn - 1, p, p0i);
			}
		}
	}

	/*
	 * Since the fs and gs words have been de-NTTized, we can use the
	 * CRT to rebuild the values.
	 */
	zint_rebuild_CRT(fs, slen, slen, n, primes, 1, gm);
	zint_rebuild_CRT(gs, slen, slen, n, primes, 1, gm);

	/*
	 * Remaining words: use modular reductions to extract the values.
	 */
	for (u = slen; u < tlen; u ++) {
		uint32_t p, p0i, R2, Rx;
		size_t v;
		uint32_t *x;

		p = primes[u].p;
		p0i = modp_ninv31(p);
		R2 = modp_R2(p, p0i);
		Rx = modp_Rx(slen, p, p0i, R2);
		if (ter) {
			modp_mkgm3(gm, igm, logn, 0, primes[u].g, p, p0i);
		} else {
			modp_mkgm2(gm, igm, logn, primes[u].g, p, p0i);
		}
		for (v = 0, x = fs; v < n; v ++, x += slen) {
			t1[v] = zint_mod_small_signed(x, slen, p, p0i, R2, Rx);
		}
		if (ter) {
			modp_NTT3(t1, gm, logn, 0, p, p0i);
		} else {
			modp_NTT2(t1, gm, logn, p, p0i);
		}
		for (v = 0, x = fd + u; v < hn; v ++, x += tlen) {
			uint32_t w0, w1;

			w0 = t1[(v << 1) + 0];
			w1 = t1[(v << 1) + 1];
			*x = modp_montymul(
				modp_montymul(w0, w1, p, p0i), R2, p, p0i);
		}
		for (v = 0, x = gs; v < n; v ++, x += slen) {
			t1[v] = zint_mod_small_signed(x, slen, p, p0i, R2, Rx);
		}
		if (ter) {
			modp_NTT3(t1, gm, logn, 0, p, p0i);
		} else {
			modp_NTT2(t1, gm, logn, p, p0i);
		}
		for (v = 0, x = gd + u; v < hn; v ++, x += tlen) {
			uint32_t w0, w1;

			w0 = t1[(v << 1) + 0];
			w1 = t1[(v << 1) + 1];
			*x = modp_montymul(
				modp_montymul(w0, w1, p, p0i), R2, p, p0i);
		}

		if (!out_ntt) {
			if (ter) {
				modp_iNTT3_ext(fd + u, tlen, igm,
					logn - 1, 0, p, p0i);
				modp_iNTT3_ext(gd + u, tlen, igm,
					logn - 1, 0, p, p0i);
			} else {
				modp_iNTT2_ext(fd + u, tlen, igm,
					logn - 1, p, p0i);
				modp_iNTT2_ext(gd + u, tlen, igm,
					logn - 1, p, p0i);
			}
		}
	}
}

/*
 * Input: f,g of degree N = 1.5*2^logn (normal representation).
 *
 * Output: f',g' of degree N/3, with the length for depth 1. Output
 * may be in NTT.
 *
 * Values are in RNS.
 */
static void
make_fg_ternary_top(uint32_t *data, unsigned logn, int out_ntt)
{
	/*
	 * Let f = f0(x^3) + x*f1(x^3) + x^2*f2(x^3).
	 * We define the field norm N(f) as the derminant of the
	 * map y |-> y*f (from the sub-field of degree N/3 to the
	 * field of degree N); this yields:
	 *
	 *   N(f) = f0^3 + f1^3*x + f2^3*x^2 - 3*f0*f1*f2*x
	 *
	 * For w such that w^3 = 1, but w != 1:
	 *
	 *   c1(f) = f(x*w) = f0(x^3) + w*f1(x^3)*x + w^2*f2(x^3)*x^2
	 *   c2(f) = f(x*w^2) = f0(x^3) + w^2*f1(x^3)*x + w*f2(x^3)*x^2
	 *
	 * It can be verified that:
	 *
	 *   N(f)(x^3) = f*c1(f)*c2(f)
	 *
	 * If c(f) = c1(f)*c2(f), then:
	 *
	 *   c(f) = (f0^2)(x^3)
	 *        - (f0*f1)(x^3) * x
	 *        + (f1^2 - f0*f2)(x^3) * x^2
	 *        - (f1*f2)(x^3) * x^3
	 *        + (f2^2)(x^3) * x^4
	 *
	 * Therefore, if the coefficients of f are integers, then so
	 * are the coefficients of c(f).
	 *
	 * Thus, the NTRU equation:
	 *   f*G - g*F = q
	 * can be solved recursively: we get F' and G' such that:
	 *   N(f)*G' - N(g)*F' = q
	 * and we then set:
	 *   F = F'(x^3) * c(g)
	 *   G = G'(x^3) * c(f)
	 *
	 * In this function, we simply compute N(f) and N(g). Since the
	 * coefficients of f and g are very small, all computations can
	 * be done modulo a single small prime.
	 *
	 * Moreover, in NTT representation, we have:
	 *
	 *   N(f)(x^3) = f(x)*c1(f)(x)*c2(f)(x)
	 *             = f(x)*f(x*w)*f(x*w^2)
	 *
	 * which allows us to compute the coefficients of N(f) by simply
	 * multiplying together the coefficients of f.
	 */

	size_t n, dn, tn, u, v;
	uint32_t *gm, *igm, *fd, *gd, *fs, *gs;
	uint32_t p, p0i, R2, R3;

	n = MKN(logn, 1);
	dn = MKN(logn, 0);
	tn = MKN(logn - 1, 0);
	fd = data;
	gd = fd + tn;
	fs = gd + tn;
	gs = fs + n;
	gm = gs + n;
	igm = gm + dn;
	memmove(fs, data, n * 2 * sizeof *data);

	p = PRIMES3[0].p;
	p0i = modp_ninv31(p);
	R2 = modp_R2(p, p0i);

	modp_mkgm3(gm, igm, logn, 1, PRIMES3[0].g, p, p0i);
	modp_NTT3(fs, gm, logn, 1, p, p0i);
	modp_NTT3(gs, gm, logn, 1, p, p0i);

	R3 = modp_montymul(R2, R2, p, p0i);

	for (u = 0, v = 0; u < n; u += 3, v ++) {
		fd[v] = modp_montymul(R3, modp_montymul(fs[u],
			modp_montymul(fs[u + 1], fs[u + 2], p, p0i),
			p, p0i), p, p0i);
		gd[v] = modp_montymul(R3, modp_montymul(gs[u],
			modp_montymul(gs[u + 1], gs[u + 2], p, p0i),
			p, p0i), p, p0i);
	}
	if (!out_ntt) {
		modp_iNTT3(fd, igm, logn - 1, 0, p, p0i);
		modp_iNTT3(gd, igm, logn - 1, 0, p, p0i);
	}
}

/*
 * Compute f and g at a specific depth, in RNS notation.
 *
 * Returned values are stored in the data[] array, at slen words per integer.
 *
 * Conditions:
 *   0 <= depth <= logn
 *
 * Space use in data[]: enough room for any two successive values (f', g',
 * f and g).
 */
static void
make_fg(uint32_t *data, const int16_t *f, const int16_t *g,
	unsigned logn, unsigned ter, unsigned depth, int out_ntt)
{
	size_t n, u;
	uint32_t *ft, *gt, p0;
	unsigned d;
	const small_prime *primes;

	n = MKN(logn, ter);
	ft = data;
	gt = ft + n;
	primes = ter ? PRIMES3 : PRIMES2;
	p0 = primes[0].p;
	for (u = 0; u < n; u ++) {
		ft[u] = modp_set(f[u], p0);
		gt[u] = modp_set(g[u], p0);
	}

	if (depth == 0 && out_ntt) {
		uint32_t *gm, *igm;
		uint32_t p, p0i;

		p = primes[0].p;
		p0i = modp_ninv31(p);
		gm = gt + n;
		igm = gm + MKN(logn, 0);
		if (ter) {
			modp_mkgm3(gm, igm, logn, 1, primes[0].g, p, p0i);
			modp_NTT3(ft, gm, logn, 1, p, p0i);
			modp_NTT3(gt, gm, logn, 1, p, p0i);
		} else {
			modp_mkgm2(gm, igm, logn, primes[0].g, p, p0i);
			modp_NTT2(ft, gm, logn, p, p0i);
			modp_NTT2(gt, gm, logn, p, p0i);
		}
		return;
	}

	if (ter) {
		make_fg_ternary_top(data, logn, depth > 1 || out_ntt);
		for (d = 1; d < depth; d ++) {
			make_fg_step(data, logn - d, d, 1,
				1, (d + 1) < depth || out_ntt);
		}
	} else {
		for (d = 0; d < depth; d ++) {
			make_fg_step(data, logn - d, d, 0,
				d != 0, (d + 1) < depth || out_ntt);
		}
	}
}

/*
 * Solving the NTRU equation, deepest level: compute the resultants of
 * f and g with X^N+1, and use binary GCD. The F and G values are
 * returned in fk->tmp.
 *
 * Returned value: 1 on success, 0 on error.
 */
static int
solve_NTRU_deepest(falcon_keygen *fk, const int16_t *f, const int16_t *g)
{
	unsigned logn;
	size_t len;
	uint32_t *Fp, *Gp, *fp, *gp, *t1, q;
	const small_prime *primes;

	logn = fk->logn;
	if (fk->ternary) {
		len = MAX_BL_SMALL3[logn];
		primes = PRIMES3;
	} else {
		len = MAX_BL_SMALL2[logn];
		primes = PRIMES2;
	}

	Fp = fk->tmp;
	Gp = Fp + len;
	fp = Gp + len;
	gp = fp + len;
	t1 = gp + len;

	make_fg(fp, f, g, logn, fk->ternary, logn, 0);

	/*
	 * We use the CRT to rebuild the resultants as big integers.
	 * There are two such big integers.
	 */
	zint_rebuild_CRT(fp, len, len, 2, primes, 0, t1);

	/*
	 * Apply the binary GCD. The zint_bezout() function works only
	 * if both inputs are odd.
	 */
	if (!zint_bezout(Gp, Fp, fp, gp, len, t1)) {
		return 0;
	}

	/*
	 * Multiply the two values by the target value q. Values must
	 * fit in the destination arrays.
	 */
	q = fk->ternary ? 18433 : 12289;
	if (zint_mul_small(Fp, len, q) != 0
		|| zint_mul_small(Gp, len, q) != 0)
	{
		return 0;
	}

	return 1;
}

/*
 * Solving the NTRU equation, intermediate level. Upon entry, the F and G
 * from the previous level should be in the fk->tmp array.
 * This function MAY be invoked for the top-level (in which case depth = 0).
 *
 * Returned value: 1 on success, 0 on error.
 */
static int
solve_NTRU_intermediate(falcon_keygen *fk,
	const int16_t *f, const int16_t *g, unsigned depth)
{
	/*
	 * In this function, 'logn' is the log2 of the degree for
	 * this step. If N = 2^logn, then:
	 *  - the F and G values already in fk->tmp (from the deeper
	 *    levels) have degree N/2;
	 *  - this function should return F and G of degree N.
	 */
	unsigned logn_top, logn, full;
	size_t n, hn, slen, dlen, llen, FGlen, u;
	uint32_t *Fd, *Gd, *Ft, *Gt, *ft, *gt, *t1;
	DOUBLE *rt1, *rt2, *rt3, *rt4, *rt5;
	uint32_t maxbl_f, maxbl_g, maxbl_fg, maxbl_FG, prev_maxbl_FG;
	uint32_t *x, *y;
	int32_t *k;
	const small_prime *primes;

	logn_top = fk->logn;
	logn = logn_top - depth;

	/*
	 * In the ternary case _and_ top-level, n is a multiple of 3,
	 * and hn = n/3. Otherwise, n is a power of 2, and hn = n/2.
	 */
	if (fk->ternary && depth == 0) {
		full = 1;
		n = (size_t)3 << (logn - 1);
		hn = (size_t)1 << (logn - 1);
	} else {
		full = 0;
		n = (size_t)1 << logn;
		hn = n >> 1;
	}

	/*
	 * slen = size for our input f and g; also size of the reduced
	 *        F and G we return (degree N)
	 *
	 * dlen = size of the F and G obtained from the deeper level
	 *        (degree N/2 or N/3)
	 *
	 * llen = size for intermediary F and G before reduction (degree N)
	 *
	 * We build our non-reduced F and G as two independent halves each,
	 * of degree N/2 (F = F0 + X*F1, G = G0 + X*G1).
	 */
	if (fk->ternary) {
		slen = MAX_BL_SMALL3[depth];
		dlen = MAX_BL_SMALL3[depth + 1];
		llen = MAX_BL_LARGE3[depth];
		primes = PRIMES3;
	} else {
		slen = MAX_BL_SMALL2[depth];
		dlen = MAX_BL_SMALL2[depth + 1];
		llen = MAX_BL_LARGE2[depth];
		primes = PRIMES2;
	}

	/*
	 * Fd and Gd are the F and G from the deeper level.
	 */
	Fd = fk->tmp;
	Gd = Fd + dlen * hn;

	/*
	 * Compute the input f and g for this level. Note that we get f
	 * and g in RNS + NTT representation.
	 */
	ft = Gd + dlen * hn;
	make_fg(ft, f, g, logn_top, fk->ternary, depth, 1);

	/*
	 * Move the newly computed f and g to make room for our candidate
	 * F and G (unreduced).
	 */
	Ft = fk->tmp;
	Gt = Ft + n * llen;
	t1 = Gt + n * llen;
	memmove(t1, ft, 2 * n * slen * sizeof *ft);
	ft = t1;
	gt = ft + slen * n;
	t1 = gt + slen * n;

	/*
	 * Move Fd and Gd _after_ f and g.
	 */
	memmove(t1, Fd, 2 * hn * dlen * sizeof *Fd);
	Fd = t1;
	Gd = Fd + hn * dlen;

	/*
	 * We reduce Fd and Gd modulo all the small primes we will need,
	 * and store the values in Ft and Gt (only n/2 values in each).
	 */
	for (u = 0; u < llen; u ++) {
		uint32_t p, p0i, R2, Rx;
		size_t v;
		uint32_t *xs, *ys, *xd, *yd;

		p = primes[u].p;
		p0i = modp_ninv31(p);
		R2 = modp_R2(p, p0i);
		Rx = modp_Rx(dlen, p, p0i, R2);
		for (v = 0, xs = Fd, ys = Gd, xd = Ft + u, yd = Gt + u;
			v < hn;
			v ++, xs += dlen, ys += dlen, xd += llen, yd += llen)
		{
			*xd = zint_mod_small_signed(xs, dlen, p, p0i, R2, Rx);
			*yd = zint_mod_small_signed(ys, dlen, p, p0i, R2, Rx);
		}
	}

	/*
	 * We do not need Fd and Gd after that point.
	 */

	/*
	 * Compute our F and G modulo sufficiently many small primes.
	 */
	for (u = 0; u < llen; u ++) {
		uint32_t p, p0i, R2;
		uint32_t *gm, *igm, *fx, *gx, *Fp, *Gp;
		size_t v;

		/*
		 * All computations are done modulo p.
		 */
		p = primes[u].p;
		p0i = modp_ninv31(p);
		R2 = modp_R2(p, p0i);

		/*
		 * If we processed slen words, then f and g have been
		 * de-NTTized, and are in RNS; we can rebuild them.
		 */
		if (u == slen) {
			zint_rebuild_CRT(ft, slen, slen, n, primes, 1, t1);
			zint_rebuild_CRT(gt, slen, slen, n, primes, 1, t1);
		}

		gm = t1;
		if (full) {
			igm = gm + ((size_t)1 << logn);
			fx = igm + ((size_t)1 << logn);
		} else {
			gm = t1;
			igm = gm + n;
			fx = igm + n;
		}
		gx = fx + n;

		if (fk->ternary) {
			modp_mkgm3(gm, igm, logn, full, primes[u].g, p, p0i);
		} else {
			modp_mkgm2(gm, igm, logn, primes[u].g, p, p0i);
		}

		if (u < slen) {
			size_t v;

			for (v = 0, x = ft + u, y = gt + u;
				v < n; v ++, x += slen, y += slen)
			{
				fx[v] = *x;
				gx[v] = *y;
			}
			if (fk->ternary) {
				modp_iNTT3_ext(ft + u, slen, igm,
					logn, full, p, p0i);
				modp_iNTT3_ext(gt + u, slen, igm,
					logn, full, p, p0i);
			} else {
				modp_iNTT2_ext(ft + u, slen, igm,
					logn, p, p0i);
				modp_iNTT2_ext(gt + u, slen, igm,
					logn, p, p0i);
			}
		} else {
			uint32_t Rx;
			size_t v;

			Rx = modp_Rx(slen, p, p0i, R2);
			for (v = 0, x = ft, y = gt;
				v < n; v ++, x += slen, y += slen)
			{
				fx[v] = zint_mod_small_signed(x, slen,
					p, p0i, R2, Rx);
				gx[v] = zint_mod_small_signed(y, slen,
					p, p0i, R2, Rx);
			}
			if (fk->ternary) {
				modp_NTT3(fx, gm, logn, full, p, p0i);
				modp_NTT3(gx, gm, logn, full, p, p0i);
			} else {
				modp_NTT2(fx, gm, logn, p, p0i);
				modp_NTT2(gx, gm, logn, p, p0i);
			}
		}

		/*
		 * Get F' and G' modulo p and in NTT representation
		 * (they have degree n/2 or n/3). These values were
		 * computed in a previous step, and stored in Ft and Gt.
		 */
		Fp = gx + n;
		Gp = Fp + hn;
		for (v = 0, x = Ft + u, y = Gt + u;
			v < hn; v ++, x += llen, y += llen)
		{
			Fp[v] = *x;
			Gp[v] = *y;
		}
		if (fk->ternary) {
			modp_NTT3(Fp, gm, logn - 1, 0, p, p0i);
			modp_NTT3(Gp, gm, logn - 1, 0, p, p0i);
		} else {
			modp_NTT2(Fp, gm, logn - 1, p, p0i);
			modp_NTT2(Gp, gm, logn - 1, p, p0i);
		}

		/*
		 * Compute our F and G modulo p.
		 *
		 * General case:
		 *
		 *   we divide degree by d = 2 or 3
		 *   f'(x^d) = N(f)(x^d) = f * adj(f)
		 *   g'(x^d) = N(g)(x^d) = g * adj(g)
		 *   f'*G' - g'*F' = q
		 *   F = F'(x^d) * adj(g)
		 *   G = G'(x^d) * adj(f)
		 *
		 * We compute things in the NTT. We group roots of phi
		 * such that all roots x in a group share the same x^d.
		 * If the roots in a group are x_1, x_2... x_d, then:
		 *
		 *   N(f)(x_1^d) = f(x_1)*f(x_2)*...*f(x_d)
		 *
		 * Thus, we have:
		 *
		 *   G(x_1) = f(x_2)*f(x_3)*...*f(x_d)*G'(x_1^d)
		 *   G(x_2) = f(x_1)*f(x_3)*...*f(x_d)*G'(x_1^d)
		 *   ...
		 *   G(x_d) = f(x_1)*f(x_2)*...*f(x_{d-1})*G'(x_1^d)
		 *
		 * In all cases, we can thus compute F and G in NTT
		 * representation by a few simple multiplications.
		 * Moreover, in our chosen NTT representation, roots
		 * from the same group are consecutive in RAM.
		 */
		if (full) {
			uint32_t R3;
			size_t v2;

			R3 = modp_montymul(R2, R2, p, p0i);
			for (v = 0, v2 = 0, x = Ft + u, y = Gt + u; v < n;
				v += 3, v2 ++, x += 3 * llen, y += 3 * llen)
			{
				uint32_t ftA, ftB, ftC, gtA, gtB, gtC;
				uint32_t mFp, mGp;

				ftA = fx[v + 0];
				ftB = fx[v + 1];
				ftC = fx[v + 2];
				gtA = gx[v + 0];
				gtB = gx[v + 1];
				gtC = gx[v + 2];
				mFp = modp_montymul(Fp[v2], R3, p, p0i);
				mGp = modp_montymul(Gp[v2], R3, p, p0i);
				x[0] = modp_montymul(mFp,
					modp_montymul(gtB, gtC, p, p0i),
					p, p0i);
				x[llen] = modp_montymul(mFp,
					modp_montymul(gtC, gtA, p, p0i),
					p, p0i);
				x[2 * llen] = modp_montymul(mFp,
					modp_montymul(gtA, gtB, p, p0i),
					p, p0i);
				y[0] = modp_montymul(mGp,
					modp_montymul(ftB, ftC, p, p0i),
					p, p0i);
				y[llen] = modp_montymul(mGp,
					modp_montymul(ftC, ftA, p, p0i),
					p, p0i);
				y[2 * llen] = modp_montymul(mGp,
					modp_montymul(ftA, ftB, p, p0i),
					p, p0i);
			}
		} else {
			for (v = 0, x = Ft + u, y = Gt + u; v < hn;
				v ++, x += (llen << 1), y += (llen << 1))
			{
				uint32_t ftA, ftB, gtA, gtB;
				uint32_t mFp, mGp;

				ftA = fx[(v << 1) + 0];
				ftB = fx[(v << 1) + 1];
				gtA = gx[(v << 1) + 0];
				gtB = gx[(v << 1) + 1];
				mFp = modp_montymul(Fp[v], R2, p, p0i);
				mGp = modp_montymul(Gp[v], R2, p, p0i);
				x[0] = modp_montymul(gtB, mFp, p, p0i);
				x[llen] = modp_montymul(gtA, mFp, p, p0i);
				y[0] = modp_montymul(ftB, mGp, p, p0i);
				y[llen] = modp_montymul(ftA, mGp, p, p0i);
			}
		}
		if (fk->ternary) {
			modp_iNTT3_ext(Ft + u, llen, igm, logn, full, p, p0i);
			modp_iNTT3_ext(Gt + u, llen, igm, logn, full, p, p0i);
		} else {
			modp_iNTT2_ext(Ft + u, llen, igm, logn, p, p0i);
			modp_iNTT2_ext(Gt + u, llen, igm, logn, p, p0i);
		}
	}

	/*
	 * Rebuild F and G with the CRT.
	 */
	zint_rebuild_CRT(Ft, llen, llen, n, primes, 1, t1);
	zint_rebuild_CRT(Gt, llen, llen, n, primes, 1, t1);

	/*
	 * At that point, Ft, Gt, ft and gt are consecutive in RAM (in that
	 * order).
	 */

	/*
	 * Apply Babai reduction to bring back F and G to size slen.
	 *
	 * We use the FFT to compute successive approximations of the
	 * reduction coefficient. We first isolate the top bits of
	 * the coefficients of f and g, and convert them to floating
	 * point; with the FFT, we compute adj(f), adj(g), and
	 * 1/(f*adj(f)+g*adj(g)).
	 *
	 * Then, we repeatedly apply the following:
	 *
	 *   - Get the top bits of the coefficients of F and G into
	 *     floating point, and use the FFT to compute:
	 *        (F*adj(f)+G*adj(g))/(f*adj(f)+g*adj(g))
	 *
	 *   - Convert back that value into normal representation, and
	 *     round it to the nearest integers, yielding a polynomial k.
	 *     Proper scaling is applied to f, g, F and G so that the
	 *     coefficients fit on 32 bits (signed).
	 *
	 *   - Subtract k*f from F and k*g from G.
	 *
	 * The process is repeated as long as it works, i.e. it decreases
	 * the maximum bit length of coefficients of F and G. This will
	 * normally bring down F and G down from llen to slen words at
	 * most.
	 */

	/*
	 * Memory layout:
	 *  - We need to compute and keep adj(f), adj(g), and
	 *    1/(f*adj(f)+g*adj(g)) (sizes N, N and N/2 fp numbers,
	 *    respectively).
	 *  - At each iteration we need two extra fp buffer (N fp values),
	 *    and produce a k (N 32-bit words). k will be shared with one
	 *    of the fp buffers.
	 *  - To compute k*f and k*g efficiently (with the NTT), we need
	 *    some extra room; we reuse the space of the temporary buffers.
	 *
	 * Arrays of 'DOUBLE' are obtained from the temporary array itself.
	 * We ensure that the base is at a properly aligned offset (the
	 * source array fk->tmp was obtained with malloc(), and is thus
	 * already aligned).
	 */

	rt3 = align_DOUBLE(fk->tmp, t1);
	rt4 = rt3 + n;
	rt5 = rt4 + n;
	rt1 = rt5 + (n >> 1);
	k = (int32_t *)align_u32(fk->tmp, rt1);
	rt2 = align_DOUBLE(fk->tmp, k + n);
	if (rt2 < (rt1 + n)) {
		rt2 = rt1 + n;
	}
	t1 = (uint32_t *)k + n;

	/*
	 * Get the maximum bit lengths of f and g. f and g are scaled
	 * down by maxbl_fg bits, so that values will be below 1.
	 */
	maxbl_f = poly_max_bitlength(ft, slen, slen, logn, full);
	maxbl_g = poly_max_bitlength(gt, slen, slen, logn, full);
	maxbl_fg = maxbl_f < maxbl_g ? maxbl_g : maxbl_f;

	/*
	 * Compute 1/(f*adj(f)+g*adj(g)) in rt5. We also keep adj(f)
	 * and adj(g) in rt3 and rt4, respectively.
	 */
	poly_big_to_fp(rt3, ft, slen, slen, logn, full, maxbl_fg, maxbl_fg);
	poly_big_to_fp(rt4, gt, slen, slen, logn, full, maxbl_fg, maxbl_fg);

	if (fk->ternary) {
		falcon_FFT3(rt3, logn, full);
		falcon_FFT3(rt4, logn, full);
		falcon_poly_invnorm2_fft3(rt5, rt3, rt4, logn, full);
		falcon_poly_adj_fft3(rt3, logn, full);
		falcon_poly_adj_fft3(rt4, logn, full);
	} else {
		falcon_FFT(rt3, logn);
		falcon_FFT(rt4, logn);
		falcon_poly_invnorm2_fft(rt5, rt3, rt4, logn);
		falcon_poly_adj_fft(rt3, logn);
		falcon_poly_adj_fft(rt4, logn);
	}

	/*
	 * Reduce F and G repeatedly while the processing works.
	 */
	prev_maxbl_FG = (uint32_t)-1;
	FGlen = llen;
	for (;;) {
		uint32_t maxbl_F, maxbl_G, scale_FG, scale_k;
		uint64_t max_kx;

		/*
		 * Get current maximum bit length of F and G. Adjust
		 * the world length accordingly (keeping room for a
		 * dozen extra bits for intermediate computations).
		 */
		maxbl_F = poly_max_bitlength(Ft, FGlen, llen, logn, full);
		maxbl_G = poly_max_bitlength(Gt, FGlen, llen, logn, full);
		maxbl_FG = maxbl_F < maxbl_G ? maxbl_G : maxbl_F;
		while ((FGlen * 31) >= (maxbl_FG + 43)) {
			FGlen --;
		}

		/*
		 * We stop when F and G have been made smaller than
		 * f and g, or when the last reduction round did not
		 * manage to reduce the maximum bit length.
		 */
		if (maxbl_FG <= maxbl_fg || maxbl_FG >= prev_maxbl_FG) {
			break;
		}
		prev_maxbl_FG = maxbl_FG;

		/*
		 * We aim at getting the coefficients of k on 30 bits;
		 * we'll scale them down afterwards if required.
		 */
		scale_FG = maxbl_FG < 30 ? 0 : maxbl_FG - 30;
		poly_big_to_fp(rt1, Ft, FGlen, llen,
			logn, full, maxbl_FG, scale_FG);
		poly_big_to_fp(rt2, Gt, FGlen, llen,
			logn, full, maxbl_FG, scale_FG);

		if (fk->ternary) {
			falcon_FFT3(rt1, logn, full);
			falcon_FFT3(rt2, logn, full);
			falcon_poly_mul_fft3(rt1, rt3, logn, full);
			falcon_poly_mul_fft3(rt2, rt4, logn, full);
			falcon_poly_add_fft3(rt2, rt1, logn, full);
			falcon_poly_mul_autoadj_fft3(rt2, rt5, logn, full);
			falcon_iFFT3(rt2, logn, full);
		} else {
			falcon_FFT(rt1, logn);
			falcon_FFT(rt2, logn);
			falcon_poly_mul_fft(rt1, rt3, logn);
			falcon_poly_mul_fft(rt2, rt4, logn);
			falcon_poly_add_fft(rt2, rt1, logn);
			falcon_poly_mul_autoadj_fft(rt2, rt5, logn);
			falcon_iFFT(rt2, logn);
		}

		/*
		 * Get the maximum coefficient of k, then adjust scaling
		 * so that they all fit on 31 bits.
		 */
		max_kx = 0;
		for (u = 0; u < n; u ++) {
			int64_t kx;

			kx = fpr_rint(rt2[u]);
			if (kx < 0) {
				kx = -kx;
			}
			if ((uint64_t)kx > max_kx) {
				max_kx = kx;
			}
		}
		if (max_kx >= ((uint64_t)1 << 62)) {
			return 0;
		}
		scale_k = bitlength((uint32_t)(max_kx >> 31));

		/*
		 * We need to scale down k by at least scale_k bits. The
		 * final scale will be: scale_FG + scale_k - maxbl_fg;
		 * we also need this value to be nonnegative.
		 */
		if (scale_k + scale_FG < maxbl_fg) {
			scale_k = maxbl_fg - scale_FG;
			if (scale_k > 62) {
				break;
			}
		}

		scale_FG += scale_k;

		/*
		 * Get the coefficients of k as int32_t.
		 */
		for (u = 0; u < n; u ++) {
			int64_t kx, ks;

			kx = fpr_rint(rt2[u]);
			if (kx < 0) {
				ks = -(int32_t)((-kx) >> scale_k);
			} else {
				ks = (int32_t)(kx >> scale_k);
			}
			k[u] = ks;
		}

		/*
		 * If we are at low depth, then we use the NTT to
		 * compute k*f and k*g.
		 */
		if (depth <= DEPTH_INT_FG) {
			poly_sub_scaled_ntt(Ft, FGlen, llen, ft, slen, slen,
				k, scale_FG - maxbl_fg,
				logn, full, fk->ternary, t1);
			poly_sub_scaled_ntt(Gt, FGlen, llen, gt, slen, slen,
				k, scale_FG - maxbl_fg,
				logn, full, fk->ternary, t1);
		} else {
			poly_sub_scaled(Ft, FGlen, llen, ft, slen, slen,
				k, scale_FG - maxbl_fg,
				logn, full, fk->ternary);
			poly_sub_scaled(Gt, FGlen, llen, gt, slen, slen,
				k, scale_FG - maxbl_fg,
				logn, full, fk->ternary);
		}
	}

	/*
	 * If we could not reduce F and G so that they fit in slen, then
	 * this is a failure.
	 */
	if (maxbl_FG > (slen * 31)) {
		return 0;
	}

	/*
	 * Compress encoding of all values to 'slen' words (this is the
	 * expected output format).
	 */
	for (u = 0, x = fk->tmp, y = fk->tmp;
		u < (n << 1); u ++, x += slen, y += llen)
	{
		memmove(x, y, slen * sizeof *y);
	}

	/*
	 * Values might actually be shorter, in which case we must
	 * sign-extend them (caller expects it).
	 */
	if (FGlen < slen) {
		for (u = 0, x = fk->tmp; u < (n << 1); u ++, x += slen) {
			uint32_t sign;
			size_t v;

			sign = -(x[FGlen - 1] >> 30) >> 1;
			for (v = FGlen; v < slen; v ++) {
				x[v] = sign;
			}
		}
	}

	return 1;
}

/*
 * Solving the NTRU equation, binary case, depth = 1. Upon entry, the
 * F and G from the previous level should be in the fk->tmp array.
 *
 * Returned value: 1 on success, 0 on error.
 */
static int
solve_NTRU_binary_depth1(falcon_keygen *fk,
	const int16_t *f, const int16_t *g)
{
	/*
	 * The first half of this function is a copy of the corresponding
	 * part in solve_NTRU_intermediate(), for the reconstruction of
	 * the unreduced F and G. The second half (Babai reduction) is
	 * done differently, because the unreduced F and G fit in 53 bits
	 * of precision, allowing a much simpler process with lower RAM
	 * usage.
	 */
	unsigned depth, logn_top, logn;
	size_t n_top, n, hn, slen, dlen, llen, u;
	uint32_t *Fd, *Gd, *Ft, *Gt, *ft, *gt, *t1;
	DOUBLE *rt1, *rt2, *rt3, *rt4, *rt5, *rt6;
	uint32_t maxbl_f, maxbl_g, maxbl_fg, maxbl_F, maxbl_G, maxbl_FG;
	uint32_t *x, *y;

	depth = 1;
	logn_top = fk->logn;
	n_top = (size_t)1 << logn_top;
	logn = logn_top - depth;
	n = (size_t)1 << logn;
	hn = n >> 1;

	/*
	 * Equations are:
	 *
	 *   f' = f0^2 - X^2*f1^2
	 *   g' = g0^2 - X^2*g1^2
	 *   F' and G' are a solution to f'G' - g'F' = q (from deeper levels)
	 *   F = F'*(g0 - X*g1)
	 *   G = G'*(f0 - X*f1)
	 *
	 * f0, f1, g0, g1, f', g', F' and G' are all "compressed" to
	 * degree N/2 (their odd-indexed coefficients are all zero).
	 */

	/*
	 * slen = size for our input f and g; also size of the reduced
	 *        F and G we return (degree N)
	 *
	 * dlen = size of the F and G obtained from the deeper level
	 *        (degree N/2)
	 *
	 * llen = size for intermediary F and G before reduction (degree N)
	 *
	 * We build our non-reduced F and G as two independent halves each,
	 * of degree N/2 (F = F0 + X*F1, G = G0 + X*G1).
	 */
	slen = MAX_BL_SMALL2[depth];
	dlen = MAX_BL_SMALL2[depth + 1];
	llen = MAX_BL_LARGE2[depth];

	/*
	 * Fd and Gd are the F and G from the deeper level. Ft and Gt
	 * are the destination arrays for the unreduced F and G.
	 */
	Fd = fk->tmp;
	Gd = Fd + dlen * hn;
	Ft = Gd + dlen * hn;
	Gt = Ft + llen * n;

	/*
	 * We reduce Fd and Gd modulo all the small primes we will need,
	 * and store the values in Ft and Gt.
	 */
	for (u = 0; u < llen; u ++) {
		uint32_t p, p0i, R2, Rx;
		size_t v;
		uint32_t *xs, *ys, *xd, *yd;

		p = PRIMES2[u].p;
		p0i = modp_ninv31(p);
		R2 = modp_R2(p, p0i);
		Rx = modp_Rx(dlen, p, p0i, R2);
		for (v = 0, xs = Fd, ys = Gd, xd = Ft + u, yd = Gt + u;
			v < hn;
			v ++, xs += dlen, ys += dlen, xd += llen, yd += llen)
		{
			*xd = zint_mod_small_signed(xs, dlen, p, p0i, R2, Rx);
			*yd = zint_mod_small_signed(ys, dlen, p, p0i, R2, Rx);
		}
	}

	/*
	 * Now Fd and Gd are not needed anymore; we can squeeze them out.
	 */
	memmove(fk->tmp, Ft, llen * n * sizeof(uint32_t));
	Ft = fk->tmp;
	memmove(Ft + llen * n, Gt, llen * n * sizeof(uint32_t));
	Gt = Ft + llen * n;
	ft = Gt + llen * n;
	gt = ft + slen * n;

	t1 = gt + slen * n;

	/*
	 * Compute our F and G modulo sufficiently many small primes.
	 */
	for (u = 0; u < llen; u ++) {
		uint32_t p, p0i, R2;
		uint32_t *gm, *igm, *fx, *gx, *Fp, *Gp;
		unsigned e;
		size_t v;

		/*
		 * All computations are done modulo p.
		 */
		p = PRIMES2[u].p;
		p0i = modp_ninv31(p);
		R2 = modp_R2(p, p0i);

		/*
		 * We recompute things from the source f and g, of full
		 * degree. However, we will need only the n first elements
		 * of the inverse NTT table (igm); the call to modp_mkgm()
		 * below will fill n_top elements in igm[] (thus overflowing
		 * into fx[]) but later code will overwrite these extra
		 * elements.
		 */
		gm = t1;
		igm = gm + n_top;
		fx = igm + n;
		gx = fx + n_top;
		modp_mkgm2(gm, igm, logn_top, PRIMES2[u].g, p, p0i);

		/*
		 * Set ft and gt to f and g modulo p, respectively.
		 */
		for (v = 0; v < n_top; v ++) {
			fx[v] = modp_set(f[v], p);
			gx[v] = modp_set(g[v], p);
		}

		/*
		 * Convert to NTT and compute our f and g.
		 */
		modp_NTT2(fx, gm, logn_top, p, p0i);
		modp_NTT2(gx, gm, logn_top, p, p0i);
		for (e = logn_top; e > logn; e --) {
			modp_poly_rec_res(fx, e, p, p0i, R2);
			modp_poly_rec_res(gx, e, p, p0i, R2);
		}

		/*
		 * From that point onward, we only need tables for
		 * degree n, so we can save some space.
		 */
		if (depth > 0) {
			memmove(gm + n, igm, n * sizeof *igm);
			igm = gm + n;
			memmove(igm + n, fx, n * sizeof *ft);
			fx = igm + n;
			memmove(fx + n, gx, n * sizeof *gt);
			gx = fx + n;
		}

		/*
		 * Get F' and G' modulo p and in NTT representation
		 * (they have degree n/2). These values were computed
		 * in a previous step, and stored in Ft and Gt.
		 */
		Fp = gx + n;
		Gp = Fp + hn;
		for (v = 0, x = Ft + u, y = Gt + u;
			v < hn; v ++, x += llen, y += llen)
		{
			Fp[v] = *x;
			Gp[v] = *y;
		}
		modp_NTT2(Fp, gm, logn - 1, p, p0i);
		modp_NTT2(Gp, gm, logn - 1, p, p0i);

		/*
		 * Compute our F and G modulo p.
		 *
		 * Equations are:
		 *
		 *   f'(x^2) = N(f)(x^2) = f * adj(f)
		 *   g'(x^2) = N(g)(x^2) = g * adj(g)
		 *
		 *   f'*G' - g'*F' = q
		 *
		 *   F = F'(x^2) * adj(g)
		 *   G = G'(x^2) * adj(f)
		 *
		 * The NTT representation of f is f(w) for all w which
		 * are roots of phi. In the binary case, as well as in
		 * the ternary case for all depth except the deepest,
		 * these roots can be grouped in pairs (w,-w), and we
		 * then have:
		 *
		 *   f(w) = adj(f)(-w)
		 *   f(-w) = adj(f)(w)
		 *
		 * and w^2 is then a root for phi at the half-degree.
		 *
		 * At the deepest level in the ternary case, this still
		 * holds, in the following sense: the roots of x^2-x+1
		 * are (w,-w^2) (for w^3 = -1, and w != -1), and we
		 * have:
		 *
		 *   f(w) = adj(f)(-w^2)
		 *   f(-w^2) = adj(f)(w)
		 *
		 * In all case, we can thus compute F and G in NTT
		 * representation by a few simple multiplications.
		 * Moreover, the two roots for each pair are consecutive
		 * in our bit-reversal encoding.
		 */
		for (v = 0, x = Ft + u, y = Gt + u;
			v < hn; v ++, x += (llen << 1), y += (llen << 1))
		{
			uint32_t ftA, ftB, gtA, gtB;
			uint32_t mFp, mGp;

			ftA = fx[(v << 1) + 0];
			ftB = fx[(v << 1) + 1];
			gtA = gx[(v << 1) + 0];
			gtB = gx[(v << 1) + 1];
			mFp = modp_montymul(Fp[v], R2, p, p0i);
			mGp = modp_montymul(Gp[v], R2, p, p0i);
			x[0] = modp_montymul(gtB, mFp, p, p0i);
			x[llen] = modp_montymul(gtA, mFp, p, p0i);
			y[0] = modp_montymul(ftB, mGp, p, p0i);
			y[llen] = modp_montymul(ftA, mGp, p, p0i);
		}
		modp_iNTT2_ext(Ft + u, llen, igm, logn, p, p0i);
		modp_iNTT2_ext(Gt + u, llen, igm, logn, p, p0i);

		/*
		 * Also save ft and gt (only up to size slen).
		 */
		if (u < slen) {
			modp_iNTT2(fx, igm, logn, p, p0i);
			modp_iNTT2(gx, igm, logn, p, p0i);
			for (v = 0, x = ft + u, y = gt + u;
				v < n; v ++, x += slen, y += slen)
			{
				*x = fx[v];
				*y = gx[v];
			}
		}
	}

	/*
	 * Rebuild f, g, F and G with the CRT. Note that the elements of F
	 * and G are consecutive, and thus can be rebuilt in a single
	 * loop; similarly, the elements of f and g are consecutive.
	 */
	zint_rebuild_CRT(Ft, llen, llen, n << 1, PRIMES2, 1, t1);
	zint_rebuild_CRT(ft, slen, slen, n << 1, PRIMES2, 1, t1);

	/*
	 * Here starts the Babai reduction, specialized for depth = 1.
	 *
	 * Candidates F and G (from Ft and Gt), and base f and g (ft and gt),
	 * are converted to floating point. There is no scaling, and a
	 * single pass is sufficient.
	 */

	/*
	 * Get maximum bit length for ft and gt, and for Ft and Gt.
	 */
	maxbl_f = poly_max_bitlength(ft, slen, slen, logn, 0);
	maxbl_g = poly_max_bitlength(gt, slen, slen, logn, 0);
	maxbl_fg = maxbl_f < maxbl_g ? maxbl_g : maxbl_f;

	maxbl_F = poly_max_bitlength(Ft, llen, llen, logn, 0);
	maxbl_G = poly_max_bitlength(Gt, llen, llen, logn, 0);
	maxbl_FG = maxbl_F < maxbl_G ? maxbl_G : maxbl_F;

	if (maxbl_fg > 53 || maxbl_FG > 53) {
		return 0;
	}

	/*
	 * Convert F and G into floating point (rt1 and rt2).
	 */
	rt1 = align_DOUBLE(fk->tmp, gt + slen * n);
	rt2 = rt1 + n;
	poly_big_to_fp(rt1, Ft, llen, llen, logn, 0, maxbl_FG, 0);
	poly_big_to_fp(rt2, Gt, llen, llen, logn, 0, maxbl_FG, 0);

	/*
	 * Integer representation of F and G is no longer needed, we
	 * can remove it.
	 */
	memmove(fk->tmp, ft, 2 * slen * n * sizeof *ft);
	ft = fk->tmp;
	gt = ft + slen * n;
	rt3 = align_DOUBLE(fk->tmp, gt + slen * n);
	memmove(rt3, rt1, 2 * n * sizeof *rt1);
	rt1 = rt3;
	rt2 = rt1 + n;
	rt3 = rt2 + n;
	rt4 = rt3 + n;

	/*
	 * Convert f and g into floating point (rt3 and rt4).
	 */
	poly_big_to_fp(rt3, ft, slen, slen, logn, 0, maxbl_fg, 0);
	poly_big_to_fp(rt4, gt, slen, slen, logn, 0, maxbl_fg, 0);

	/*
	 * Remove unneeded ft and gt.
	 */
	memmove(fk->tmp, rt1, 4 * n * sizeof *rt1);
	rt1 = (DOUBLE *)fk->tmp;
	rt2 = rt1 + n;
	rt3 = rt2 + n;
	rt4 = rt3 + n;

	/*
	 * We now have:
	 *   rt1 = F
	 *   rt2 = G
	 *   rt3 = f
	 *   rt4 = g
	 * in that order in RAM. We convert all of them to FFT.
	 */
	falcon_FFT(rt1, logn);
	falcon_FFT(rt2, logn);
	falcon_FFT(rt3, logn);
	falcon_FFT(rt4, logn);

	/*
	 * Compute:
	 *   rt5 = F*adj(f) + G*adj(g)
	 *   rt6 = 1 / (f*adj(f) + g*adj(g))
	 * (Note that rt6 is half-length.)
	 */
	rt5 = rt4 + n;
	rt6 = rt5 + n;
	falcon_poly_add_muladj_fft(rt5, rt1, rt2, rt3, rt4, logn);
	falcon_poly_invnorm2_fft(rt6, rt3, rt4, logn);

	/*
	 * Compute:
	 *   rt5 = (F*adj(f)+G*adj(g)) / (f*adj(f)+g*adj(g))
	 */
	falcon_poly_mul_autoadj_fft(rt5, rt6, logn);

	/*
	 * Compute k as the rounded version of rt5.
	 */
	falcon_iFFT(rt5, logn);
	for (u = 0; u < n; u ++) {
		rt5[u] = fpr_rint(rt5[u]);
	}
	falcon_FFT(rt5, logn);

	/*
	 * Subtract k*f from F, and k*g from G.
	 */
	falcon_poly_mul_fft(rt3, rt5, logn);
	falcon_poly_mul_fft(rt4, rt5, logn);
	falcon_poly_sub_fft(rt1, rt3, logn);
	falcon_poly_sub_fft(rt2, rt4, logn);
	falcon_iFFT(rt1, logn);
	falcon_iFFT(rt2, logn);

	/*
	 * Convert back F and G to integers, and return.
	 */
	Ft = fk->tmp;
	Gt = Ft + n;
	rt3 = align_DOUBLE(fk->tmp, Gt + n);
	memmove(rt3, rt1, 2 * n * sizeof *rt1);
	rt1 = rt3;
	rt2 = rt1 + n;
	for (u = 0; u < n; u ++) {
		Ft[u] = (uint32_t)fpr_rint(rt1[u]);
		Gt[u] = (uint32_t)fpr_rint(rt2[u]);
	}

	return 1;
}

/*
 * Solving the NTRU equation, top level. Upon entry, the F and G
 * from the previous level should be in the fk->tmp array.
 *
 * Returned value: 1 on success, 0 on error.
 */
static int
solve_NTRU_binary_depth0(falcon_keygen *fk,
	const int16_t *f, const int16_t *g)
{
	unsigned logn;
	size_t n, hn, u;
	uint32_t p, p0i, R2;
	uint32_t *Fp, *Gp, *t1, *t2, *t3, *t4, *t5;
	uint32_t *gm, *igm, *ft, *gt;
	DOUBLE *rt2, *rt3;

	logn = fk->logn;
	n = (size_t)1 << logn;
	hn = n >> 1;

	/*
	 * Equations are:
	 *
	 *   f' = f0^2 - X^2*f1^2
	 *   g' = g0^2 - X^2*g1^2
	 *   F' and G' are a solution to f'G' - g'F' = q (from deeper levels)
	 *   F = F'*(g0 - X*g1)
	 *   G = G'*(f0 - X*f1)
	 *
	 * f0, f1, g0, g1, f', g', F' and G' are all "compressed" to
	 * degree N/2 (their odd-indexed coefficients are all zero).
	 *
	 * Everything should fit in 31-bit integers, hence we can just use
	 * the first small prime p = 2147473409.
	 */
	p = PRIMES2[0].p;
	p0i = modp_ninv31(p);
	R2 = modp_R2(p, p0i);

	Fp = fk->tmp;
	Gp = Fp + hn;
	ft = Gp + hn;
	gt = ft + n;
	gm = gt + n;
	igm = gm + n;

	modp_mkgm2(gm, igm, logn, PRIMES2[0].g, p, p0i);

	/*
	 * Convert F' anf G' in NTT representation.
	 */
	for (u = 0; u < hn; u ++) {
		Fp[u] = modp_set(zint_one_to_plain(Fp + u), p);
		Gp[u] = modp_set(zint_one_to_plain(Gp + u), p);
	}
	modp_NTT2(Fp, gm, logn - 1, p, p0i);
	modp_NTT2(Gp, gm, logn - 1, p, p0i);

	/*
	 * Load f and g and convert them to NTT representation.
	 */
	for (u = 0; u < n; u ++) {
		ft[u] = modp_set(f[u], p);
		gt[u] = modp_set(g[u], p);
	}
	modp_NTT2(ft, gm, logn, p, p0i);
	modp_NTT2(gt, gm, logn, p, p0i);

	/*
	 * Build the unreduced F,G in ft and gt.
	 */
	for (u = 0; u < n; u += 2) {
		uint32_t ftA, ftB, gtA, gtB;
		uint32_t mFp, mGp;

		ftA = ft[u + 0];
		ftB = ft[u + 1];
		gtA = gt[u + 0];
		gtB = gt[u + 1];
		mFp = modp_montymul(Fp[u >> 1], R2, p, p0i);
		mGp = modp_montymul(Gp[u >> 1], R2, p, p0i);
		ft[u + 0] = modp_montymul(gtB, mFp, p, p0i);
		ft[u + 1] = modp_montymul(gtA, mFp, p, p0i);
		gt[u + 0] = modp_montymul(ftB, mGp, p, p0i);
		gt[u + 1] = modp_montymul(ftA, mGp, p, p0i);
	}
	modp_iNTT2(ft, igm, logn, p, p0i);
	modp_iNTT2(gt, igm, logn, p, p0i);

	Gp = Fp + n;
	t1 = Gp + n;
	memmove(Fp, ft, 2 * n * sizeof *ft);

	/*
	 * We now need to apply the Babai reduction. At that point,
	 * we have F and G in two n-word arrays.
	 *
	 * We can compute F*adj(f)+G*adj(g) and f*adj(f)+g*adj(g)
	 * modulo p, using the NTT. We still move memory around in
	 * order to save RAM.
	 */
	t2 = t1 + n;
	t3 = t2 + n;
	t4 = t3 + n;
	t5 = t4 + n;

	/*
	 * Compute the NTT tables in t1 and t2. We do not keep t2
	 * (we'll recompute it later on).
	 */
	modp_mkgm2(t1, t2, logn, PRIMES2[0].g, p, p0i);

	/*
	 * Convert F and G to NTT.
	 */
	modp_NTT2(Fp, t1, logn, p, p0i);
	modp_NTT2(Gp, t1, logn, p, p0i);

	/*
	 * Load f and adj(f) in t4 and t5, and convert them to NTT
	 * representation.
	 */
	t4[0] = t5[0] = modp_set(f[0], p);
	for (u = 1; u < n; u ++) {
		t4[u] = modp_set(f[u], p);
		t5[n - u] = modp_set(-f[u], p);
	}
	modp_NTT2(t4, t1, logn, p, p0i);
	modp_NTT2(t5, t1, logn, p, p0i);

	/*
	 * Compute F*adj(f) in t2, and f*adj(f) in t3.
	 */
	for (u = 0; u < n; u ++) {
		uint32_t w;

		w = modp_montymul(t5[u], R2, p, p0i);
		t2[u] = modp_montymul(w, Fp[u], p, p0i);
		t3[u] = modp_montymul(w, t4[u], p, p0i);
	}

	/*
	 * Load g and adj(g) in t4 and t5, and convert them to NTT
	 * representation.
	 */
	t4[0] = t5[0] = modp_set(g[0], p);
	for (u = 1; u < n; u ++) {
		t4[u] = modp_set(g[u], p);
		t5[n - u] = modp_set(-g[u], p);
	}
	modp_NTT2(t4, t1, logn, p, p0i);
	modp_NTT2(t5, t1, logn, p, p0i);

	/*
	 * Add G*adj(g) to t2, and g*adj(g) to t3.
	 */
	for (u = 0; u < n; u ++) {
		uint32_t w;

		w = modp_montymul(t5[u], R2, p, p0i);
		t2[u] = modp_add(t2[u],
			modp_montymul(w, Gp[u], p, p0i), p);
		t3[u] = modp_add(t3[u],
			modp_montymul(w, t4[u], p, p0i), p);
	}

	/*
	 * Convert back t2 and t3 to normal representation (normalized
	 * around 0), and then
	 * move them to t1 and t2. We first need to recompute the
	 * inverse table for NTT.
	 */
	modp_mkgm2(t1, t4, logn, PRIMES2[0].g, p, p0i);
	modp_iNTT2(t2, t4, logn, p, p0i);
	modp_iNTT2(t3, t4, logn, p, p0i);
	for (u = 0; u < n; u ++) {
		t1[u] = (uint32_t)modp_norm(t2[u], p);
		t2[u] = (uint32_t)modp_norm(t3[u], p);
	}

	/*
	 * At that point, array contents are:
	 *
	 *   F (NTT representation) (Fp)
	 *   G (NTT representation) (Gp)
	 *   F*adj(f)+G*adj(g) (t1)
	 *   f*adj(f)+g*adj(g) (t2)
	 *
	 * We want to divide t1 by t2. The result is not integral; it
	 * must be rounded. We thus need to use the FFT.
	 */

	/*
	 * Get f*adj(f)+g*adj(g) in FFT representation. Since this
	 * polynomial is auto-adjoint, all its coordinates in FFT
	 * representation are actually real, so we can truncate off
	 * the imaginary parts.
	 */
	rt3 = align_DOUBLE(fk->tmp, t3);
	for (u = 0; u < n; u ++) {
		rt3[u] = (DOUBLE)((int32_t *)t2)[u];
	}
	falcon_FFT(rt3, logn);
	rt2 = align_DOUBLE(fk->tmp, t2);
	memmove(rt2, rt3, hn * sizeof *rt3);

	/*
	 * Convert F*adj(f)+G*adj(g) in FFT representation.
	 */
	rt3 = rt2 + hn;
	for (u = 0; u < n; u ++) {
		rt3[u] = (DOUBLE)((int32_t *)t1)[u];
	}
	falcon_FFT(rt3, logn);

	/*
	 * Compute (F*adj(f)+G*adj(g))/(f*adj(f)+g*adj(g)) and get
	 * its rounded normal representation in t1.
	 */
	falcon_poly_div_autoadj_fft(rt3, rt2, logn);
	falcon_iFFT(rt3, logn);
	for (u = 0; u < n; u ++) {
		t1[u] = modp_set((int32_t)fpr_rint(rt3[u]), p);
	}

	/*
	 * RAM contents are now:
	 *
	 *   F (NTT representation) (Fp)
	 *   G (NTT representation) (Gp)
	 *   k (t1)
	 *
	 * We want to compute F-k*f, and G-k*g.
	 */
	t2 = t1 + n;
	t3 = t2 + n;
	t4 = t3 + n;
	t5 = t4 + n;
	modp_mkgm2(t2, t3, logn, PRIMES2[0].g, p, p0i);
	for (u = 0; u < n; u ++) {
		t4[u] = modp_set(f[u], p);
		t5[u] = modp_set(g[u], p);
	}
	modp_NTT2(t1, t2, logn, p, p0i);
	modp_NTT2(t4, t2, logn, p, p0i);
	modp_NTT2(t5, t2, logn, p, p0i);
	for (u = 0; u < n; u ++) {
		uint32_t kw;

		kw = modp_montymul(t1[u], R2, p, p0i);
		Fp[u] = modp_sub(Fp[u],
			modp_montymul(kw, t4[u], p, p0i), p);
		Gp[u] = modp_sub(Gp[u],
			modp_montymul(kw, t5[u], p, p0i), p);
	}
	modp_iNTT2(Fp, t3, logn, p, p0i);
	modp_iNTT2(Gp, t3, logn, p, p0i);
	for (u = 0; u < n; u ++) {
		Fp[u] = (uint32_t)modp_norm(Fp[u], p);
		Gp[u] = (uint32_t)modp_norm(Gp[u], p);
	}

	return 1;
}

/*
 * Solving the NTRU equation, top level, ternary case. Upon entry, the
 * F and G from the previous level should be in the fk->tmp array.
 *
 * Returned value: 1 on success, 0 on error.
 */
static int
solve_NTRU_ternary_depth0(falcon_keygen *fk,
	const int16_t *f, const int16_t *g)
{
	unsigned logn;
	size_t n, tn, hn, sn, u, v;
	uint32_t *Fp, *Gp, *t1;
	DOUBLE *rt1, *rt2, *rt3, *rt4, *rt5;

	logn = fk->logn;
	n = (size_t)3 << (logn - 1);
	tn = (size_t)1 << (logn - 1);
	hn = n >> 1;
	sn = tn >> 1;

	/*
	 * The F' and G' from the upper level should fit on one word per
	 * value, since MAX_BL_SMALL3[1] == 1. However, intermediate
	 * values won't fit, and we will need to use floating point.
	 */
	Fp = fk->tmp;
	Gp = Fp + tn;
	t1 = Gp + tn;

	/*
	 * Load f and g into floating-point registers, and compute
	 * 1/(f*adj(f)+g*adj(g)) (in FFT representation).
	 */
	rt1 = align_DOUBLE(fk->tmp, t1);
	rt2 = rt1 + n;
	rt3 = rt2 + n;
	poly_small_to_fp(rt1, f, logn, 1);
	poly_small_to_fp(rt2, g, logn, 1);
	falcon_FFT3(rt1, logn, 1);
	falcon_FFT3(rt2, logn, 1);
	falcon_poly_invnorm2_fft3(rt3, rt1, rt2, logn, 1);

	/*
	 * We discard f and g for now.
	 */
	memmove(rt1, rt3, hn * sizeof *rt3);
	rt5 = rt1;

	/*
	 * We load F' and G' into rt1 and rt2 (in FFT representation).
	 */
	rt1 = rt5 + hn;
	rt2 = rt1 + tn;
	for (u = 0; u < tn; u ++) {
		rt1[u] = (DOUBLE)zint_one_to_plain(Fp + u);
		rt2[u] = (DOUBLE)zint_one_to_plain(Gp + u);
	}
	falcon_FFT3(rt1, logn - 1, 0);
	falcon_FFT3(rt2, logn - 1, 0);

	/*
	 * We don't need the non-fp F' and G' now.
	 */
	memmove(fk->tmp, rt5, (hn + tn * 2) * sizeof(*rt1));
	rt5 = (DOUBLE *)fk->tmp;
	rt1 = rt5 + hn;
	rt2 = rt1 + tn;

	/*
	 * We have 1/(f*adj(f)+g*adj(g)), F' and G' in RAM, in that
	 * order (rt5, rt1 and rt2, with hn, tn and tn slots, respectively).
	 *
	 * Load f and g in rt3 and rt4, in FFT representation.
	 */
	rt3 = rt2 + tn;
	rt4 = rt3 + n;
	poly_small_to_fp(rt3, f, logn, 1);
	poly_small_to_fp(rt4, g, logn, 1);
	falcon_FFT3(rt3, logn, 1);
	falcon_FFT3(rt4, logn, 1);

	/*
	 * Build candidate F and G in rt3 and rt4.
	 */
	for (u = 0, v = 0; u < hn; u += 3, v ++) {

#define FPC_MUL(d_re, d_im, a_re, a_im, b_re, b_im)   do { \
		DOUBLE fpct_a_re, fpct_a_im; \
		DOUBLE fpct_b_re, fpct_b_im; \
		DOUBLE fpct_d_re, fpct_d_im; \
		fpct_a_re = (a_re); \
		fpct_a_im = (a_im); \
		fpct_b_re = (b_re); \
		fpct_b_im = (b_im); \
		fpct_d_re = fpr_sub( \
			fpr_mul(fpct_a_re, fpct_b_re), \
			fpr_mul(fpct_a_im, fpct_b_im)); \
		fpct_d_im = fpr_add( \
			fpr_mul(fpct_a_re, fpct_b_im), \
			fpr_mul(fpct_a_im, fpct_b_re)); \
		(d_re) = fpct_d_re; \
		(d_im) = fpct_d_im; \
	} while (0)

		DOUBLE Fre, Fim, Gre, Gim;
		DOUBLE f1re, f1im, f2re, f2im, f3re, f3im;
		DOUBLE g1re, g1im, g2re, g2im, g3re, g3im;
		DOUBLE re, im;

		/*
		 * Let x1, x2 and x3 be three roots of phi that share the
		 * same cube x1^3. Then we have:
		 *
		 *   G(x1) = f(x2)*f(x3)*G'(x1^3)
		 *   G(x2) = f(x3)*f(x1)*G'(x1^3)
		 *   G(x3) = f(x1)*f(x2)*G'(x1^3)
		 *
		 * f(x1), f(x2) and f(x3) are consecutive in our FFT
		 * representation.
		 */
		Fre = rt1[v];
		Fim = rt1[v + sn];
		Gre = rt2[v];
		Gim = rt2[v + sn];
		f1re = rt3[u + 0];
		f1im = rt3[u + 0 + hn];
		f2re = rt3[u + 1];
		f2im = rt3[u + 1 + hn];
		f3re = rt3[u + 2];
		f3im = rt3[u + 2 + hn];
		g1re = rt4[u + 0];
		g1im = rt4[u + 0 + hn];
		g2re = rt4[u + 1];
		g2im = rt4[u + 1 + hn];
		g3re = rt4[u + 2];
		g3im = rt4[u + 2 + hn];

		FPC_MUL(re, im, f2re, f2im, f3re, f3im);
		FPC_MUL(rt4[u + 0], rt4[u + 0 + hn], re, im, Gre, Gim);
		FPC_MUL(re, im, f3re, f3im, f1re, f1im);
		FPC_MUL(rt4[u + 1], rt4[u + 1 + hn], re, im, Gre, Gim);
		FPC_MUL(re, im, f1re, f1im, f2re, f2im);
		FPC_MUL(rt4[u + 2], rt4[u + 2 + hn], re, im, Gre, Gim);
		FPC_MUL(re, im, g2re, g2im, g3re, g3im);
		FPC_MUL(rt3[u + 0], rt3[u + 0 + hn], re, im, Fre, Fim);
		FPC_MUL(re, im, g3re, g3im, g1re, g1im);
		FPC_MUL(rt3[u + 1], rt3[u + 1 + hn], re, im, Fre, Fim);
		FPC_MUL(re, im, g1re, g1im, g2re, g2im);
		FPC_MUL(rt3[u + 2], rt3[u + 2 + hn], re, im, Fre, Fim);

#undef FPC_MUL
	}

	/*
	 * We can discard F' and G' now. We rename F and G as rt1 and
	 * rt2, respectively. They are in FFT representation.
	 */
	memmove(rt1, rt3, 2 * n * sizeof *rt3);
	rt2 = rt1 + n;
	rt3 = rt2 + n;
	rt4 = rt3 + n;

	/*
	 * Memory contents:
	 *   rt5   hn slots   1/(f*adj(f)+g*adj(g))
	 *   rt1   n slots    F
	 *   rt2   n slots    G
	 *   rt3   n slots    free
	 *   rt4   n slots    free
	 *
	 * We load f and g into rt3 and rt4 (FFT).
	 */
	poly_small_to_fp(rt3, f, logn, 1);
	poly_small_to_fp(rt4, g, logn, 1);
	falcon_FFT3(rt3, logn, 1);
	falcon_FFT3(rt4, logn, 1);

	/*
	 * Compute (F*adj(f)+G*adj(g))/(f*adj(f)+g*adj(g)) in rt3.
	 */
	falcon_poly_adj_fft3(rt3, logn, 1);
	falcon_poly_adj_fft3(rt4, logn, 1);
	falcon_poly_mul_fft3(rt3, rt1, logn, 1);
	falcon_poly_mul_fft3(rt4, rt2, logn, 1);
	falcon_poly_add_fft3(rt3, rt4, logn, 1);
	falcon_poly_mul_autoadj_fft3(rt3, rt5, logn, 1);

	/*
	 * Round the contents of rt3 to get k, converted back into FFT.
	 */
	falcon_iFFT3(rt3, logn, 1);
	for (u = 0; u < n; u ++) {
		rt3[u] = (DOUBLE)fpr_rint(rt3[u]);
	}
	falcon_FFT3(rt3, logn, 1);

	/*
	 * Subtract k*f from F, and k*g from G.
	 */
	poly_small_to_fp(rt4, f, logn, 1);
	falcon_FFT3(rt4, logn, 1);
	falcon_poly_mul_fft3(rt4, rt3, logn, 1);
	falcon_poly_sub_fft3(rt1, rt4, logn, 1);
	poly_small_to_fp(rt4, g, logn, 1);
	falcon_FFT3(rt4, logn, 1);
	falcon_poly_mul_fft3(rt4, rt3, logn, 1);
	falcon_poly_sub_fft3(rt2, rt4, logn, 1);

	/*
	 * Convert back the final F and G from FFT.
	 */
	falcon_iFFT3(rt1, logn, 1);
	falcon_iFFT3(rt2, logn, 1);

	Fp = fk->tmp;
	Gp = Fp + n;
	t1 = Gp + n;
	rt5 = align_DOUBLE(fk->tmp, t1);
	memmove(rt5, rt1, 2 * n * sizeof *rt1);
	rt1 = rt5;
	rt2 = rt1 + n;
	for (u = 0; u < n; u ++) {
		Fp[u] = (uint32_t)fpr_rint(rt1[u]);
		Gp[u] = (uint32_t)fpr_rint(rt2[u]);
	}

	return 1;
}

/*
 * Solve the NTRU equation. Returned value is 1 on success, 0 on error.
 */
int
solve_NTRU(falcon_keygen *fk, int16_t *F, int16_t *G,
	const int16_t *f, const int16_t *g)
{
	unsigned logn;
	size_t n, u;
	uint32_t *ft, *gt, *Ft, *Gt, *gm;
	uint32_t p, p0i, r;
	const small_prime *primes;

	logn = fk->logn;
	n = MKN(logn, fk->ternary);

	if (!solve_NTRU_deepest(fk, f, g)) {
		fprintf(stderr, "Failed to solve deepest\n");
		return 0;
	}

	/*
	 * For logn <= 2, we need to use solve_NTRU_intermediate()
	 * directly, because coefficients are a bit too large and
	 * do not fit the hypotheses in solve_NTRU_binary_depth0()
	 * or solve_NTRU_ternary_depth0().
	 */
	if (logn <= 2) {
		unsigned depth;

		depth = logn;
		while (depth -- > 0) {
			if (!solve_NTRU_intermediate(fk, f, g, depth)) {
				return 0;
			}
		}
	} else {
		unsigned depth;

		depth = logn;
		if (fk->ternary) {
			while (depth -- > 1) {
				if (!solve_NTRU_intermediate(fk, f, g, depth)) {
					return 0;
				}
			}
			if (!solve_NTRU_ternary_depth0(fk, f, g)) {
				return 0;
			}
		} else {
			while (depth -- > 2) {
				if (!solve_NTRU_intermediate(fk, f, g, depth)) {
					return 0;
				}
			}
			if (!solve_NTRU_binary_depth1(fk, f, g)) {
				return 0;
			}
			if (!solve_NTRU_binary_depth0(fk, f, g)) {
				return 0;
			}
		}
	}

	/*
	 * Final F and G are in fk->tmp, one word per coefficient
	 * (signed value over 31 bits).
	 */
	if (!poly_big_to_small(F, fk->tmp, logn, fk->ternary)
		|| !poly_big_to_small(G, fk->tmp + n, logn, fk->ternary))
	{
		return 0;
	}

	/*
	 * Verify that the NTRU equation is fulfilled. Since all elements
	 * have short lengths, verifying modulo a small prime p works, and
	 * allows using the NTT.
	 */
	ft = fk->tmp;
	gt = ft + n;
	Ft = gt + n;
	Gt = Ft + n;
	gm = Gt + n;

	primes = fk->ternary ? PRIMES3 : PRIMES2;
	p = primes[0].p;
	p0i = modp_ninv31(p);
	if (fk->ternary) {
		modp_mkgm3(gm, ft, logn, 1, primes[0].g, p, p0i);
	} else {
		modp_mkgm2(gm, ft, logn, primes[0].g, p, p0i);
	}
	for (u = 0; u < n; u ++) {
		ft[u] = modp_set(f[u], p);
		gt[u] = modp_set(g[u], p);
		Ft[u] = modp_set(F[u], p);
		Gt[u] = modp_set(G[u], p);
	}
	if (fk->ternary) {
		modp_NTT3(ft, gm, logn, 1, p, p0i);
		modp_NTT3(gt, gm, logn, 1, p, p0i);
		modp_NTT3(Ft, gm, logn, 1, p, p0i);
		modp_NTT3(Gt, gm, logn, 1, p, p0i);
		r = modp_montymul(18433, 1, p, p0i);
	} else {
		modp_NTT2(ft, gm, logn, p, p0i);
		modp_NTT2(gt, gm, logn, p, p0i);
		modp_NTT2(Ft, gm, logn, p, p0i);
		modp_NTT2(Gt, gm, logn, p, p0i);
		r = modp_montymul(12289, 1, p, p0i);
	}
	for (u = 0; u < n; u ++) {
		uint32_t z;

		z = modp_sub(modp_montymul(ft[u], Gt[u], p, p0i),
			modp_montymul(gt[u], Ft[u], p, p0i), p);
		if (z != r) {
			return 0;
		}
	}

	return 1;
}

/*
 * Generate a random polynomial with a Gaussian distribution. This function
 * also makes sure that the resultant of the polynomial with phi is odd.
 *
 * This function is only for the binary case. 
 */
static void
poly_small_mkgauss(falcon_keygen *fk, int16_t *f, unsigned logn)
{
	size_t n, u;
	unsigned mod2;

	n = MKN(logn, 0);
	mod2 = 0;
	for (u = 0; u < n; u ++) {
		int s;

	restart:
		s = mkgauss(fk, logn);
		if (u == n - 1) {
			if ((mod2 ^ (unsigned)(s & 1)) == 0) {
				goto restart;
			}
		} else {
			mod2 ^= (unsigned)(s & 1);
		}
		f[u] = s;
	}
}

/* see falcon.h */
int
falcon_keygen_make(falcon_keygen *fk, int comp,
	void *privkey, size_t *privkey_len,
	void *pubkey, size_t *pubkey_len)
{
	/*
	 * Algorithm is the following:
	 *
	 *  - Generate f and g with the Gaussian distribution.
	 *
	 *  - If either Res(f,phi) or Res(g,phi) is even, try again.
	 *
	 *  - If ||(f,g)|| is too large, try again.
	 *
	 *  - If ||B~_{f,g}|| is too large, try again.
	 *
	 *  - If f is not invertible mod phi mod q, try again.
	 *
	 *  - Compute h = g/f mod phi mod q.
	 *
	 *  - Solve the NTRU equation fG - gF = q; if the solving fails,
	 *    try again. Usual failure condition is when Res(f,phi)
	 *    and Res(g,phi) are not prime to each other.
	 */
	unsigned logn, ter;
	size_t n, u;
	int16_t f[1024], g[1024], F[1024], G[1024];
	uint16_t h[1024];
	size_t klen, skoff;
	unsigned char *skbuf;
	int16_t *ske[4];
	int i;

	logn = fk->logn;
	ter = fk->ternary;
	n = MKN(logn, ter);

	/*
	 * Make sure the RNG is properly seeded and ready to output bits.
	 */
	if (!rng_ready(fk)) {
		return 0;
	}

	/*
	 * We need to generate f and g randomly, until we find values
	 * such that the norm of (g,-f), and of the orthogonalized
	 * vector, are satisfying. The orthogonalized vector is:
	 *   (q*adj(f)/(f*adj(f)+g*adj(g)), q*adj(g)/(f*adj(f)+g*adj(g)))
	 * (it is actually the (N+1)-th row of the Gram-Schmidt basis).
	 *
	 * In the binary case, coefficients of f and g are generated
	 * independently of each other, with a discrete Gaussian
	 * distribution of standard deviation 1.17*sqrt(q/(2*N)). Then,
	 * the two vectors have expected norm 1.17*sqrt(q), which is
	 * also our acceptance bound: we require both vectors to be no
	 * larger than that (this will be satisfied about 1/4th of the
	 * time, thus we expect sampling new (f,g) about 4 times for that
	 * step).
	 *
	 * In the ternary case, we need a spheroid in the FFT representation,
	 * thus we use a rounded Gaussian in that representation. Standard
	 * deviation is then sigma = sqrt(q/sqrt(8)). The vector norms
	 * are computed over the FFT representation, with common bound
	 * 2*sqrt(N)*sigma.
	 *
	 * In both cases, we require that Res(f,phi) and Res(g,phi) are
	 * both odd (the NTRU equation solver requires it).
	 */
	for (;;) {
		DOUBLE *rt1, *rt2, *rt3;
		DOUBLE bnorm;
		DOUBLE bound;
		uint32_t normf, normg, norm;

		/*
		 * The poly_small_mkgauss() function makes sure
		 * that the sum of coefficients is 1 modulo 2
		 * (i.e. the resultant of the polynomial with phi
		 * will be odd).
		 */
		poly_small_mkgauss(fk, f, logn);
		poly_small_mkgauss(fk, g, logn);

		/*
		 * Bound is 1.17*sqrt(q). We compute the squared
		 * norms. With q = 12289, the squared bound is:
		 *   (1.17^2)* 12289 = 16822.4121
		 * Since f and g are integral, the squared norm
		 * of (g,-f) is an integer.
		 */
		normf = poly_small_sqnorm(f, logn, ter);
		normg = poly_small_sqnorm(g, logn, ter);
		norm = (normf + normg) | -((normf | normg) >> 31);
		bound = 1.3689 * fk->q;
		if (norm >= bound) {
			continue;
		}

		/*
		 * We compute the orthogonalized vector norm.
		 */
		rt1 = (DOUBLE *)fk->tmp;
		rt2 = rt1 + n;
		rt3 = rt2 + n;
		poly_small_to_fp(rt1, f, logn, 0);
		poly_small_to_fp(rt2, g, logn, 0);
		falcon_FFT(rt1, logn);
		falcon_FFT(rt2, logn);
		falcon_poly_invnorm2_fft(rt3, rt1, rt2, logn);
		falcon_poly_adj_fft(rt1, logn);
		falcon_poly_adj_fft(rt2, logn);
		falcon_poly_mulconst_fft(rt1, (DOUBLE)fk->q, logn);
		falcon_poly_mulconst_fft(rt2, (DOUBLE)fk->q, logn);
		falcon_poly_mul_autoadj_fft(rt1, rt3, logn);
		falcon_poly_mul_autoadj_fft(rt2, rt3, logn);
		falcon_iFFT(rt1, logn);
		falcon_iFFT(rt2, logn);
		bnorm = (DOUBLE)0;
		for (u = 0; u < n; u ++) {
			bnorm = fpr_add(bnorm, fpr_sqr(rt1[u]));
			bnorm = fpr_add(bnorm, fpr_sqr(rt2[u]));
		}
		if (!fpr_lt(bnorm, fpr_div(
			(DOUBLE)168224121, (DOUBLE)10000)))
		{
			continue;
		}

		/*
		 * Compute public key h = g/f mod X^N+1 mod q. If this
		 * fails, we must restart.
		 */
		if (!falcon_compute_public(h, f, g, logn, ter)) {
			continue;
		}

		/*
		 * Solve the NTRU equation to get F and G.
		 */
		if (!solve_NTRU(fk, F, G, f, g)) {
			continue;
		}

		/*
		 * Key pair is generated.
		 */
		break;
	}

	/*
	 * Encode private key.
	 */
	klen = *privkey_len;
	skbuf = privkey;
	if (klen < 1) {
		return 0;
	}
	skbuf[0] = (ter << 7) + (comp << 5) + logn;
	skoff = 1;
	ske[0] = f;
	ske[1] = g;
	ske[2] = F;
	ske[3] = G;
	for (i = 0; i < 4; i ++) {
		size_t elen;

		elen = falcon_encode_small(skbuf + skoff, klen - skoff,
			comp, fk->q, ske[i], logn);
		if (elen == 0) {
			return 0;
		}
		skoff += elen;
	}
	*privkey_len = skoff;

	/*
	 * Encode public key.
	 */
	klen = *pubkey_len;
	if (klen < 1) {
		return 0;
	}
	((unsigned char *)pubkey)[0] = (ter << 7) + logn;
	if (ter) {
		klen = falcon_encode_18433(
			(unsigned char *)pubkey + 1, klen - 1, h, logn);
	} else {
		klen = falcon_encode_12289(
			(unsigned char *)pubkey + 1, klen - 1, h, logn);
	}
	if (klen == 0) {
		return 0;
	}
	*pubkey_len = klen + 1;

	/*
	 * Success!
	 */
	return 1;
}
