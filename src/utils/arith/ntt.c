/*****************************************************************************
 * Copyright (C) Queen's University Belfast, ECIT, 2016                      *
 *                                                                           *
 * This file is part of libsafecrypto.                                       *
 *                                                                           *
 * This file is subject to the terms and conditions defined in the file      *
 * 'LICENSE', which is part of this source code package.                     *
 *****************************************************************************/

/*
 * Git commit information:
 *   Author: $SC_AUTHOR$
 *   Date:   $SC_DATE$
 *   Branch: $SC_BRANCH$
 *   Id:     $SC_IDENT$
 */

#include "utils/arith/ntt.h"
#ifndef USE_RUNTIME_NTT_TABLES
#include "utils/arith/ntt_tables.h"
#endif
#include "utils/arith/sc_math.h"

#include <stdio.h>

#if defined(HAVE_AVX) || defined(HAVE_AVX2)
#include <immintrin.h>
#endif


const utils_arith_ntt_t *ntt_table;


#ifdef LUT_BASED_INVERSE_SHUFFLE
static const SC_DEFAULT_ALIGNED UINT32 shuffle_lut_256[120] =
{
     ((1<<16) | 128), ((2<<16) | 64), ((3<<16) | 192), ((4<<16) | 32), ((5<<16) | 160), ((6<<16) | 96), ((7<<16) | 224), ((8<<16) | 16), ((9<<16) | 144),
    ((10<<16) | 80), ((11<<16) | 208), ((12<<16) | 48), ((13<<16) | 176), ((14<<16) | 112), ((15<<16) | 240), ((17<<16) | 136), ((18<<16) | 72),
    ((19<<16) | 200), ((20<<16) | 40), ((21<<16) | 168), ((22<<16) | 104), ((23<<16) | 232), ((25<<16) | 152), ((26<<16) | 88), ((27<<16) | 216),
    ((28<<16) | 56), ((29<<16) | 184), ((30<<16) | 120), ((31<<16) | 248), ((33<<16) | 132), ((34<<16) | 68), ((35<<16) | 196), ((37<<16) | 164),
    ((38<<16) | 100), ((39<<16) | 228), ((41<<16) | 148), ((42<<16) | 84), ((43<<16) | 212), ((44<<16) | 52), ((45<<16) | 180), ((46<<16) | 116),
    ((47<<16) | 244), ((49<<16) | 140), ((50<<16) | 76), ((51<<16) | 204), ((53<<16) | 172), ((54<<16) | 108), ((55<<16) | 236), ((57<<16) | 156),
    ((58<<16) | 92), ((59<<16) | 220), ((61<<16) | 188), ((62<<16) | 124), ((63<<16) | 252), ((65<<16) | 130), ((67<<16) | 194), ((69<<16) | 162),
    ((70<<16) | 98), ((71<<16) | 226), ((73<<16) | 146), ((74<<16) | 82), ((75<<16) | 210), ((77<<16) | 178), ((78<<16) | 114), ((79<<16) | 242),
    ((81<<16) | 138), ((83<<16) | 202), ((85<<16) | 170), ((86<<16) | 106), ((87<<16) | 234), ((89<<16) | 154), ((91<<16) | 218), ((93<<16) | 186),
    ((94<<16) | 122), ((95<<16) | 250), ((97<<16) | 134), ((99<<16) | 198), ((101<<16) | 166), ((103<<16) | 230), ((105<<16) | 150), ((107<<16) | 214),
    ((109<<16) | 182), ((110<<16) | 118), ((111<<16) | 246), ((113<<16) | 142), ((115<<16) | 206), ((117<<16) | 174), ((119<<16) | 238), ((121<<16) | 158),
    ((123<<16) | 222), ((125<<16) | 190), ((127<<16) | 254), ((131<<16) | 193), ((133<<16) | 161), ((135<<16) | 225), ((137<<16) | 145), ((139<<16) | 209),
    ((141<<16) | 177), ((143<<16) | 241), ((147<<16) | 201), ((149<<16) | 169), ((151<<16) | 233), ((155<<16) | 217), ((157<<16) | 185), ((159<<16) | 249),
    ((163<<16) | 197), ((167<<16) | 229), ((171<<16) | 213), ((173<<16) | 181), ((175<<16) | 245), ((179<<16) | 205), ((183<<16) | 237), ((187<<16) | 221),
    ((191<<16) | 253), ((199<<16) | 227), ((203<<16) | 211), ((207<<16) | 243), ((215<<16) | 235), ((223<<16) | 251), ((239<<16) | 247)
};

static const SC_DEFAULT_ALIGNED UINT32 shuffle_lut_512[240] =
{
    ((1<<16) | 256), ((2<<16) | 128), ((3<<16) | 384), ((4<<16) | 64), ((5<<16) | 320), ((6<<16) | 192), ((7<<16) | 448), ((8<<16) | 32), ((9<<16) | 288),
    ((10<<16) | 160), ((11<<16) | 416), ((12<<16) | 96), ((13<<16) | 352), ((14<<16) | 224), ((15<<16) | 480), ((17<<16) | 272), ((18<<16) | 144), ((19<<16) | 400),
    ((20<<16) | 80), ((21<<16) | 336), ((22<<16) | 208), ((23<<16) | 464), ((24<<16) | 48), ((25<<16) | 304), ((26<<16) | 176), ((27<<16) | 432), ((28<<16) | 112),
    ((29<<16) | 368), ((30<<16) | 240), ((31<<16) | 496), ((33<<16) | 264), ((34<<16) | 136), ((35<<16) | 392), ((36<<16) | 72), ((37<<16) | 328), ((38<<16) | 200),
    ((39<<16) | 456), ((41<<16) | 296), ((42<<16) | 168), ((43<<16) | 424), ((44<<16) | 104), ((45<<16) | 360), ((46<<16) | 232), ((47<<16) | 488), ((49<<16) | 280),
    ((50<<16) | 152), ((51<<16) | 408), ((52<<16) | 88), ((53<<16) | 344), ((54<<16) | 216), ((55<<16) | 472), ((57<<16) | 312), ((58<<16) | 184), ((59<<16) | 440),
    ((60<<16) | 120), ((61<<16) | 376), ((62<<16) | 248), ((63<<16) | 504), ((65<<16) | 260), ((66<<16) | 132), ((67<<16) | 388), ((69<<16) | 324), ((70<<16) | 196),
    ((71<<16) | 452), ((73<<16) | 292), ((74<<16) | 164), ((75<<16) | 420), ((76<<16) | 100), ((77<<16) | 356), ((78<<16) | 228), ((79<<16) | 484), ((81<<16) | 276),
    ((82<<16) | 148), ((83<<16) | 404), ((85<<16) | 340), ((86<<16) | 212), ((87<<16) | 468), ((89<<16) | 308), ((90<<16) | 180), ((91<<16) | 436), ((92<<16) | 116),
    ((93<<16) | 372), ((94<<16) | 244), ((95<<16) | 500), ((97<<16) | 268), ((98<<16) | 140), ((99<<16) | 396), ((101<<16) | 332), ((102<<16) | 204), ((103<<16) | 460),
    ((105<<16) | 300), ((106<<16) | 172), ((107<<16) | 428), ((109<<16) | 364), ((110<<16) | 236), ((111<<16) | 492), ((113<<16) | 284), ((114<<16) | 156), ((115<<16) | 412),
    ((117<<16) | 348), ((118<<16) | 220), ((119<<16) | 476), ((121<<16) | 316), ((122<<16) | 188), ((123<<16) | 444), ((125<<16) | 380), ((126<<16) | 252), ((127<<16) | 508),
    ((129<<16) | 258), ((131<<16) | 386), ((133<<16) | 322), ((134<<16) | 194), ((135<<16) | 450), ((137<<16) | 290), ((138<<16) | 162), ((139<<16) | 418), ((141<<16) | 354),
    ((142<<16) | 226), ((143<<16) | 482), ((145<<16) | 274), ((147<<16) | 402), ((149<<16) | 338), ((150<<16) | 210), ((151<<16) | 466), ((153<<16) | 306), ((154<<16) | 178),
    ((155<<16) | 434), ((157<<16) | 370), ((158<<16) | 242), ((159<<16) | 498), ((161<<16) | 266), ((163<<16) | 394), ((165<<16) | 330), ((166<<16) | 202), ((167<<16) | 458),
    ((169<<16) | 298), ((171<<16) | 426), ((173<<16) | 362), ((174<<16) | 234), ((175<<16) | 490), ((177<<16) | 282), ((179<<16) | 410), ((181<<16) | 346), ((182<<16) | 218),
    ((183<<16) | 474), ((185<<16) | 314), ((187<<16) | 442), ((189<<16) | 378), ((190<<16) | 250), ((191<<16) | 506), ((193<<16) | 262), ((195<<16) | 390), ((197<<16) | 326),
    ((199<<16) | 454), ((201<<16) | 294), ((203<<16) | 422), ((205<<16) | 358), ((206<<16) | 230), ((207<<16) | 486), ((209<<16) | 278), ((211<<16) | 406), ((213<<16) | 342),
    ((215<<16) | 470), ((217<<16) | 310), ((219<<16) | 438), ((221<<16) | 374), ((222<<16) | 246), ((223<<16) | 502), ((225<<16) | 270), ((227<<16) | 398), ((229<<16) | 334),
    ((231<<16) | 462), ((233<<16) | 302), ((235<<16) | 430), ((237<<16) | 366), ((239<<16) | 494), ((241<<16) | 286), ((243<<16) | 414), ((245<<16) | 350), ((247<<16) | 478),
    ((249<<16) | 318), ((251<<16) | 446), ((253<<16) | 382), ((255<<16) | 510), ((259<<16) | 385), ((261<<16) | 321), ((263<<16) | 449), ((265<<16) | 289), ((267<<16) | 417),
    ((269<<16) | 353), ((271<<16) | 481), ((275<<16) | 401), ((277<<16) | 337), ((279<<16) | 465), ((281<<16) | 305), ((283<<16) | 433), ((285<<16) | 369), ((287<<16) | 497),
    ((291<<16) | 393), ((293<<16) | 329), ((295<<16) | 457), ((299<<16) | 425), ((301<<16) | 361), ((303<<16) | 489), ((307<<16) | 409), ((309<<16) | 345), ((311<<16) | 473),
    ((315<<16) | 441), ((317<<16) | 377), ((319<<16) | 505), ((323<<16) | 389), ((327<<16) | 453), ((331<<16) | 421), ((333<<16) | 357), ((335<<16) | 485), ((339<<16) | 405),
    ((343<<16) | 469), ((347<<16) | 437), ((349<<16) | 373), ((351<<16) | 501), ((355<<16) | 397), ((359<<16) | 461), ((363<<16) | 429), ((367<<16) | 493), ((371<<16) | 413),
    ((375<<16) | 477), ((379<<16) | 445), ((383<<16) | 509), ((391<<16) | 451), ((395<<16) | 419), ((399<<16) | 483), ((407<<16) | 467), ((411<<16) | 435), ((415<<16) | 499),
    ((423<<16) | 459), ((431<<16) | 491), ((439<<16) | 475), ((447<<16) | 507), ((463<<16) | 487), ((479<<16) | 503)
};

static const SC_DEFAULT_ALIGNED UINT32 shuffle_lut_1024[496] =
{     ((1<<16) | 512), ((2<<16) | 256), ((3<<16) | 768), ((4<<16) | 128), ((5<<16) | 640), ((6<<16) | 384), ((7<<16) | 896), ((8<<16) | 64), ((9<<16) | 576), ((10<<16) | 320), ((11<<16) | 832), ((12<<16) | 192), ((13<<16) | 704),
    ((14<<16) | 448), ((15<<16) | 960), ((16<<16) | 32), ((17<<16) | 544), ((18<<16) | 288), ((19<<16) | 800), ((20<<16) | 160), ((21<<16) | 672), ((22<<16) | 416), ((23<<16) | 928), ((24<<16) | 96), ((25<<16) | 608), ((26<<16) | 352),
    ((27<<16) | 864), ((28<<16) | 224), ((29<<16) | 736), ((30<<16) | 480), ((31<<16) | 992), ((33<<16) | 528), ((34<<16) | 272), ((35<<16) | 784), ((36<<16) | 144), ((37<<16) | 656), ((38<<16) | 400), ((39<<16) | 912), ((40<<16) | 80),
    ((41<<16) | 592), ((42<<16) | 336), ((43<<16) | 848), ((44<<16) | 208), ((45<<16) | 720), ((46<<16) | 464), ((47<<16) | 976), ((49<<16) | 560), ((50<<16) | 304), ((51<<16) | 816), ((52<<16) | 176), ((53<<16) | 688), ((54<<16) | 432),
    ((55<<16) | 944), ((56<<16) | 112), ((57<<16) | 624), ((58<<16) | 368), ((59<<16) | 880), ((60<<16) | 240), ((61<<16) | 752), ((62<<16) | 496), ((63<<16) | 1008), ((65<<16) | 520), ((66<<16) | 264), ((67<<16) | 776), ((68<<16) | 136),
    ((69<<16) | 648), ((70<<16) | 392), ((71<<16) | 904), ((73<<16) | 584), ((74<<16) | 328), ((75<<16) | 840), ((76<<16) | 200), ((77<<16) | 712), ((78<<16) | 456), ((79<<16) | 968), ((81<<16) | 552), ((82<<16) | 296), ((83<<16) | 808),
    ((84<<16) | 168), ((85<<16) | 680), ((86<<16) | 424), ((87<<16) | 936), ((88<<16) | 104), ((89<<16) | 616), ((90<<16) | 360), ((91<<16) | 872), ((92<<16) | 232), ((93<<16) | 744), ((94<<16) | 488), ((95<<16) | 1000), ((97<<16) | 536),
    ((98<<16) | 280), ((99<<16) | 792), ((100<<16) | 152), ((101<<16) | 664), ((102<<16) | 408), ((103<<16) | 920), ((105<<16) | 600), ((106<<16) | 344), ((107<<16) | 856), ((108<<16) | 216), ((109<<16) | 728), ((110<<16) | 472),
    ((111<<16) | 984), ((113<<16) | 568), ((114<<16) | 312), ((115<<16) | 824), ((116<<16) | 184), ((117<<16) | 696), ((118<<16) | 440), ((119<<16) | 952), ((121<<16) | 632), ((122<<16) | 376), ((123<<16) | 888), ((124<<16) | 248),
    ((125<<16) | 760), ((126<<16) | 504), ((127<<16) | 1016), ((129<<16) | 516), ((130<<16) | 260), ((131<<16) | 772), ((133<<16) | 644), ((134<<16) | 388), ((135<<16) | 900), ((137<<16) | 580), ((138<<16) | 324), ((139<<16) | 836),
    ((140<<16) | 196), ((141<<16) | 708), ((142<<16) | 452), ((143<<16) | 964), ((145<<16) | 548), ((146<<16) | 292), ((147<<16) | 804), ((148<<16) | 164), ((149<<16) | 676), ((150<<16) | 420), ((151<<16) | 932), ((153<<16) | 612),
    ((154<<16) | 356), ((155<<16) | 868), ((156<<16) | 228), ((157<<16) | 740), ((158<<16) | 484), ((159<<16) | 996), ((161<<16) | 532), ((162<<16) | 276), ((163<<16) | 788), ((165<<16) | 660), ((166<<16) | 404), ((167<<16) | 916),
    ((169<<16) | 596), ((170<<16) | 340), ((171<<16) | 852), ((172<<16) | 212), ((173<<16) | 724), ((174<<16) | 468), ((175<<16) | 980), ((177<<16) | 564), ((178<<16) | 308), ((179<<16) | 820), ((181<<16) | 692), ((182<<16) | 436),
    ((183<<16) | 948), ((185<<16) | 628), ((186<<16) | 372), ((187<<16) | 884), ((188<<16) | 244), ((189<<16) | 756), ((190<<16) | 500), ((191<<16) | 1012), ((193<<16) | 524), ((194<<16) | 268), ((195<<16) | 780), ((197<<16) | 652),
    ((198<<16) | 396), ((199<<16) | 908), ((201<<16) | 588), ((202<<16) | 332), ((203<<16) | 844), ((205<<16) | 716), ((206<<16) | 460), ((207<<16) | 972), ((209<<16) | 556), ((210<<16) | 300), ((211<<16) | 812), ((213<<16) | 684),
    ((214<<16) | 428), ((215<<16) | 940), ((217<<16) | 620), ((218<<16) | 364), ((219<<16) | 876), ((220<<16) | 236), ((221<<16) | 748), ((222<<16) | 492), ((223<<16) | 1004), ((225<<16) | 540), ((226<<16) | 284), ((227<<16) | 796),
    ((229<<16) | 668), ((230<<16) | 412), ((231<<16) | 924), ((233<<16) | 604), ((234<<16) | 348), ((235<<16) | 860), ((237<<16) | 732), ((238<<16) | 476), ((239<<16) | 988), ((241<<16) | 572), ((242<<16) | 316), ((243<<16) | 828),
    ((245<<16) | 700), ((246<<16) | 444), ((247<<16) | 956), ((249<<16) | 636), ((250<<16) | 380), ((251<<16) | 892), ((253<<16) | 764), ((254<<16) | 508), ((255<<16) | 1020), ((257<<16) | 514), ((259<<16) | 770), ((261<<16) | 642),
    ((262<<16) | 386), ((263<<16) | 898), ((265<<16) | 578), ((266<<16) | 322), ((267<<16) | 834), ((269<<16) | 706), ((270<<16) | 450), ((271<<16) | 962), ((273<<16) | 546), ((274<<16) | 290), ((275<<16) | 802), ((277<<16) | 674),
    ((278<<16) | 418), ((279<<16) | 930), ((281<<16) | 610), ((282<<16) | 354), ((283<<16) | 866), ((285<<16) | 738), ((286<<16) | 482), ((287<<16) | 994), ((289<<16) | 530), ((291<<16) | 786), ((293<<16) | 658), ((294<<16) | 402),
    ((295<<16) | 914), ((297<<16) | 594), ((298<<16) | 338), ((299<<16) | 850), ((301<<16) | 722), ((302<<16) | 466), ((303<<16) | 978), ((305<<16) | 562), ((307<<16) | 818), ((309<<16) | 690), ((310<<16) | 434), ((311<<16) | 946),
    ((313<<16) | 626), ((314<<16) | 370), ((315<<16) | 882), ((317<<16) | 754), ((318<<16) | 498), ((319<<16) | 1010), ((321<<16) | 522), ((323<<16) | 778), ((325<<16) | 650), ((326<<16) | 394), ((327<<16) | 906), ((329<<16) | 586),
    ((331<<16) | 842), ((333<<16) | 714), ((334<<16) | 458), ((335<<16) | 970), ((337<<16) | 554), ((339<<16) | 810), ((341<<16) | 682), ((342<<16) | 426), ((343<<16) | 938), ((345<<16) | 618), ((346<<16) | 362), ((347<<16) | 874),
    ((349<<16) | 746), ((350<<16) | 490), ((351<<16) | 1002), ((353<<16) | 538), ((355<<16) | 794), ((357<<16) | 666), ((358<<16) | 410), ((359<<16) | 922), ((361<<16) | 602), ((363<<16) | 858), ((365<<16) | 730), ((366<<16) | 474),
    ((367<<16) | 986), ((369<<16) | 570), ((371<<16) | 826), ((373<<16) | 698), ((374<<16) | 442), ((375<<16) | 954), ((377<<16) | 634), ((379<<16) | 890), ((381<<16) | 762), ((382<<16) | 506), ((383<<16) | 1018), ((385<<16) | 518),
    ((387<<16) | 774), ((389<<16) | 646), ((391<<16) | 902), ((393<<16) | 582), ((395<<16) | 838), ((397<<16) | 710), ((398<<16) | 454), ((399<<16) | 966), ((401<<16) | 550), ((403<<16) | 806), ((405<<16) | 678), ((406<<16) | 422),
    ((407<<16) | 934), ((409<<16) | 614), ((411<<16) | 870), ((413<<16) | 742), ((414<<16) | 486), ((415<<16) | 998), ((417<<16) | 534), ((419<<16) | 790), ((421<<16) | 662), ((423<<16) | 918), ((425<<16) | 598), ((427<<16) | 854),
    ((429<<16) | 726), ((430<<16) | 470), ((431<<16) | 982), ((433<<16) | 566), ((435<<16) | 822), ((437<<16) | 694), ((439<<16) | 950), ((441<<16) | 630), ((443<<16) | 886), ((445<<16) | 758), ((446<<16) | 502), ((447<<16) | 1014),
    ((449<<16) | 526), ((451<<16) | 782), ((453<<16) | 654), ((455<<16) | 910), ((457<<16) | 590), ((459<<16) | 846), ((461<<16) | 718), ((463<<16) | 974), ((465<<16) | 558), ((467<<16) | 814), ((469<<16) | 686), ((471<<16) | 942),
    ((473<<16) | 622), ((475<<16) | 878), ((477<<16) | 750), ((478<<16) | 494), ((479<<16) | 1006), ((481<<16) | 542), ((483<<16) | 798), ((485<<16) | 670), ((487<<16) | 926), ((489<<16) | 606), ((491<<16) | 862), ((493<<16) | 734),
    ((495<<16) | 990), ((497<<16) | 574), ((499<<16) | 830), ((501<<16) | 702), ((503<<16) | 958), ((505<<16) | 638), ((507<<16) | 894), ((509<<16) | 766), ((511<<16) | 1022), ((515<<16) | 769), ((517<<16) | 641), ((519<<16) | 897),
    ((521<<16) | 577), ((523<<16) | 833), ((525<<16) | 705), ((527<<16) | 961), ((529<<16) | 545), ((531<<16) | 801), ((533<<16) | 673), ((535<<16) | 929), ((537<<16) | 609), ((539<<16) | 865), ((541<<16) | 737), ((543<<16) | 993),
    ((547<<16) | 785), ((549<<16) | 657), ((551<<16) | 913), ((553<<16) | 593), ((555<<16) | 849), ((557<<16) | 721), ((559<<16) | 977), ((563<<16) | 817), ((565<<16) | 689), ((567<<16) | 945), ((569<<16) | 625), ((571<<16) | 881),
    ((573<<16) | 753), ((575<<16) | 1009), ((579<<16) | 777), ((581<<16) | 649), ((583<<16) | 905), ((587<<16) | 841), ((589<<16) | 713), ((591<<16) | 969), ((595<<16) | 809), ((597<<16) | 681), ((599<<16) | 937), ((601<<16) | 617),
    ((603<<16) | 873), ((605<<16) | 745), ((607<<16) | 1001), ((611<<16) | 793), ((613<<16) | 665), ((615<<16) | 921), ((619<<16) | 857), ((621<<16) | 729), ((623<<16) | 985), ((627<<16) | 825), ((629<<16) | 697), ((631<<16) | 953),
    ((635<<16) | 889), ((637<<16) | 761), ((639<<16) | 1017), ((643<<16) | 773), ((647<<16) | 901), ((651<<16) | 837), ((653<<16) | 709), ((655<<16) | 965), ((659<<16) | 805), ((661<<16) | 677), ((663<<16) | 933), ((667<<16) | 869),
    ((669<<16) | 741), ((671<<16) | 997), ((675<<16) | 789), ((679<<16) | 917), ((683<<16) | 853), ((685<<16) | 725), ((687<<16) | 981), ((691<<16) | 821), ((695<<16) | 949), ((699<<16) | 885), ((701<<16) | 757), ((703<<16) | 1013),
    ((707<<16) | 781), ((711<<16) | 909), ((715<<16) | 845), ((719<<16) | 973), ((723<<16) | 813), ((727<<16) | 941), ((731<<16) | 877), ((733<<16) | 749), ((735<<16) | 1005), ((739<<16) | 797), ((743<<16) | 925), ((747<<16) | 861),
    ((751<<16) | 989), ((755<<16) | 829), ((759<<16) | 957), ((763<<16) | 893), ((767<<16) | 1021), ((775<<16) | 899), ((779<<16) | 835), ((783<<16) | 963), ((787<<16) | 803), ((791<<16) | 931), ((795<<16) | 867), ((799<<16) | 995),
    ((807<<16) | 915), ((811<<16) | 851), ((815<<16) | 979), ((823<<16) | 947), ((827<<16) | 883), ((831<<16) | 1011), ((839<<16) | 907), ((847<<16) | 971), ((855<<16) | 939), ((859<<16) | 875), ((863<<16) | 1003), ((871<<16) | 923),
    ((879<<16) | 987), ((887<<16) | 955), ((895<<16) | 1019), ((911<<16) | 967), ((919<<16) | 935), ((927<<16) | 999), ((943<<16) | 983), ((959<<16) | 1015), ((991<<16) | 1007)
};
#endif


// Initialise the struct used to control modular reduction
void init_reduce(ntt_params_t *p, size_t n, SINT32 q)
{
	p->n = n;
    p->u.ntt32.q = q;
    barrett_init(p);
    p->q_dbl = (DOUBLE) q;
    p->inv_q_dbl = 1.0 / p->q_dbl;
    p->inv_q_flt = 1.0 / (FLOAT) q;
}

void barrett_init(ntt_params_t *p)
{
    p->u.ntt32.k = 30;
    p->u.ntt32.m = (1 << p->u.ntt32.k) / p->u.ntt32.q;
}

SINT32 barrett_reduction_32(/*should be UINT64*/SINT64 a, SINT32 m, SINT32 k, SINT32 q)
{
    SINT64 t = (((SINT64)a * (SINT64)m) >> k);
    SINT64 c = a - t * (SINT64)q;
    if (c >= q)
        c -= q;
    return c;
}

// Sparse polynomial multiplication
void ntt32_mult_sparse_32_generic(SINT32 *v, size_t n, UINT16 omega, const SINT32 *t, const SINT32 *u)
{
    size_t i;
    SINT32 j, pos;

    // Ensure the output is cleared to zero
    for (i=n; i--;) {
        v[i] = 0;
    }

    for (i=0; i<omega; i++) {
        pos = u[i];
        for (j=0; j<pos; j++) {
            v[j] += t[j + n - pos];
        }
        for (j=pos; j<(SINT32)n; j++) {
            v[j] -= t[j - pos];
        }
    }
}

// Sparse polynomial multiplication
void ntt32_mult_sparse_16_generic(SINT32 *v, size_t n, UINT16 omega, const SINT16 *t, const SINT32 *u)
{
    size_t i;
    SINT32 j, pos;

    // Ensure the output is cleared to zero
    for (i=n; i--;) {
        v[i] = 0;
    }

    for (i=0; i<omega; i++) {
        pos = u[i];
        for (j=0; j<pos; j++) {
            v[j] += t[j + n - pos];
        }
        for (j=pos; j<(SINT32)n; j++) {
            v[j] -= t[j - pos];
        }
    }
}

// Multiply with a scalar  v = t * c.
void ntt32_mult_scalar_generic(SINT32 *v, const ntt_params_t *p,
                const SINT32 *t, SINT32 c)
{
#ifdef HAVE_AVX2
    size_t i;

    union u {
        __m256i m;
        SINT64 s[4];
    };

    // This is an AVX2 implementation ...
    __m256i scalar   = _mm256_setr_epi32(c, 0, c, 0, c, 0, c, 0);
    __m256i quotient = _mm256_setr_epi32(p->u.ntt32.q, 0, p->u.ntt32.q, 0, p->u.ntt32.q, 0, p->u.ntt32.q, 0);
    __m256i zero     = {0};
    for (i=0; i<p->n; i+=4) {
        __m128i int32t   = _mm_load_si128((__m128i*)(t + i));
        __m256i vec1     = _mm256_cvtepi32_epi64(int32t);
        __m256i res      = _mm256_mul_epi32(vec1, scalar);
        __m256i mask     = _mm256_cmpgt_epi64(zero, res);
        __m256i add      = _mm256_and_si256(mask, quotient);
        union u simd;
        simd.m = _mm256_add_epi64(res, add);
        v[i  ] = simd.s[0];
        v[i+1] = simd.s[1];
        v[i+2] = simd.s[2];
        v[i+3] = simd.s[3];
    }
#else
    size_t i;
    SINT32 q = p->u.ntt32.q;

    for (i=p->n; i--;) {
        SINT32 x = ntt_table->muln_32(t[i], c, p);
        if (x < 0)
            x += q;
        v[i] = x;
    }
#endif
}

void inverse_shuffle_32(SINT32 *v, size_t n)
{
    size_t i;

#ifdef LUT_BASED_INVERSE_SHUFFLE
    // Use a precomputed swap table with sequential reads, only use if
    // RAM/ROM is not constrained
    const SC_DEFAULT_ALIGNED UINT32 *lut = (1024 == n)? shuffle_lut_1024 :
                                           (512  == n)? shuffle_lut_512  :
                                                        shuffle_lut_256;
    size_t depth = (1024 == n)? 496 : (512 == n)? 240 : 120;
    for (i = 0; i < depth; i++) {
        UINT32 data = lut[i];
        size_t idx1 = data >> 16;
        size_t idx2 = data & 0xFFFF;

        SINT32 t = v[idx1];
        v[idx1] = v[idx2];
        v[idx2] = t;
    }
#else
#ifdef __arm__
    // Make use of a bit reversal instruction
    UINT32 bits = 32 - sc_ctz_32(n);
    for (i = 1; i < n-1; i++) {       // 00..0 and 11..1 remain same
        UINT32 r = sc_bit_reverse_32(i);
        r >>= bits;
        if (i < r) {
            SINT32 x = v[i];
            v[i] = v[r];
            v[r] = x;
        }
    }
#else
#ifdef HAVE___BUILTIN_CTZ
    size_t j;
    // If a BUILTIN funtion exists for CTZ then inverse incremental
    // counting can be achieved by incrementing the MSB's
    UINT32 bits = sc_ctz_32(n) - 1;
    j = n >> 1;
    for (i = 1; i < (size_t)n - 1;) {       // 00..0 and 11..1 remain same
        if (i < j) {
            SINT32 x = v[i];
            v[i] = v[j];
            v[j] = x;
        }
        UINT32 mask = i++;
        mask ^= i;
        UINT32 len = sc_ctz_32(i);
        mask <<= bits - len;
        j ^= mask;
    }
#else
    size_t j, k;

    // This is the fallback method that also increments the MSB's
    j = n >> 1;
    for (i = 1; i < n - 1; i++) {       // 00..0 and 11..1 remain same
        if (i < j) {
            SINT32 x = v[i];
            v[i] = v[j];
            v[j] = x;
        }
        k = n;
        do {
            k >>= 1;
            j ^= k;
        } while ((j & k) == 0);
    }
#endif
#endif
#endif
}

static void swap_ntt32(SINT32 *a, SINT32 *b, size_t n)
{
    SINT32 i, j;
    SINT32 limit = (n-1)>>1;

    for (i = 1, j = n - 1; i <= limit; i++, j--) {
        SINT32 x = a[i];
        a[i] = b[j];
        b[j] = x;
    }
    a[0] = -a[0];
}

void ntt32_flip_generic(SINT32 *v, const ntt_params_t *p)
{
    size_t i;
    SINT32 q = p->u.ntt32.q;

    swap_ntt32(v, v, p->n); // Encourage automatic loop vectorisation ...

    for (i=p->n; i--;) {
        SINT32 x = v[i];
        if (x < 0)
            x += q;
        if (x >= q)
            x -= q;
        v[i] = x;
    }
}


/*****************************************************************************
 * LIMB-BASED GENERIC NTT FUNCTIONS
 ****************************************************************************/

void ntt_mult_scalar_generic(sc_slimb_t *v, const ntt_params_t *p,
    const sc_slimb_t *t, sc_slimb_t c)
{
}

void ntt_mult_sparse_limb_generic(sc_slimb_t *v, size_t n, UINT16 omega,
    const sc_slimb_t *t, const sc_slimb_t *u)
{
    size_t i;
    SINT32 j, pos;

    // Ensure the output is cleared to zero
    for (i=n; i--;) {
        v[i] = 0;
    }

    for (i=0; i<omega; i++) {
        pos = u[i];
        for (j=0; j<pos; j++) {
            v[j] += t[j + n - pos];
        }
        for (j=pos; j<(SINT32)n; j++) {
            v[j] -= t[j - pos];
        }
    }
}

void ntt_mult_sparse_32_generic(sc_slimb_t *v, size_t n, UINT16 omega,
    const SINT32 *t, const sc_slimb_t *u)
{
    size_t i;
    SINT32 j, pos;

    // Ensure the output is cleared to zero
    for (i=n; i--;) {
        v[i] = 0;
    }

    for (i=0; i<omega; i++) {
        pos = u[i];
        for (j=0; j<pos; j++) {
            v[j] += (sc_slimb_t)t[j + n - pos];
        }
        for (j=pos; j<(SINT32)n; j++) {
            v[j] -= (sc_slimb_t)t[j - pos];
        }
    }
}

void ntt_mult_sparse_16_generic(sc_slimb_t *v, size_t n, UINT16 omega,
    const SINT16 *t, const sc_slimb_t *u)
{
    size_t i;
    SINT32 j, pos;

    // Ensure the output is cleared to zero
    for (i=n; i--;) {
        v[i] = 0;
    }

    for (i=0; i<omega; i++) {
        pos = u[i];
        for (j=0; j<pos; j++) {
            v[j] += (sc_slimb_t)t[j + n - pos];
        }
        for (j=pos; j<(SINT32)n; j++) {
            v[j] -= (sc_slimb_t)t[j - pos];
        }
    }
}

static void swap_ntt_limb(sc_slimb_t *a, sc_slimb_t *b, size_t n)
{
    SINT32 i, j;
    SINT32 limit = (n-1)>>1;

    for (i = 1, j = n - 1; i <= limit; i++, j--) {
        sc_slimb_t x = a[i];
        a[i] = b[j];
        b[j] = x;
    }
    a[0] = -a[0];
}

void ntt_flip_generic(sc_slimb_t *v, const ntt_params_t *p)
{
    size_t i;
    sc_slimb_t q = p->u.ntt32.q;

    swap_ntt_limb(v, v, p->n); // Encourage automatic loop vectorisation ...

    for (i=p->n; i--;) {
        sc_slimb_t x = v[i];
        if (x < 0)
            x += q;
        if (x >= q)
            x -= q;
        v[i] = x;
    }
}

void inverse_shuffle(sc_slimb_t *v, size_t n)
{
    size_t i;

#ifdef LUT_BASED_INVERSE_SHUFFLE
    // Use a precomputed swap table with sequential reads, only use if
    // RAM/ROM is not constrained
    const SC_DEFAULT_ALIGNED UINT32 *lut = (1024 == n)? shuffle_lut_1024 :
                                           (512  == n)? shuffle_lut_512  :
                                                        shuffle_lut_256;
    size_t depth = (1024 == n)? 496 : (512 == n)? 240 : 120;
    for (i = 0; i < depth; i++) {
        UINT32 data = lut[i];
        size_t idx1 = data >> 16;
        size_t idx2 = data & 0xFFFF;

        sc_slimb_t t = v[idx1];
        v[idx1] = v[idx2];
        v[idx2] = t;
    }
#else
#ifdef __arm__
    // Make use of a bit reversal instruction
    UINT32 bits = 32 - sc_ctz_32(n);
    for (i = 1; i < n-1; i++) {       // 00..0 and 11..1 remain same
        UINT32 r = sc_bit_reverse_32(i);
        r >>= bits;
        if (i < r) {
            sc_slimb_t x = v[i];
            v[i] = v[r];
            v[r] = x;
        }
    }
#else
#ifdef HAVE___BUILTIN_CTZ
    size_t j;

    // If a BUILTIN funtion exists for CTZ then inverse incremental
    // counting can be achieved by incrementing the MSB's
    UINT32 bits = sc_ctz_32(n) - 1;
    j = n >> 1;
    for (i = 1; i < (size_t)n - 1;) {       // 00..0 and 11..1 remain same
        if (i < j) {
            sc_slimb_t x = v[i];
            v[i] = v[j];
            v[j] = x;
        }
        UINT32 mask = i++;
        mask ^= i;
        UINT32 len = sc_ctz_32(i);
        mask <<= bits - len;
        j ^= mask;
    }
#else
    size_t j, k;

    // This is the fallback method that also increments the MSB's
    j = n >> 1;
    for (i = 1; i < n - 1; i++) {       // 00..0 and 11..1 remain same
        if (i < j) {
            sc_slimb_t x = v[i];
            v[i] = v[j];
            v[j] = x;
        }
        k = n;
        do {
            k >>= 1;
            j ^= k;
        } while ((j & k) == 0);
    }
#endif
#endif
#endif
}


#ifdef BARRETT_REDUCTION
#undef BARRETT_REDUCTION
#endif
